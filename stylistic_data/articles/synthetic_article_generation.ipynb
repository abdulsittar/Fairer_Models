{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7aef6d6e",
   "metadata": {},
   "source": [
    "# Synthetic Article Generation for Dataset Balancing\n",
    "\n",
    "## Overview\n",
    "This notebook generates synthetic fake news articles to address class imbalance in our dataset. Based on comprehensive analysis, we focus on:\n",
    "- **Fake data source**: \"News\" subject from Fake_articles.csv\n",
    "- **Real data source**: \"politicsnews\" subject from True_articles.csv\n",
    "\n",
    "These subjects show good differentiation and favorable imbalance for synthetic data generation methods.\n",
    "\n",
    "## Generation Strategy\n",
    "Following our successful approach with headlines and tweets:\n",
    "1. **Phase 1**: Generate 100 articles for validation\n",
    "2. **Phase 2**: Generate 500 articles for quality assessment  \n",
    "3. **Phase 3**: Full dataset generation to address imbalance (if quality is good)\n",
    "\n",
    "## Methodology\n",
    "- **Feature-guided generation**: Use discriminative patterns from real vs fake analysis\n",
    "- **Validation approach**: Test synthetic articles against baseline model performance\n",
    "- **Quality control**: Ensure coherence while maintaining distinguishing characteristics\n",
    "- **Iterative refinement**: Adjust generation parameters based on validation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cc8f4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Libraries imported successfully!\n",
      "üöÄ Setting up environment for synthetic article generation...\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import openai\n",
    "import json\n",
    "import re\n",
    "import time\n",
    "from datetime import datetime\n",
    "from typing import List, Dict, Tuple, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP and feature extraction\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from textstat import flesch_reading_ease, flesch_kincaid_grade, automated_readability_index\n",
    "from textblob import TextBlob\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "# Machine learning for validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import joblib\n",
    "\n",
    "# File and environment handling\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully!\")\n",
    "print(\"üöÄ Setting up environment for synthetic article generation...\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e788db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Configuring environment...\n",
      "üìÅ Data path: ../data/articles\n",
      "üìÅ Processed path: ../data/processed\n",
      "üìÅ Results path: ../results\n",
      "üìÅ Models path: ../saved_models\n",
      "\n",
      "üìä Generation Plan:\n",
      "   Phase 1: 100 articles (validation)\n",
      "   Phase 2: 500 articles (quality assessment)\n",
      "   Phase 3: Full imbalance correction (size TBD)\n"
     ]
    }
   ],
   "source": [
    "# Configure paths and load environment\n",
    "print(\"üîß Configuring environment...\")\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up paths\n",
    "DATA_PATH = Path('../data/articles')\n",
    "PROCESSED_PATH = Path('../data/processed')\n",
    "RESULTS_PATH = Path('../results')\n",
    "SAVED_MODELS_PATH = Path('../saved_models')\n",
    "\n",
    "# Create directories if they don't exist\n",
    "for path in [PROCESSED_PATH, RESULTS_PATH]:\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Data path: {DATA_PATH}\")\n",
    "print(f\"üìÅ Processed path: {PROCESSED_PATH}\")\n",
    "print(f\"üìÅ Results path: {RESULTS_PATH}\")\n",
    "print(f\"üìÅ Models path: {SAVED_MODELS_PATH}\")\n",
    "\n",
    "# Generation parameters\n",
    "PHASE_1_SIZE = 100   # Initial validation batch\n",
    "PHASE_2_SIZE = 500   # Quality assessment batch\n",
    "PHASE_3_SIZE = None  # Will calculate based on actual imbalance\n",
    "\n",
    "print(f\"\\nüìä Generation Plan:\")\n",
    "print(f\"   Phase 1: {PHASE_1_SIZE} articles (validation)\")\n",
    "print(f\"   Phase 2: {PHASE_2_SIZE} articles (quality assessment)\")\n",
    "print(f\"   Phase 3: Full imbalance correction (size TBD)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "714139f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìö Loading article datasets...\n",
      "‚úÖ Loaded 23,481 fake articles\n",
      "‚úÖ Loaded 21,417 true articles\n",
      "\n",
      "üìã Fake articles columns: ['title', 'text', 'subject', 'date']\n",
      "üìã True articles columns: ['title', 'text', 'subject', 'date']\n",
      "\n",
      "üìä Fake articles - Subject distribution:\n",
      "subject\n",
      "News               9050\n",
      "politics           6841\n",
      "left-news          4459\n",
      "Government News    1570\n",
      "US_News             783\n",
      "Middle-east         778\n",
      "\n",
      "üìä True articles - Subject distribution:\n",
      "subject\n",
      "politicsNews    11272\n",
      "worldnews       10145\n"
     ]
    }
   ],
   "source": [
    "# Load and filter the datasets for our target subjects\n",
    "print(\"üìö Loading article datasets...\")\n",
    "\n",
    "try:\n",
    "    # Load the datasets\n",
    "    fake_df = pd.read_csv(DATA_PATH / 'Fake_articles.csv')\n",
    "    true_df = pd.read_csv(DATA_PATH / 'True_articles.csv')\n",
    "    \n",
    "    print(f\"‚úÖ Loaded {len(fake_df):,} fake articles\")\n",
    "    print(f\"‚úÖ Loaded {len(true_df):,} true articles\")\n",
    "    \n",
    "    # Display column information\n",
    "    print(f\"\\nüìã Fake articles columns: {fake_df.columns.tolist()}\")\n",
    "    print(f\"üìã True articles columns: {true_df.columns.tolist()}\")\n",
    "    \n",
    "    # Check subject distribution\n",
    "    if 'subject' in fake_df.columns:\n",
    "        print(f\"\\nüìä Fake articles - Subject distribution:\")\n",
    "        fake_subject_counts = fake_df['subject'].value_counts()\n",
    "        print(fake_subject_counts.to_string())\n",
    "    \n",
    "    if 'subject' in true_df.columns:\n",
    "        print(f\"\\nüìä True articles - Subject distribution:\")\n",
    "        true_subject_counts = true_df['subject'].value_counts()\n",
    "        print(true_subject_counts.to_string())\n",
    "    \n",
    "except FileNotFoundError as e:\n",
    "    print(f\"‚ùå Error loading datasets: {e}\")\n",
    "    print(\"Please ensure the article CSV files exist in the data/articles directory\")\n",
    "    fake_df, true_df = None, None\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error processing datasets: {e}\")\n",
    "    fake_df, true_df = None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16cc0233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Filtering for target subjects...\n",
      "üìä Filtered Results:\n",
      "   Fake articles ('News'): 9,050\n",
      "   Real articles ('politicsnews'): 11,272\n",
      "\n",
      "‚öñÔ∏è  Dataset Balance Analysis:\n",
      "   Total articles: 20,322\n",
      "   Fake articles: 9,050 (44.5%)\n",
      "   Real articles: 11,272 (55.5%)\n",
      "   Imbalance ratio: 1.25:1 (real:fake)\n",
      "   üìà Synthetic articles needed for balance: 2,222\n",
      "   üéØ Phase 3 target size: 2,222 articles\n",
      "\n",
      "‚úÖ Target dataset prepared:\n",
      "   Combined articles: 20,322\n",
      "   Text column: text\n"
     ]
    }
   ],
   "source": [
    "# Filter datasets for our target subjects: \"News\" (fake) and \"politicsnews\" (real)\n",
    "print(\"üéØ Filtering for target subjects...\")\n",
    "\n",
    "if fake_df is not None and true_df is not None:\n",
    "    # Filter fake articles for \"News\" subject\n",
    "    target_fake = fake_df[fake_df['subject'] == 'News'].copy()\n",
    "    \n",
    "    # Filter real articles for \"politicsnews\" subject  \n",
    "    target_real = true_df[true_df['subject'] == 'politicsNews'].copy()\n",
    "    \n",
    "    print(f\"üìä Filtered Results:\")\n",
    "    print(f\"   Fake articles ('News'): {len(target_fake):,}\")\n",
    "    print(f\"   Real articles ('politicsnews'): {len(target_real):,}\")\n",
    "    \n",
    "    # Calculate imbalance\n",
    "    total_articles = len(target_fake) + len(target_real)\n",
    "    fake_ratio = len(target_fake) / total_articles\n",
    "    real_ratio = len(target_real) / total_articles\n",
    "    imbalance_ratio = len(target_real) / len(target_fake) if len(target_fake) > 0 else float('inf')\n",
    "    \n",
    "    print(f\"\\n‚öñÔ∏è  Dataset Balance Analysis:\")\n",
    "    print(f\"   Total articles: {total_articles:,}\")\n",
    "    print(f\"   Fake articles: {len(target_fake):,} ({fake_ratio:.1%})\")\n",
    "    print(f\"   Real articles: {len(target_real):,} ({real_ratio:.1%})\")\n",
    "    print(f\"   Imbalance ratio: {imbalance_ratio:.2f}:1 (real:fake)\")\n",
    "    \n",
    "    # Calculate synthetic articles needed for balance\n",
    "    if len(target_real) > len(target_fake):\n",
    "        articles_needed = len(target_real) - len(target_fake)\n",
    "        print(f\"   üìà Synthetic articles needed for balance: {articles_needed:,}\")\n",
    "        \n",
    "        # Update Phase 3 size\n",
    "        PHASE_3_SIZE = articles_needed\n",
    "        print(f\"   üéØ Phase 3 target size: {PHASE_3_SIZE:,} articles\")\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Dataset is already balanced or fake-heavy\")\n",
    "        PHASE_3_SIZE = 0\n",
    "    \n",
    "    # Add labels for consistency\n",
    "    target_fake['label'] = 1  # Fake = 1\n",
    "    target_real['label'] = 0  # Real = 0\n",
    "    \n",
    "    # Combine for analysis\n",
    "    combined_df = pd.concat([target_fake, target_real], ignore_index=True)\n",
    "    \n",
    "    print(f\"\\n‚úÖ Target dataset prepared:\")\n",
    "    print(f\"   Combined articles: {len(combined_df):,}\")\n",
    "    print(f\"   Text column: {'text' if 'text' in combined_df.columns else 'content' if 'content' in combined_df.columns else 'UNKNOWN'}\")\n",
    "    \n",
    "    # Standardize text column name\n",
    "    text_cols = ['text', 'content', 'article', 'body']\n",
    "    text_col = None\n",
    "    for col in text_cols:\n",
    "        if col in combined_df.columns:\n",
    "            text_col = col\n",
    "            break\n",
    "    \n",
    "    if text_col and text_col != 'text':\n",
    "        combined_df['text'] = combined_df[text_col]\n",
    "        print(f\"   üìù Renamed '{text_col}' to 'text' for consistency\")\n",
    "    \n",
    "    # Store in globals for later use\n",
    "    globals()['TARGET_FAKE_DF'] = target_fake\n",
    "    globals()['TARGET_REAL_DF'] = target_real  \n",
    "    globals()['COMBINED_DF'] = combined_df\n",
    "    globals()['ARTICLES_NEEDED'] = articles_needed if 'articles_needed' in locals() else 0\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Cannot proceed - datasets not loaded successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea8983a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Analyzing target dataset quality and characteristics...\n",
      "üìä Dataset Overview:\n",
      "   Shape: (20322, 5)\n",
      "   Memory usage: 0.8 MB\n",
      "\n",
      "üîç Data Quality Check:\n",
      "\n",
      "üìù Text Content Analysis:\n",
      "   Valid text articles: 20,322 / 20,322 (100.0%)\n",
      "\n",
      "üìè Text Length Statistics:\n",
      "   Character count - Mean: 2582, Median: 2417\n",
      "   Character count - Min: 1, Max: 29,781\n",
      "   Word count - Mean: 423, Median: 397\n",
      "   Word count - Min: 0, Max: 5,172\n",
      "\n",
      "‚öñÔ∏è  Fake vs Real Comparison:\n",
      "   Fake articles - Characters: 2623 ¬± 966\n",
      "   Real articles - Characters: 2549 ¬± 1783\n",
      "   Fake articles - Words: 441 ¬± 152\n",
      "   Real articles - Words: 408 ¬± 288\n",
      "   Character count effect size (Cohen's d): 0.050\n",
      "   Word count effect size (Cohen's d): 0.140\n",
      "\n",
      "‚úÖ Dataset ready for feature extraction and generation\n"
     ]
    }
   ],
   "source": [
    "# Dataset quality and content analysis\n",
    "print(\"üîç Analyzing target dataset quality and characteristics...\")\n",
    "\n",
    "if 'COMBINED_DF' in globals():\n",
    "    df = COMBINED_DF\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"üìä Dataset Overview:\")\n",
    "    print(f\"   Shape: {df.shape}\")\n",
    "    print(f\"   Memory usage: {df.memory_usage().sum() / 1024**2:.1f} MB\")\n",
    "    \n",
    "    # Check for missing values\n",
    "    print(f\"\\nüîç Data Quality Check:\")\n",
    "    missing_counts = df.isnull().sum()\n",
    "    for col, count in missing_counts.items():\n",
    "        if count > 0:\n",
    "            print(f\"   Missing {col}: {count:,} ({count/len(df):.1%})\")\n",
    "    \n",
    "    # Text content analysis\n",
    "    if 'text' in df.columns:\n",
    "        print(f\"\\nüìù Text Content Analysis:\")\n",
    "        \n",
    "        # Remove rows with missing text\n",
    "        valid_text_mask = df['text'].notna() & (df['text'].astype(str).str.len() > 0)\n",
    "        valid_df = df[valid_text_mask].copy()\n",
    "        \n",
    "        print(f\"   Valid text articles: {len(valid_df):,} / {len(df):,} ({len(valid_df)/len(df):.1%})\")\n",
    "        \n",
    "        # Text length statistics\n",
    "        text_lengths = valid_df['text'].astype(str).str.len()\n",
    "        word_counts = valid_df['text'].astype(str).str.split().str.len()\n",
    "        \n",
    "        print(f\"\\nüìè Text Length Statistics:\")\n",
    "        print(f\"   Character count - Mean: {text_lengths.mean():.0f}, Median: {text_lengths.median():.0f}\")\n",
    "        print(f\"   Character count - Min: {text_lengths.min():,}, Max: {text_lengths.max():,}\")\n",
    "        print(f\"   Word count - Mean: {word_counts.mean():.0f}, Median: {word_counts.median():.0f}\")\n",
    "        print(f\"   Word count - Min: {word_counts.min():,}, Max: {word_counts.max():,}\")\n",
    "        \n",
    "        # Compare fake vs real lengths\n",
    "        fake_lengths = valid_df[valid_df['label'] == 1]['text'].astype(str).str.len()\n",
    "        real_lengths = valid_df[valid_df['label'] == 0]['text'].astype(str).str.len()\n",
    "        \n",
    "        fake_words = valid_df[valid_df['label'] == 1]['text'].astype(str).str.split().str.len()\n",
    "        real_words = valid_df[valid_df['label'] == 0]['text'].astype(str).str.split().str.len()\n",
    "        \n",
    "        print(f\"\\n‚öñÔ∏è  Fake vs Real Comparison:\")\n",
    "        print(f\"   Fake articles - Characters: {fake_lengths.mean():.0f} ¬± {fake_lengths.std():.0f}\")\n",
    "        print(f\"   Real articles - Characters: {real_lengths.mean():.0f} ¬± {real_lengths.std():.0f}\")\n",
    "        print(f\"   Fake articles - Words: {fake_words.mean():.0f} ¬± {fake_words.std():.0f}\")\n",
    "        print(f\"   Real articles - Words: {real_words.mean():.0f} ¬± {real_words.std():.0f}\")\n",
    "        \n",
    "        # Calculate effect sizes (Cohen's d)\n",
    "        def cohens_d(x, y):\n",
    "            nx, ny = len(x), len(y)\n",
    "            dof = nx + ny - 2\n",
    "            pooled_std = np.sqrt(((nx-1)*x.var() + (ny-1)*y.var()) / dof)\n",
    "            return (x.mean() - y.mean()) / pooled_std if pooled_std > 0 else 0\n",
    "        \n",
    "        char_effect_size = cohens_d(fake_lengths, real_lengths)\n",
    "        word_effect_size = cohens_d(fake_words, real_words)\n",
    "        \n",
    "        print(f\"   Character count effect size (Cohen's d): {char_effect_size:.3f}\")\n",
    "        print(f\"   Word count effect size (Cohen's d): {word_effect_size:.3f}\")\n",
    "        \n",
    "        # Store cleaned dataset\n",
    "        globals()['VALID_DF'] = valid_df\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset ready for feature extraction and generation\")\n",
    "    \n",
    "    else:\n",
    "        print(\"‚ùå No text column found in dataset\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Combined dataset not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5f56c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÄ Sample Content Preview...\n",
      "\n",
      "üì∞ Sample Fake Article (News subject):\n",
      "================================================================================\n",
      "Title:  Donald Trump Sends Out Embarrassing New Year‚Äôs Eve Message; This is Disturbing\n",
      "Subject: News\n",
      "Text preview: Donald Trump just couldn t wish all Americans a Happy New Year and leave it at that. Instead, he had to give a shout out to his enemies, haters and  the very dishonest fake news media.  The former reality show star had just one job to do and he couldn t do it. As our Country rapidly grows stronger and smarter, I want to wish all of my friends, supporters, enemies, haters, and even the very dishonest Fake News Media, a Happy and Healthy New Year,  President Angry Pants tweeted.  2018 will be a gr...\n",
      "Full length: 2,893 characters\n",
      "\n",
      "üì∞ Sample Real Article (politicsnews subject):\n",
      "================================================================================\n",
      "Title: As U.S. budget fight looms, Republicans flip their fiscal script\n",
      "Subject: politicsNews\n",
      "Text preview: WASHINGTON (Reuters) - The head of a conservative Republican faction in the U.S. Congress, who voted this month for a huge expansion of the national debt to pay for tax cuts, called himself a ‚Äúfiscal conservative‚Äù on Sunday and urged budget restraint in 2018. In keeping with a sharp pivot under way among Republicans, U.S. Representative Mark Meadows, speaking on CBS‚Äô ‚ÄúFace the Nation,‚Äù drew a hard line on federal spending, which lawmakers are bracing to do battle over in January. When they retur...\n",
      "Full length: 4,659 characters\n",
      "\n",
      "üíæ Sample data saved to: ../data/processed/article_samples.json\n",
      "‚úÖ Ready to proceed with feature extraction and generation setup\n"
     ]
    }
   ],
   "source": [
    "# Sample content preview\n",
    "print(\"üëÄ Sample Content Preview...\")\n",
    "\n",
    "if 'VALID_DF' in globals():\n",
    "    df = VALID_DF\n",
    "    \n",
    "    # Show sample articles from each class\n",
    "    print(\"\\nüì∞ Sample Fake Article (News subject):\")\n",
    "    print(\"=\" * 80)\n",
    "    fake_sample = df[df['label'] == 1].iloc[0]\n",
    "    fake_text = fake_sample['text'][:500] + \"...\" if len(fake_sample['text']) > 500 else fake_sample['text']\n",
    "    print(f\"Title: {fake_sample.get('title', 'N/A')}\")\n",
    "    print(f\"Subject: {fake_sample.get('subject', 'N/A')}\")\n",
    "    print(f\"Text preview: {fake_text}\")\n",
    "    print(f\"Full length: {len(fake_sample['text']):,} characters\")\n",
    "    \n",
    "    print(\"\\nüì∞ Sample Real Article (politicsnews subject):\")\n",
    "    print(\"=\" * 80)\n",
    "    real_sample = df[df['label'] == 0].iloc[0]\n",
    "    real_text = real_sample['text'][:500] + \"...\" if len(real_sample['text']) > 500 else real_sample['text']\n",
    "    print(f\"Title: {real_sample.get('title', 'N/A')}\")\n",
    "    print(f\"Subject: {real_sample.get('subject', 'N/A')}\")\n",
    "    print(f\"Text preview: {real_text}\")\n",
    "    print(f\"Full length: {len(real_sample['text']):,} characters\")\n",
    "    \n",
    "    # Save sample data for reference\n",
    "    sample_data = {\n",
    "        'fake_sample': {\n",
    "            'title': fake_sample.get('title', 'N/A'),\n",
    "            'subject': fake_sample.get('subject', 'N/A'),\n",
    "            'text_length': len(fake_sample['text']),\n",
    "            'text_preview': fake_text\n",
    "        },\n",
    "        'real_sample': {\n",
    "            'title': real_sample.get('title', 'N/A'),\n",
    "            'subject': real_sample.get('subject', 'N/A'),\n",
    "            'text_length': len(real_sample['text']),\n",
    "            'text_preview': real_text\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save to file for reference\n",
    "    with open(PROCESSED_PATH / 'article_samples.json', 'w') as f:\n",
    "        json.dump(sample_data, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Sample data saved to: {PROCESSED_PATH / 'article_samples.json'}\")\n",
    "    print(\"‚úÖ Ready to proceed with feature extraction and generation setup\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Valid dataset not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b441b36",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "The foundation is now set up with:\n",
    "1. ‚úÖ **Dataset Loading**: Successfully loaded and filtered articles\n",
    "2. ‚úÖ **Subject Selection**: \"News\" (fake) vs \"politicsnews\" (real) \n",
    "3. ‚úÖ **Imbalance Analysis**: Calculated synthetic articles needed\n",
    "4. ‚úÖ **Quality Assessment**: Analyzed text content and characteristics\n",
    "5. ‚úÖ **Sample Preview**: Examined representative articles from each class\n",
    "\n",
    "**Dataset Summary:**\n",
    "- Target fake articles: News subject\n",
    "- Target real articles: politicsnews subject  \n",
    "- Imbalance ratio identified for synthetic generation planning\n",
    "- Text content validated and ready for feature extraction\n",
    "\n",
    "**Ready for next phases:**\n",
    "- Feature extraction and discriminative analysis\n",
    "- Generation prompt engineering  \n",
    "- OpenAI API setup and validation\n",
    "- Iterative generation and quality testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe85b20",
   "metadata": {},
   "source": [
    "## Feature-Guided Generation Framework\n",
    "\n",
    "Based on your comprehensive analysis, we'll implement a three-stage generation process using the key differentiators between \"News\" (fake) and \"politicsNews\" (real) articles:\n",
    "\n",
    "### üéØ Key Feature Targets (from your analysis):\n",
    "1. **Subjectivity**: 0.45-0.65 (vs 0.30-0.45 for real) - TOP differentiator\n",
    "2. **Commas**: 20-30 per article (vs 8-15 for real) - Strong structural marker  \n",
    "3. **Word Count**: 800-900 words (vs 500-700 for real) - Length difference\n",
    "4. **Gunning Fog**: 14-18 (vs 11-14 for real) - Complexity marker\n",
    "5. **N-grams**: Social media patterns vs formal wire service language\n",
    "\n",
    "### üèóÔ∏è Generation Framework:\n",
    "- **Stage 1**: 100 articles (validation & parameter tuning)\n",
    "- **Stage 2**: 500 articles (quality assessment & refinement)  \n",
    "- **Stage 3**: Full dataset generation (address complete imbalance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "965af573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë Setting up OpenAI API for synthetic article generation...\n",
      "‚úÖ OpenAI client initialized successfully\n",
      "‚úÖ API connectivity confirmed\n",
      "\n",
      "üí∞ Cost Estimation:\n",
      "   Planned articles: 2,822\n",
      "   Estimated input tokens: 564,400\n",
      "   Estimated output tokens: 3,118,310\n",
      "   Estimated total cost: $4.96\n"
     ]
    }
   ],
   "source": [
    "# OpenAI API Configuration and Cost Calculation\n",
    "print(\"üîë Setting up OpenAI API for synthetic article generation...\")\n",
    "\n",
    "# Load API key\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key or len(api_key) < 10:\n",
    "    print(\"‚ùå OPENAI_API_KEY not found or invalid!\")\n",
    "    print(\"   Please set your API key in .env file or environment variable\")\n",
    "    API_AVAILABLE = False\n",
    "else:\n",
    "    try:\n",
    "        client = openai.OpenAI(api_key=api_key)\n",
    "        print(\"‚úÖ OpenAI client initialized successfully\")\n",
    "        \n",
    "        # Test API connectivity\n",
    "        test_response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": \"Say 'API test successful'\"}],\n",
    "            max_tokens=10,\n",
    "            temperature=0\n",
    "        )\n",
    "        \n",
    "        if \"API test successful\" in test_response.choices[0].message.content:\n",
    "            print(\"‚úÖ API connectivity confirmed\")\n",
    "            API_AVAILABLE = True\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è API connectivity uncertain but proceeding\")\n",
    "            API_AVAILABLE = True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå API setup failed: {e}\")\n",
    "        API_AVAILABLE = False\n",
    "\n",
    "# Cost estimation for article generation\n",
    "if API_AVAILABLE:\n",
    "    print(f\"\\nüí∞ Cost Estimation:\")\n",
    "    \n",
    "    # Rough estimates for article generation\n",
    "    words_per_article = 850  # Target length\n",
    "    tokens_per_article_input = 200  # Prompt tokens\n",
    "    tokens_per_article_output = int(words_per_article * 1.3)  # ~1.3 tokens per word\n",
    "    \n",
    "    total_articles_planned = PHASE_1_SIZE + PHASE_2_SIZE + (ARTICLES_NEEDED if 'ARTICLES_NEEDED' in globals() else 0)\n",
    "    \n",
    "    total_input_tokens = tokens_per_article_input * total_articles_planned\n",
    "    total_output_tokens = tokens_per_article_output * total_articles_planned\n",
    "    \n",
    "    # GPT-3.5-turbo pricing (per 1M tokens)\n",
    "    input_cost = (total_input_tokens / 1_000_000) * 0.50\n",
    "    output_cost = (total_output_tokens / 1_000_000) * 1.50\n",
    "    total_cost = input_cost + output_cost\n",
    "    \n",
    "    print(f\"   Planned articles: {total_articles_planned:,}\")\n",
    "    print(f\"   Estimated input tokens: {total_input_tokens:,}\")\n",
    "    print(f\"   Estimated output tokens: {total_output_tokens:,}\")\n",
    "    print(f\"   Estimated total cost: ${total_cost:.2f}\")\n",
    "    \n",
    "    # Store configuration\n",
    "    globals()['OPENAI_CLIENT'] = client\n",
    "    globals()['GENERATION_COST_ESTIMATE'] = total_cost\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Proceeding without API - generation will not be available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a6043a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Article feature extractor initialized with target validation\n",
      "üìä Target ranges defined for 10 key features\n"
     ]
    }
   ],
   "source": [
    "# Advanced Article Feature Extractor (based on your analysis)\n",
    "class ArticleFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Extract comprehensive features from articles for validation against target patterns.\n",
    "    Based on News vs politicsNews discriminative analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Download required NLTK data\n",
    "        try:\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            nltk.download('vader_lexicon', quiet=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english')) if nltk else set()\n",
    "    \n",
    "    def extract_features(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Extract comprehensive features matching your analysis\"\"\"\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return {}\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Basic text statistics\n",
    "        words = text.split()\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        features['word_count'] = len(words)\n",
    "        features['char_count'] = len(text)\n",
    "        features['sentence_count'] = len(sentences)\n",
    "        features['avg_sentence_length'] = len(words) / max(len(sentences), 1)\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
    "        \n",
    "        # KEY DIFFERENTIATOR 1: Subjectivity (TOP feature from your analysis)\n",
    "        try:\n",
    "            blob = TextBlob(text)\n",
    "            features['subjectivity'] = blob.sentiment.subjectivity\n",
    "            features['polarity'] = blob.sentiment.polarity\n",
    "        except:\n",
    "            features['subjectivity'] = 0\n",
    "            features['polarity'] = 0\n",
    "        \n",
    "        # KEY DIFFERENTIATOR 2: Commas (strong structural marker)\n",
    "        features['commas'] = text.count(',')\n",
    "        features['comma_density'] = features['commas'] / max(features['word_count'], 1) * 100\n",
    "        \n",
    "        # Other punctuation\n",
    "        features['question_marks'] = text.count('?')\n",
    "        features['exclamation_marks'] = text.count('!')\n",
    "        features['quotation_marks'] = text.count('\"') + text.count(\"'\")\n",
    "        \n",
    "        # KEY DIFFERENTIATOR 4: Readability (Gunning Fog)\n",
    "        try:\n",
    "            features['gunning_fog'] = textstat.gunning_fog(text)\n",
    "            features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n",
    "            features['smog_index'] = textstat.smog_index(text)\n",
    "        except:\n",
    "            features['gunning_fog'] = 0\n",
    "            features['flesch_reading_ease'] = 0\n",
    "            features['smog_index'] = 0\n",
    "        \n",
    "        # Entity patterns (from your analysis)\n",
    "        # Rough approximation of named entities\n",
    "        import re\n",
    "        \n",
    "        # Person mentions (capitalized names)\n",
    "        person_pattern = r'\\b[A-Z][a-z]+ [A-Z][a-z]+\\b'\n",
    "        features['person_mentions'] = len(re.findall(person_pattern, text))\n",
    "        \n",
    "        # Organization mentions (common patterns)\n",
    "        org_indicators = ['Corp', 'Inc', 'LLC', 'Company', 'Association', 'Department', 'Agency', 'Office']\n",
    "        features['org_mentions'] = sum(text.count(indicator) for indicator in org_indicators)\n",
    "        \n",
    "        # Location mentions (rough approximation)\n",
    "        location_indicators = ['Washington', 'New York', 'California', 'Texas', 'D.C.', 'DC']\n",
    "        features['location_mentions'] = sum(text.count(location) for location in location_indicators)\n",
    "        \n",
    "        # KEY DIFFERENTIATOR 5: N-gram patterns\n",
    "        # Social media indicators (News pattern)\n",
    "        social_indicators = ['twitter', 'facebook', 'pic twitter com', 'social media', 'video', 'image']\n",
    "        features['social_media_mentions'] = sum(text.lower().count(indicator) for indicator in social_indicators)\n",
    "        \n",
    "        # Wire service patterns (politicsNews pattern)\n",
    "        wire_indicators = ['reuters', 'washington', 'associated press', 'ap news']\n",
    "        features['wire_service_mentions'] = sum(text.lower().count(indicator) for indicator in wire_indicators)\n",
    "        \n",
    "        # POS patterns (approximated)\n",
    "        adverb_indicators = ['very', 'really', 'quite', 'extremely', 'incredibly', 'absolutely', 'completely']\n",
    "        features['adverb_density'] = sum(text.lower().count(adv) for adv in adverb_indicators)\n",
    "        \n",
    "        pronoun_indicators = ['we', 'you', 'they', 'people', 'everyone', 'someone']\n",
    "        features['pronoun_density'] = sum(text.lower().count(pron) for pron in pronoun_indicators)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def validate_against_targets(self, features: Dict, targets: Dict) -> Dict:\n",
    "        \"\"\"Validate features against target ranges from your analysis\"\"\"\n",
    "        validation = {}\n",
    "        \n",
    "        for feature, target_range in targets.items():\n",
    "            if feature in features:\n",
    "                value = features[feature]\n",
    "                min_val, max_val = target_range\n",
    "                \n",
    "                validation[feature] = {\n",
    "                    'value': value,\n",
    "                    'target_min': min_val,\n",
    "                    'target_max': max_val,\n",
    "                    'in_range': min_val <= value <= max_val,\n",
    "                    'distance_from_target': min(abs(value - min_val), abs(value - max_val)) if not (min_val <= value <= max_val) else 0\n",
    "                }\n",
    "        \n",
    "        return validation\n",
    "\n",
    "# Initialize feature extractor\n",
    "feature_extractor = ArticleFeatureExtractor()\n",
    "\n",
    "# Define target ranges based on your analysis\n",
    "NEWS_TARGETS = {\n",
    "    'word_count': (800, 900),           # 40% longer than politicsNews\n",
    "    'subjectivity': (0.45, 0.65),      # TOP differentiator\n",
    "    'commas': (20, 30),                 # 2X more than politicsNews  \n",
    "    'gunning_fog': (14, 18),            # 25% harder to read\n",
    "    'question_marks': (2, 4),           # 3X more\n",
    "    'sentence_count': (30, 40),         # For target length\n",
    "    'avg_sentence_length': (20, 25),    # Longer sentences\n",
    "    'person_mentions': (8, 12),         # Entity patterns\n",
    "    'org_mentions': (10, 15),          # Organization references\n",
    "    'social_media_mentions': (1, 3)     # Social context markers\n",
    "}\n",
    "\n",
    "print(\"‚úÖ Article feature extractor initialized with target validation\")\n",
    "print(f\"üìä Target ranges defined for {len(NEWS_TARGETS)} key features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e2c841",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Synthetic article generator initialized\n",
      "üéØ Ready for three-stage generation process\n"
     ]
    }
   ],
   "source": [
    "# Synthetic Article Generator Framework\n",
    "class SyntheticArticleGenerator:\n",
    "    \"\"\"\n",
    "    Generate synthetic articles matching News vs politicsNews patterns.\n",
    "    Based on your comprehensive feature analysis and checklist.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, targets):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.targets = targets\n",
    "        \n",
    "        # Base prompt templates (to be refined with your specific prompts)\n",
    "        self.base_prompts = {\n",
    "            'interpretive_news': \"\"\"\n",
    "Write a news article in the style of interpretive journalism that covers {topic}.\n",
    "\n",
    "CRITICAL REQUIREMENTS (based on analysis):\n",
    "- Length: 800-900 words (significantly longer than wire service articles)\n",
    "- Subjectivity: Include interpretation, opinion, and analysis (not just facts)\n",
    "- Structure: Use narrative structure with 20-30 commas for complex sentences\n",
    "- Complexity: Gunning Fog index 14-18 (sophisticated but accessible)\n",
    "- Questions: Include 2-3 rhetorical questions to engage readers\n",
    "- Personal language: Use \"we\", \"people\", \"you\" to create engagement\n",
    "- Social context: Reference social media reactions or public response\n",
    "\n",
    "The article should feel like interpretive journalism that explains what events MEAN, \n",
    "not just what happened. Include analysis of implications and context.\n",
    "\"\"\",\n",
    "            \n",
    "            'narrative_analysis': \"\"\"\n",
    "Create an analytical news article about {topic} that focuses on the broader story and implications.\n",
    "\n",
    "KEY STYLE REQUIREMENTS:\n",
    "- Word count: 850 words with complex sentence structures\n",
    "- High subjectivity: Blend reporting with interpretation and analysis  \n",
    "- Punctuation: 20-30 commas in longer, more complex sentences\n",
    "- Readability: Complex but engaging (Gunning Fog 14-18)\n",
    "- Engagement: Include rhetorical questions and direct reader address\n",
    "- Context: Reference public reactions, social media, or broader implications\n",
    "- People focus: Name 8-12 individuals and their roles/reactions\n",
    "- Organization references: Mention 10-15 organizations/institutions\n",
    "\n",
    "Write in a narrative style that tells the story behind the news, not just the facts.\n",
    "\"\"\",\n",
    "            \n",
    "            'opinion_infused_reporting': \"\"\"\n",
    "Write a news article about {topic} that incorporates analysis and perspective.\n",
    "\n",
    "STRUCTURAL REQUIREMENTS (from feature analysis):\n",
    "- Target length: 800-900 words in 30-40 sentences\n",
    "- Sentence complexity: Average 20-25 words per sentence with frequent commas\n",
    "- Subjectivity level: 0.45-0.65 (interpretive, not purely objective)\n",
    "- Reading level: Gunning Fog 14-18 (sophisticated analysis)\n",
    "- Interactive elements: 2-4 questions that make readers think\n",
    "- Social awareness: Reference public discourse, reactions, or social media\n",
    "- Personal pronouns: Use engaging language (\"we\", \"people\", \"everyone\")\n",
    "\n",
    "The tone should be that of a journalist who explains not just what happened,\n",
    "but what it means and why readers should care.\n",
    "\"\"\"\n",
    "        }\n",
    "        \n",
    "        # Political topics for generation (based on your subjects)\n",
    "        self.political_topics = [\n",
    "            \"recent presidential administration policy changes\",\n",
    "            \"congressional legislative developments\",\n",
    "            \"electoral process and voting rights discussions\", \n",
    "            \"political party strategy and positioning\",\n",
    "            \"government agency regulatory decisions\",\n",
    "            \"political figure statements and reactions\",\n",
    "            \"policy implementation and public response\",\n",
    "            \"political controversy and public debate\",\n",
    "            \"government transparency and accountability issues\",\n",
    "            \"political campaign developments and implications\"\n",
    "        ]\n",
    "    \n",
    "    def generate_single_article(self, prompt_type: str = None, topic: str = None) -> Dict:\n",
    "        \"\"\"Generate a single synthetic article\"\"\"\n",
    "        \n",
    "        # Select prompt and topic\n",
    "        prompt_type = prompt_type or np.random.choice(list(self.base_prompts.keys()))\n",
    "        topic = topic or np.random.choice(self.political_topics)\n",
    "        \n",
    "        # Create full prompt\n",
    "        base_prompt = self.base_prompts[prompt_type]\n",
    "        full_prompt = base_prompt.format(topic=topic)\n",
    "        \n",
    "        try:\n",
    "            # Generate article\n",
    "            response = self.client.chat.completions.create(\n",
    "                model=\"gpt-3.5-turbo\",\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"system\", \n",
    "                        \"content\": \"You are an expert journalist creating synthetic news articles for research purposes. Focus on matching the specified stylistic patterns while maintaining coherence and realism.\"\n",
    "                    },\n",
    "                    {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": full_prompt\n",
    "                    }\n",
    "                ],\n",
    "                max_tokens=1200,  # Allow for longer articles\n",
    "                temperature=0.8   # Some creativity while maintaining consistency\n",
    "            )\n",
    "            \n",
    "            article_text = response.choices[0].message.content.strip()\n",
    "            \n",
    "            # Extract features for validation\n",
    "            features = self.feature_extractor.extract_features(article_text)\n",
    "            \n",
    "            # Validate against targets\n",
    "            validation = self.feature_extractor.validate_against_targets(features, self.targets)\n",
    "            \n",
    "            return {\n",
    "                'article': article_text,\n",
    "                'prompt_type': prompt_type,\n",
    "                'topic': topic,\n",
    "                'features': features,\n",
    "                'validation': validation,\n",
    "                'generation_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'error': str(e),\n",
    "                'prompt_type': prompt_type,\n",
    "                'topic': topic,\n",
    "                'generation_timestamp': datetime.now().isoformat()\n",
    "            }\n",
    "    \n",
    "    def generate_batch(self, count: int, stage_name: str = \"\") -> List[Dict]:\n",
    "        \"\"\"Generate a batch of synthetic articles\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Generating {count} articles for {stage_name}...\")\n",
    "        \n",
    "        articles = []\n",
    "        successful = 0\n",
    "        \n",
    "        for i in range(count):\n",
    "            try:\n",
    "                result = self.generate_single_article()\n",
    "                \n",
    "                if 'error' not in result:\n",
    "                    articles.append(result)\n",
    "                    successful += 1\n",
    "                    \n",
    "                    if successful % 10 == 0:\n",
    "                        print(f\"   Generated {successful}/{count} articles...\")\n",
    "                else:\n",
    "                    print(f\"   Error in article {i+1}: {result['error']}\")\n",
    "                \n",
    "                # Rate limiting\n",
    "                time.sleep(0.5)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Failed to generate article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Successfully generated {successful} articles\")\n",
    "        return articles\n",
    "    \n",
    "    def validate_batch_quality(self, articles: List[Dict]) -> Dict:\n",
    "        \"\"\"Validate a batch of articles against target criteria\"\"\"\n",
    "        \n",
    "        if not articles:\n",
    "            return {'error': 'No articles to validate'}\n",
    "        \n",
    "        # Extract features from all articles\n",
    "        all_features = [art['features'] for art in articles if 'features' in art]\n",
    "        \n",
    "        if not all_features:\n",
    "            return {'error': 'No feature data available'}\n",
    "        \n",
    "        # Calculate batch statistics\n",
    "        batch_stats = {}\n",
    "        target_compliance = {}\n",
    "        \n",
    "        for feature in self.targets.keys():\n",
    "            values = [f.get(feature, 0) for f in all_features]\n",
    "            if values:\n",
    "                batch_stats[feature] = {\n",
    "                    'mean': np.mean(values),\n",
    "                    'std': np.std(values),\n",
    "                    'min': np.min(values),\n",
    "                    'max': np.max(values)\n",
    "                }\n",
    "                \n",
    "                # Check target compliance\n",
    "                target_min, target_max = self.targets[feature]\n",
    "                in_range_count = sum(1 for v in values if target_min <= v <= target_max)\n",
    "                target_compliance[feature] = {\n",
    "                    'in_range_count': in_range_count,\n",
    "                    'in_range_percentage': in_range_count / len(values) * 100,\n",
    "                    'mean_in_range': target_min <= batch_stats[feature]['mean'] <= target_max\n",
    "                }\n",
    "        \n",
    "        # Overall quality score\n",
    "        overall_compliance = np.mean([tc['in_range_percentage'] for tc in target_compliance.values()])\n",
    "        \n",
    "        return {\n",
    "            'batch_size': len(articles),\n",
    "            'successful_extractions': len(all_features),\n",
    "            'batch_statistics': batch_stats,\n",
    "            'target_compliance': target_compliance,\n",
    "            'overall_compliance_percentage': overall_compliance,\n",
    "            'quality_score': 'PASS' if overall_compliance >= 60 else 'NEEDS_IMPROVEMENT'\n",
    "        }\n",
    "\n",
    "# Initialize generator (will be available when API is configured)\n",
    "if API_AVAILABLE and 'OPENAI_CLIENT' in globals():\n",
    "    generator = SyntheticArticleGenerator(OPENAI_CLIENT, feature_extractor, NEWS_TARGETS)\n",
    "    print(\"‚úÖ Synthetic article generator initialized\")\n",
    "    print(\"üéØ Ready for three-stage generation process\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Generator not initialized - API not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be0a874",
   "metadata": {},
   "source": [
    "## Three-Stage Generation Framework\n",
    "\n",
    "Now we implement the systematic three-stage approach for synthetic article generation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d58638",
   "metadata": {},
   "source": [
    "## Stage 1: Three Generation Approaches Comparison\n",
    "\n",
    "We'll test three different synthetic generation strategies in Stage 1 to determine the most effective approach:\n",
    "\n",
    "### üéØ Three Generation Methods:\n",
    "\n",
    "1. **Zero-Shot Generation**: Use extracted features, topics, and n-grams to prompt LLM directly\n",
    "2. **Few-Shot Generation**: Provide 3 fake article examples as context for generation  \n",
    "3. **Style Transfer**: Take real articles and rewrite them in fake news stylistic patterns\n",
    "\n",
    "### üß™ Evaluation Strategy:\n",
    "- Train classification model on **original data only**\n",
    "- Test how the model classifies each set of 100 synthetic articles\n",
    "- Compare classification accuracy to determine which method produces most realistic fake news patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7da32c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Preparing data for three generation approaches...\n",
      "üìä Available data:\n",
      "   Fake articles: 9,050\n",
      "   Real articles: 11,272\n",
      "\n",
      "üìù Prepared examples:\n",
      "   Few-shot fake examples: 3\n",
      "   Real articles for style transfer: 100\n",
      "\n",
      "üîç Loading existing analysis results...\n",
      "   ‚úÖ Loaded 25 key n-grams from News analysis\n",
      "   Top 5 n-grams: ['donald trump', 'getty images', 'white house', 'hillary clinton', 'united states']\n",
      "   ‚úÖ Loaded 0 key topics from News analysis\n",
      "   ‚úÖ Loaded stylistic features analysis for News subject\n",
      "\n",
      "‚úÖ Data preparation complete using existing analysis results\n"
     ]
    }
   ],
   "source": [
    "# Prepare examples and data for three generation approaches\n",
    "print(\"üîß Preparing data for three generation approaches...\")\n",
    "\n",
    "if 'VALID_DF' in globals():\n",
    "    df = VALID_DF\n",
    "    \n",
    "    # Get fake and real article samples\n",
    "    fake_articles = df[df['label'] == 1]\n",
    "    real_articles = df[df['label'] == 0]\n",
    "    \n",
    "    print(f\"üìä Available data:\")\n",
    "    print(f\"   Fake articles: {len(fake_articles):,}\")\n",
    "    print(f\"   Real articles: {len(real_articles):,}\")\n",
    "    \n",
    "    # Sample examples for few-shot learning (3 fake articles)\n",
    "    few_shot_fake_examples = fake_articles.sample(n=3, random_state=42)\n",
    "    \n",
    "    # Sample real articles for style transfer (different from few-shot)\n",
    "    style_transfer_real_examples = real_articles.sample(n=100, random_state=42)  # 100 for rewriting\n",
    "    \n",
    "    print(f\"\\nüìù Prepared examples:\")\n",
    "    print(f\"   Few-shot fake examples: {len(few_shot_fake_examples)}\")\n",
    "    print(f\"   Real articles for style transfer: {len(style_transfer_real_examples)}\")\n",
    "    \n",
    "    # Load existing analysis results for News vs politicsNews\n",
    "    print(f\"\\nüîç Loading existing analysis results...\")\n",
    "    \n",
    "    try:\n",
    "        # Load News subject n-grams (fake news patterns)\n",
    "        news_2grams_path = '/home/mateja/Documents/IJS/current/Fairer_Models/results/subject_analysis/News_2-grams.csv'\n",
    "        news_3grams_path = '/home/mateja/Documents/IJS/current/Fairer_Models/results/subject_analysis/News_3-grams.csv'\n",
    "        \n",
    "        news_2grams_df = pd.read_csv(news_2grams_path)\n",
    "        news_3grams_df = pd.read_csv(news_3grams_path)\n",
    "        \n",
    "        # Get top n-grams (most frequent/distinctive)\n",
    "        top_2grams = news_2grams_df.head(15)['ngram'].tolist()\n",
    "        top_3grams = news_3grams_df.head(10)['ngram'].tolist()\n",
    "        \n",
    "        fake_key_ngrams = top_2grams + top_3grams\n",
    "        \n",
    "        print(f\"   ‚úÖ Loaded {len(fake_key_ngrams)} key n-grams from News analysis\")\n",
    "        print(f\"   Top 5 n-grams: {fake_key_ngrams[:5]}\")\n",
    "        \n",
    "        # Load News topics\n",
    "        news_topics_path = '/home/mateja/Documents/IJS/current/Fairer_Models/results/subject_analysis/News_topics.csv'\n",
    "        news_topics_df = pd.read_csv(news_topics_path)\n",
    "        \n",
    "        # Get top topics \n",
    "        fake_key_topics = news_topics_df.head(10)['topic'].tolist() if 'topic' in news_topics_df.columns else []\n",
    "        \n",
    "        print(f\"   ‚úÖ Loaded {len(fake_key_topics)} key topics from News analysis\")\n",
    "        \n",
    "        # Load stylistic features for News (our targets)\n",
    "        news_features_path = '/home/mateja/Documents/IJS/current/Fairer_Models/results/subject_analysis/News_stylistic_features.csv'\n",
    "        news_features_df = pd.read_csv(news_features_path)\n",
    "        \n",
    "        print(f\"   ‚úÖ Loaded stylistic features analysis for News subject\")\n",
    "        \n",
    "        # Store for generation\n",
    "        globals()['FEW_SHOT_FAKE_EXAMPLES'] = few_shot_fake_examples\n",
    "        globals()['STYLE_TRANSFER_REAL_EXAMPLES'] = style_transfer_real_examples\n",
    "        globals()['FAKE_KEY_NGRAMS'] = fake_key_ngrams\n",
    "        globals()['FAKE_KEY_TOPICS'] = fake_key_topics\n",
    "        globals()['NEWS_FEATURES_DF'] = news_features_df\n",
    "        \n",
    "        print(f\"\\n‚úÖ Data preparation complete using existing analysis results\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error loading existing analysis: {e}\")\n",
    "        print(\"üí° Falling back to basic preparation...\")\n",
    "        \n",
    "        # Fallback: just prepare examples without n-gram extraction\n",
    "        globals()['FEW_SHOT_FAKE_EXAMPLES'] = few_shot_fake_examples\n",
    "        globals()['STYLE_TRANSFER_REAL_EXAMPLES'] = style_transfer_real_examples\n",
    "        globals()['FAKE_KEY_NGRAMS'] = []\n",
    "        globals()['FAKE_KEY_TOPICS'] = []\n",
    "        \n",
    "        print(f\"‚úÖ Basic data preparation complete\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Valid dataset not available for example preparation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d1d1c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Multi-approach generator initialized\n",
      "üéØ Ready for three-method comparison generation\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Synthetic Article Generator with Three Approaches\n",
    "class MultiApproachSyntheticGenerator:\n",
    "    \"\"\"\n",
    "    Generate synthetic articles using three different approaches:\n",
    "    1. Zero-shot with features/topics/n-grams\n",
    "    2. Few-shot with fake article examples\n",
    "    3. Style transfer from real articles\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, targets):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.targets = targets\n",
    "    \n",
    "    def generate_zero_shot(self, count: int = 100) -> List[Dict]:\n",
    "        \"\"\"Approach 1: Zero-shot generation using extracted patterns\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Approach 1: Zero-shot generation ({count} articles)\")\n",
    "        \n",
    "        # Create zero-shot prompt based on extracted features\n",
    "        zero_shot_prompt = f\"\"\"\n",
    "Create a news article that matches these specific fake news characteristics:\n",
    "\n",
    "STYLISTIC REQUIREMENTS (extracted from analysis):\n",
    "- Length: 800-900 words in 30-40 sentences\n",
    "- Subjectivity: High interpretive/opinion content (0.45-0.65 subjectivity score)\n",
    "- Sentence structure: Complex sentences with 20-30 commas total\n",
    "- Reading complexity: Gunning Fog index 14-18 (sophisticated but accessible)\n",
    "- Engagement: Include 2-4 rhetorical questions\n",
    "- Personal language: Use \"we\", \"people\", \"you\" frequently\n",
    "\n",
    "CONTENT PATTERNS (from fake news analysis):\n",
    "- Include social media references or public reactions\n",
    "- Name 8-12 specific people and their roles\n",
    "- Reference 10-15 organizations or institutions  \n",
    "- Incorporate these typical n-gram patterns: {', '.join(FAKE_KEY_NGRAMS[:10]) if 'FAKE_KEY_NGRAMS' in globals() else 'social media, public reaction, controversy'}\n",
    "\n",
    "TOPIC: {{topic}}\n",
    "\n",
    "Write a complete news article that feels interpretive rather than purely factual, focusing on what events MEAN rather than just what happened.\n",
    "\"\"\"\n",
    "        \n",
    "        political_topics = [\n",
    "            \"recent congressional legislative debates\",\n",
    "            \"presidential administration policy implementations\", \n",
    "            \"electoral integrity and voting rights discussions\",\n",
    "            \"political party strategic positioning\",\n",
    "            \"government transparency initiatives\",\n",
    "            \"regulatory agency decisions and public response\",\n",
    "            \"political figure controversial statements\",\n",
    "            \"policy impact on different communities\",\n",
    "            \"government accountability investigations\",\n",
    "            \"political campaign strategy developments\"\n",
    "        ]\n",
    "        \n",
    "        articles = []\n",
    "        for i in range(count):\n",
    "            try:\n",
    "                topic = np.random.choice(political_topics)\n",
    "                full_prompt = zero_shot_prompt.format(topic=topic)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are creating synthetic news articles for research. Focus on matching the specified stylistic patterns of interpretive journalism.\"},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt}\n",
    "                    ],\n",
    "                    max_tokens=1200,\n",
    "                    temperature=0.8\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': 'zero_shot',\n",
    "                    'topic': topic,\n",
    "                    'features': features,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 20 == 0:\n",
    "                    print(f\"   Generated {i + 1}/{count} zero-shot articles...\")\n",
    "                    \n",
    "                time.sleep(0.3)  # Rate limiting\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating zero-shot article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Zero-shot generation complete: {len(articles)} articles\")\n",
    "        return articles\n",
    "    \n",
    "    def generate_few_shot(self, count: int = 100) -> List[Dict]:\n",
    "        \"\"\"Approach 2: Few-shot generation with fake article examples\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Approach 2: Few-shot generation ({count} articles)\")\n",
    "        \n",
    "        if 'FEW_SHOT_FAKE_EXAMPLES' not in globals():\n",
    "            print(\"‚ùå Few-shot examples not available\")\n",
    "            return []\n",
    "        \n",
    "        examples = FEW_SHOT_FAKE_EXAMPLES\n",
    "        \n",
    "        # Create few-shot prompt with examples\n",
    "        examples_text = \"\"\n",
    "        for idx, row in examples.iterrows():\n",
    "            title = row.get('title', 'No title')\n",
    "            text = row['text'][:800] + \"...\" if len(row['text']) > 800 else row['text']\n",
    "            examples_text += f\"\\nExample {len(examples_text.split('Example')) if examples_text else 1}:\\n\"\n",
    "            examples_text += f\"Title: {title}\\n\"\n",
    "            examples_text += f\"Article: {text}\\n\"\n",
    "            examples_text += \"---\\n\"\n",
    "        \n",
    "        few_shot_prompt = f\"\"\"\n",
    "Here are examples of fake news articles with their characteristic style:\n",
    "\n",
    "{examples_text}\n",
    "\n",
    "Based on these examples, create a similar news article about {{topic}} that matches the same:\n",
    "- Interpretive, opinion-heavy writing style\n",
    "- Length and sentence complexity patterns  \n",
    "- Use of personal pronouns and engagement techniques\n",
    "- Social context and public reaction references\n",
    "- Narrative structure over pure factual reporting\n",
    "\n",
    "Create a complete article that follows these stylistic patterns while covering the given topic.\n",
    "\"\"\"\n",
    "        \n",
    "        articles = []\n",
    "        topics = [\n",
    "            \"government policy implementation challenges\",\n",
    "            \"political accountability investigations\", \n",
    "            \"electoral system integrity debates\",\n",
    "            \"regulatory decision public backlash\",\n",
    "            \"political figure controversial actions\",\n",
    "            \"legislative process transparency issues\",\n",
    "            \"campaign finance reform discussions\",\n",
    "            \"government agency oversight concerns\",\n",
    "            \"political party internal conflicts\",\n",
    "            \"policy impact community responses\"\n",
    "        ]\n",
    "        \n",
    "        for i in range(count):\n",
    "            try:\n",
    "                topic = np.random.choice(topics)\n",
    "                full_prompt = few_shot_prompt.format(topic=topic)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are creating synthetic news articles for research based on provided examples. Match the stylistic patterns of the examples.\"},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt}\n",
    "                    ],\n",
    "                    max_tokens=1200,\n",
    "                    temperature=0.7\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': 'few_shot',\n",
    "                    'topic': topic,\n",
    "                    'features': features,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 20 == 0:\n",
    "                    print(f\"   Generated {i + 1}/{count} few-shot articles...\")\n",
    "                    \n",
    "                time.sleep(0.3)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating few-shot article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Few-shot generation complete: {len(articles)} articles\")\n",
    "        return articles\n",
    "    \n",
    "    def generate_style_transfer(self, count: int = 100) -> List[Dict]:\n",
    "        \"\"\"Approach 3: Style transfer from real to fake patterns\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Approach 3: Style transfer generation ({count} articles)\")\n",
    "        \n",
    "        if 'STYLE_TRANSFER_REAL_EXAMPLES' not in globals():\n",
    "            print(\"‚ùå Real articles for style transfer not available\")\n",
    "            return []\n",
    "        \n",
    "        real_articles = STYLE_TRANSFER_REAL_EXAMPLES.head(count)\n",
    "        \n",
    "        style_transfer_prompt = \"\"\"\n",
    "Rewrite the following real news article to match fake news stylistic patterns:\n",
    "\n",
    "ORIGINAL ARTICLE:\n",
    "{original_article}\n",
    "\n",
    "TRANSFORMATION REQUIREMENTS:\n",
    "- Change from objective reporting to interpretive/opinion-heavy style\n",
    "- Increase subjectivity (add analysis of what events MEAN)\n",
    "- Make sentences longer and more complex with more commas\n",
    "- Add rhetorical questions (2-4 total)\n",
    "- Include references to public reactions or social media response\n",
    "- Use personal pronouns (\"we\", \"people\", \"you\") to engage readers\n",
    "- Transform from inverted pyramid to narrative structure\n",
    "- Maintain the same basic facts and topic but change the framing\n",
    "\n",
    "Rewrite this to sound like interpretive journalism that explains implications rather than just reporting facts.\n",
    "\"\"\"\n",
    "        \n",
    "        articles = []\n",
    "        for idx, row in real_articles.iterrows():\n",
    "            try:\n",
    "                original_article = row['text']\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are transforming objective news articles into interpretive journalism style for research purposes. Focus on changing the framing and style while maintaining factual accuracy.\"},\n",
    "                        {\"role\": \"user\", \"content\": style_transfer_prompt.format(original_article=original_article)}\n",
    "                    ],\n",
    "                    max_tokens=1200,\n",
    "                    temperature=0.6\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': 'style_transfer',\n",
    "                    'original_article': original_article,\n",
    "                    'features': features,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (len(articles)) % 20 == 0:\n",
    "                    print(f\"   Generated {len(articles)}/{count} style transfer articles...\")\n",
    "                    \n",
    "                time.sleep(0.3)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating style transfer article {len(articles)+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Style transfer generation complete: {len(articles)} articles\")\n",
    "        return articles\n",
    "\n",
    "# Initialize multi-approach generator\n",
    "if API_AVAILABLE and 'OPENAI_CLIENT' in globals():\n",
    "    multi_generator = MultiApproachSyntheticGenerator(OPENAI_CLIENT, feature_extractor, NEWS_TARGETS)\n",
    "    print(\"‚úÖ Multi-approach generator initialized\")\n",
    "    print(\"üéØ Ready for three-method comparison generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Multi-approach generator not initialized - API not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a29495ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ STAGE 1: THREE-APPROACH COMPARATIVE GENERATION\n",
      "============================================================\n",
      "üìä Generating 100 articles using each of the 3 approaches\n",
      "üß™ Goal: Compare generation methods and select best approach\n",
      "\n",
      "üöÄ Starting three-approach generation...\n",
      "\n",
      "==================================================\n",
      "üöÄ Approach 1: Zero-shot generation (100 articles)\n",
      "   Generated 20/100 zero-shot articles...\n",
      "   Generated 20/100 zero-shot articles...\n",
      "   Generated 40/100 zero-shot articles...\n",
      "   Generated 40/100 zero-shot articles...\n",
      "   Generated 60/100 zero-shot articles...\n",
      "   Generated 60/100 zero-shot articles...\n",
      "   Generated 80/100 zero-shot articles...\n",
      "   Generated 80/100 zero-shot articles...\n",
      "   Generated 100/100 zero-shot articles...\n",
      "   Generated 100/100 zero-shot articles...\n",
      "‚úÖ Zero-shot generation complete: 100 articles\n",
      "\n",
      "==================================================\n",
      "üöÄ Approach 2: Few-shot generation (100 articles)\n",
      "‚úÖ Zero-shot generation complete: 100 articles\n",
      "\n",
      "==================================================\n",
      "üöÄ Approach 2: Few-shot generation (100 articles)\n",
      "   Generated 20/100 few-shot articles...\n",
      "   Generated 20/100 few-shot articles...\n",
      "   Generated 40/100 few-shot articles...\n",
      "   Generated 40/100 few-shot articles...\n",
      "   Generated 60/100 few-shot articles...\n",
      "   Generated 60/100 few-shot articles...\n",
      "   Generated 80/100 few-shot articles...\n",
      "   Generated 80/100 few-shot articles...\n",
      "   Generated 100/100 few-shot articles...\n",
      "   Generated 100/100 few-shot articles...\n",
      "‚úÖ Few-shot generation complete: 100 articles\n",
      "\n",
      "==================================================\n",
      "üöÄ Approach 3: Style transfer generation (100 articles)\n",
      "‚úÖ Few-shot generation complete: 100 articles\n",
      "\n",
      "==================================================\n",
      "üöÄ Approach 3: Style transfer generation (100 articles)\n",
      "   Generated 20/100 style transfer articles...\n",
      "   Generated 20/100 style transfer articles...\n",
      "   Generated 40/100 style transfer articles...\n",
      "   Generated 40/100 style transfer articles...\n",
      "   Generated 60/100 style transfer articles...\n",
      "   Generated 60/100 style transfer articles...\n",
      "   Generated 80/100 style transfer articles...\n",
      "   Generated 80/100 style transfer articles...\n",
      "   Generated 100/100 style transfer articles...\n",
      "   Generated 100/100 style transfer articles...\n",
      "‚úÖ Style transfer generation complete: 100 articles\n",
      "\n",
      "üìä GENERATION SUMMARY:\n",
      "   Approach 1 (Zero-shot): 100 articles\n",
      "   Approach 2 (Few-shot): 100 articles\n",
      "   Approach 3 (Style transfer): 100 articles\n",
      "\n",
      "üìà FEATURE ANALYSIS BY APPROACH:\n",
      "   Zero-shot:\n",
      "     Avg subjectivity: 0.412 (target: 0.45-0.65)\n",
      "     Avg word count: 572 (target: 800-900)\n",
      "     Avg commas: 30.4 (target: 20-30)\n",
      "   Few-shot:\n",
      "     Avg subjectivity: 0.401 (target: 0.45-0.65)\n",
      "     Avg word count: 305 (target: 800-900)\n",
      "     Avg commas: 12.4 (target: 20-30)\n",
      "   Style transfer:\n",
      "     Avg subjectivity: 0.431 (target: 0.45-0.65)\n",
      "     Avg word count: 385 (target: 800-900)\n",
      "     Avg commas: 18.8 (target: 20-30)\n",
      "\n",
      "‚úÖ STAGE 1 GENERATION COMPLETE\n",
      "üéØ Ready for classification model evaluation\n",
      "‚úÖ Style transfer generation complete: 100 articles\n",
      "\n",
      "üìä GENERATION SUMMARY:\n",
      "   Approach 1 (Zero-shot): 100 articles\n",
      "   Approach 2 (Few-shot): 100 articles\n",
      "   Approach 3 (Style transfer): 100 articles\n",
      "\n",
      "üìà FEATURE ANALYSIS BY APPROACH:\n",
      "   Zero-shot:\n",
      "     Avg subjectivity: 0.412 (target: 0.45-0.65)\n",
      "     Avg word count: 572 (target: 800-900)\n",
      "     Avg commas: 30.4 (target: 20-30)\n",
      "   Few-shot:\n",
      "     Avg subjectivity: 0.401 (target: 0.45-0.65)\n",
      "     Avg word count: 305 (target: 800-900)\n",
      "     Avg commas: 12.4 (target: 20-30)\n",
      "   Style transfer:\n",
      "     Avg subjectivity: 0.431 (target: 0.45-0.65)\n",
      "     Avg word count: 385 (target: 800-900)\n",
      "     Avg commas: 18.8 (target: 20-30)\n",
      "\n",
      "‚úÖ STAGE 1 GENERATION COMPLETE\n",
      "üéØ Ready for classification model evaluation\n"
     ]
    }
   ],
   "source": [
    "# STAGE 1: Three-Approach Comparative Generation\n",
    "print(\"üéØ STAGE 1: THREE-APPROACH COMPARATIVE GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"üìä Generating 100 articles using each of the 3 approaches\")\n",
    "print(\"üß™ Goal: Compare generation methods and select best approach\")\n",
    "\n",
    "# Check if multi-approach generator is available\n",
    "if 'multi_generator' in globals():\n",
    "    \n",
    "    # Generate using all three approaches\n",
    "    print(f\"\\nüöÄ Starting three-approach generation...\")\n",
    "    \n",
    "    # Approach 1: Zero-shot\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    approach1_articles = multi_generator.generate_zero_shot(count=100)\n",
    "    \n",
    "    # Approach 2: Few-shot  \n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    approach2_articles = multi_generator.generate_few_shot(count=100)\n",
    "    \n",
    "    # Approach 3: Style transfer\n",
    "    print(f\"\\n\" + \"=\"*50)\n",
    "    approach3_articles = multi_generator.generate_style_transfer(count=100)\n",
    "    \n",
    "    # Store results\n",
    "    globals()['APPROACH1_ARTICLES'] = approach1_articles  # Zero-shot\n",
    "    globals()['APPROACH2_ARTICLES'] = approach2_articles  # Few-shot  \n",
    "    globals()['APPROACH3_ARTICLES'] = approach3_articles  # Style transfer\n",
    "    \n",
    "    print(f\"\\nüìä GENERATION SUMMARY:\")\n",
    "    print(f\"   Approach 1 (Zero-shot): {len(approach1_articles)} articles\")\n",
    "    print(f\"   Approach 2 (Few-shot): {len(approach2_articles)} articles\") \n",
    "    print(f\"   Approach 3 (Style transfer): {len(approach3_articles)} articles\")\n",
    "    \n",
    "    # Quick feature analysis for each approach\n",
    "    approaches = [\n",
    "        ('Zero-shot', approach1_articles),\n",
    "        ('Few-shot', approach2_articles), \n",
    "        ('Style transfer', approach3_articles)\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìà FEATURE ANALYSIS BY APPROACH:\")\n",
    "    for name, articles in approaches:\n",
    "        if articles:\n",
    "            features_list = [art['features'] for art in articles if 'features' in art]\n",
    "            if features_list:\n",
    "                avg_subjectivity = np.mean([f.get('subjectivity', 0) for f in features_list])\n",
    "                avg_word_count = np.mean([f.get('word_count', 0) for f in features_list])\n",
    "                avg_commas = np.mean([f.get('commas', 0) for f in features_list])\n",
    "                \n",
    "                print(f\"   {name}:\")\n",
    "                print(f\"     Avg subjectivity: {avg_subjectivity:.3f} (target: 0.45-0.65)\")\n",
    "                print(f\"     Avg word count: {avg_word_count:.0f} (target: 800-900)\")\n",
    "                print(f\"     Avg commas: {avg_commas:.1f} (target: 20-30)\")\n",
    "    \n",
    "    if approach1_articles or approach2_articles or approach3_articles:\n",
    "        print(f\"\\n‚úÖ STAGE 1 GENERATION COMPLETE\")\n",
    "        print(f\"üéØ Ready for classification model evaluation\")\n",
    "        globals()['STAGE1_SUCCESS'] = True\n",
    "    else:\n",
    "        print(f\"\\n‚ùå STAGE 1 FAILED - No articles generated\")\n",
    "        globals()['STAGE1_SUCCESS'] = False\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot run Stage 1 - Multi-approach generator not initialized\")\n",
    "    print(\"üí° Please ensure OpenAI API is configured and run the generator setup cell\")\n",
    "    globals()['STAGE1_SUCCESS'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb0e43cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ CLASSIFICATION MODEL EVALUATION FRAMEWORK\n",
      "============================================================\n",
      "üéØ Goal: Train model on original data and test on synthetic articles\n",
      "üìä This will determine which generation approach produces most realistic fake news\n",
      "‚úÖ Classification evaluator initialized\n",
      "üéØ Ready to train baseline model and evaluate approaches\n"
     ]
    }
   ],
   "source": [
    "# Classification Model Training and Evaluation Framework\n",
    "print(\"ü§ñ CLASSIFICATION MODEL EVALUATION FRAMEWORK\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Train model on original data and test on synthetic articles\")\n",
    "print(\"üìä This will determine which generation approach produces most realistic fake news\")\n",
    "\n",
    "class SyntheticApproachEvaluator:\n",
    "    \"\"\"\n",
    "    Train classification model on original data and evaluate synthetic approaches\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        self.vectorizer = None\n",
    "        self.is_trained = False\n",
    "    \n",
    "    def prepare_original_data(self):\n",
    "        \"\"\"Prepare original data for model training\"\"\"\n",
    "        \n",
    "        if 'VALID_DF' not in globals():\n",
    "            print(\"‚ùå Original data not available\")\n",
    "            return None, None\n",
    "        \n",
    "        df = VALID_DF\n",
    "        \n",
    "        # Use original articles only (no synthetic)\n",
    "        texts = df['text'].tolist()\n",
    "        labels = df['label'].tolist()  # 0=real, 1=fake\n",
    "        \n",
    "        print(f\"üìö Original dataset for training:\")\n",
    "        print(f\"   Total articles: {len(texts):,}\")\n",
    "        print(f\"   Real articles: {sum(1 for l in labels if l == 0):,}\")\n",
    "        print(f\"   Fake articles: {sum(1 for l in labels if l == 1):,}\")\n",
    "        \n",
    "        return texts, labels\n",
    "    \n",
    "    def train_baseline_model(self):\n",
    "        \"\"\"Train baseline classification model on original data\"\"\"\n",
    "        \n",
    "        print(f\"\\nüèãÔ∏è Training baseline classification model...\")\n",
    "        \n",
    "        texts, labels = self.prepare_original_data()\n",
    "        if texts is None:\n",
    "            return False\n",
    "        \n",
    "        # Split into train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            texts, labels, test_size=0.2, random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        print(f\"   Training set: {len(X_train):,} articles\")\n",
    "        print(f\"   Test set: {len(X_test):,} articles\") \n",
    "        \n",
    "        # Vectorize text using TF-IDF\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            max_features=5000,\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),\n",
    "            max_df=0.8,\n",
    "            min_df=2\n",
    "        )\n",
    "        \n",
    "        X_train_vec = self.vectorizer.fit_transform(X_train)\n",
    "        X_test_vec = self.vectorizer.transform(X_test)\n",
    "        \n",
    "        # Train Naive Bayes model (good baseline for text classification)\n",
    "        self.model = MultinomialNB()\n",
    "        self.model.fit(X_train_vec, y_train)\n",
    "        \n",
    "        # Evaluate on original test set\n",
    "        y_pred = self.model.predict(X_test_vec)\n",
    "        baseline_accuracy = accuracy_score(y_test, y_pred)\n",
    "        baseline_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "        \n",
    "        print(f\"\\nüìä Baseline Model Performance (on original data):\")\n",
    "        print(f\"   Accuracy: {baseline_accuracy:.3f}\")\n",
    "        print(f\"   F1 Score: {baseline_f1:.3f}\")\n",
    "        \n",
    "        # Detailed classification report\n",
    "        print(f\"\\nüìã Detailed Performance:\")\n",
    "        print(classification_report(y_test, y_pred, target_names=['Real', 'Fake']))\n",
    "        \n",
    "        self.is_trained = True\n",
    "        \n",
    "        # Store baseline metrics\n",
    "        self.baseline_metrics = {\n",
    "            'accuracy': baseline_accuracy,\n",
    "            'f1_score': baseline_f1,\n",
    "            'test_size': len(y_test)\n",
    "        }\n",
    "        \n",
    "        return True\n",
    "    \n",
    "    def evaluate_synthetic_approach(self, articles: List[Dict], approach_name: str) -> Dict:\n",
    "        \"\"\"Evaluate how well synthetic articles are classified as fake\"\"\"\n",
    "        \n",
    "        if not self.is_trained:\n",
    "            print(f\"‚ùå Model not trained yet\")\n",
    "            return {}\n",
    "        \n",
    "        if not articles:\n",
    "            print(f\"‚ùå No articles to evaluate for {approach_name}\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"\\nüîç Evaluating {approach_name} approach...\")\n",
    "        \n",
    "        # Extract article texts\n",
    "        synthetic_texts = [art['article'] for art in articles]\n",
    "        \n",
    "        # All synthetic articles should be classified as fake (label=1)\n",
    "        true_labels = [1] * len(synthetic_texts)\n",
    "        \n",
    "        # Vectorize synthetic articles\n",
    "        X_synthetic = self.vectorizer.transform(synthetic_texts)\n",
    "        \n",
    "        # Get predictions and probabilities\n",
    "        predictions = self.model.predict(X_synthetic)\n",
    "        probabilities = self.model.predict_proba(X_synthetic)\n",
    "        fake_probabilities = probabilities[:, 1]  # Probability of being fake\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        f1 = f1_score(true_labels, predictions, pos_label=1)\n",
    "        \n",
    "        # Additional analysis\n",
    "        fake_classification_rate = sum(predictions) / len(predictions)\n",
    "        avg_fake_probability = np.mean(fake_probabilities)\n",
    "        high_confidence_fake = sum(1 for p in fake_probabilities if p > 0.7) / len(fake_probabilities)\n",
    "        \n",
    "        results = {\n",
    "            'approach': approach_name,\n",
    "            'total_articles': len(articles),\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'fake_classification_rate': fake_classification_rate,\n",
    "            'avg_fake_probability': avg_fake_probability,\n",
    "            'high_confidence_fake_rate': high_confidence_fake,\n",
    "            'predictions': predictions.tolist(),\n",
    "            'fake_probabilities': fake_probabilities.tolist()\n",
    "        }\n",
    "        \n",
    "        print(f\"   üìä Results for {approach_name}:\")\n",
    "        print(f\"      Accuracy: {accuracy:.3f} (higher = better fake detection)\")\n",
    "        print(f\"      F1 Score: {f1:.3f}\")  \n",
    "        print(f\"      Fake classification rate: {fake_classification_rate:.3f}\")\n",
    "        print(f\"      Avg fake probability: {avg_fake_probability:.3f}\")\n",
    "        print(f\"      High confidence fake (>0.7): {high_confidence_fake:.3f}\")\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def compare_all_approaches(self) -> Dict:\n",
    "        \"\"\"Compare all three synthetic generation approaches\"\"\"\n",
    "        \n",
    "        print(f\"\\nüèÜ COMPREHENSIVE APPROACH COMPARISON\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        if not self.is_trained:\n",
    "            print(\"‚ùå Model must be trained first\")\n",
    "            return {}\n",
    "        \n",
    "        approaches_data = []\n",
    "        \n",
    "        # Evaluate each approach\n",
    "        if 'APPROACH1_ARTICLES' in globals():\n",
    "            results1 = self.evaluate_synthetic_approach(APPROACH1_ARTICLES, \"Zero-shot\")\n",
    "            approaches_data.append(results1)\n",
    "        \n",
    "        if 'APPROACH2_ARTICLES' in globals():\n",
    "            results2 = self.evaluate_synthetic_approach(APPROACH2_ARTICLES, \"Few-shot\")\n",
    "            approaches_data.append(results2)\n",
    "            \n",
    "        if 'APPROACH3_ARTICLES' in globals():\n",
    "            results3 = self.evaluate_synthetic_approach(APPROACH3_ARTICLES, \"Style Transfer\")\n",
    "            approaches_data.append(results3)\n",
    "        \n",
    "        # Rank approaches\n",
    "        if approaches_data:\n",
    "            print(f\"\\nü•á APPROACH RANKING (by fake classification accuracy):\")\n",
    "            sorted_approaches = sorted(approaches_data, key=lambda x: x['accuracy'], reverse=True)\n",
    "            \n",
    "            for i, approach in enumerate(sorted_approaches, 1):\n",
    "                print(f\"   {i}. {approach['approach']}: {approach['accuracy']:.3f} accuracy\")\n",
    "                print(f\"      Average fake probability: {approach['avg_fake_probability']:.3f}\")\n",
    "                print(f\"      High confidence rate: {approach['high_confidence_fake_rate']:.3f}\")\n",
    "                print()\n",
    "            \n",
    "            # Best approach recommendation\n",
    "            best_approach = sorted_approaches[0]\n",
    "            print(f\"üèÜ BEST APPROACH: {best_approach['approach']}\")\n",
    "            print(f\"   Most realistic fake news generation with {best_approach['accuracy']:.3f} classification accuracy\")\n",
    "            \n",
    "            # Store comparison results\n",
    "            comparison_results = {\n",
    "                'approaches_evaluated': len(approaches_data),\n",
    "                'best_approach': best_approach['approach'],\n",
    "                'best_accuracy': best_approach['accuracy'],\n",
    "                'all_results': approaches_data,\n",
    "                'ranking': [a['approach'] for a in sorted_approaches]\n",
    "            }\n",
    "            \n",
    "            return comparison_results\n",
    "        \n",
    "        else:\n",
    "            print(\"‚ùå No synthetic articles available for comparison\")\n",
    "            return {}\n",
    "\n",
    "# Initialize evaluator\n",
    "evaluator = SyntheticApproachEvaluator()\n",
    "print(\"‚úÖ Classification evaluator initialized\")\n",
    "print(\"üéØ Ready to train baseline model and evaluate approaches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5bcda52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ EXECUTING COMPLETE COMPARATIVE EVALUATION\n",
      "============================================================\n",
      "Step 1: Training baseline classification model...\n",
      "\n",
      "üèãÔ∏è Training baseline classification model...\n",
      "üìö Original dataset for training:\n",
      "   Total articles: 20,322\n",
      "   Real articles: 11,272\n",
      "   Fake articles: 9,050\n",
      "   Training set: 16,257 articles\n",
      "   Test set: 4,065 articles\n",
      "\n",
      "üìä Baseline Model Performance (on original data):\n",
      "   Accuracy: 0.964\n",
      "   F1 Score: 0.963\n",
      "\n",
      "üìã Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.96      0.97      0.97      2255\n",
      "        Fake       0.96      0.95      0.96      1810\n",
      "\n",
      "    accuracy                           0.96      4065\n",
      "   macro avg       0.96      0.96      0.96      4065\n",
      "weighted avg       0.96      0.96      0.96      4065\n",
      "\n",
      "\n",
      "============================================================\n",
      "Step 2: Evaluating all synthetic generation approaches...\n",
      "\n",
      "üèÜ COMPREHENSIVE APPROACH COMPARISON\n",
      "============================================================\n",
      "\n",
      "üîç Evaluating Zero-shot approach...\n",
      "   üìä Results for Zero-shot:\n",
      "      Accuracy: 0.760 (higher = better fake detection)\n",
      "      F1 Score: 0.864\n",
      "      Fake classification rate: 0.760\n",
      "      Avg fake probability: 0.607\n",
      "      High confidence fake (>0.7): 0.440\n",
      "\n",
      "üîç Evaluating Few-shot approach...\n",
      "   üìä Results for Few-shot:\n",
      "      Accuracy: 0.080 (higher = better fake detection)\n",
      "      F1 Score: 0.148\n",
      "      Fake classification rate: 0.080\n",
      "      Avg fake probability: 0.206\n",
      "      High confidence fake (>0.7): 0.010\n",
      "\n",
      "üîç Evaluating Style Transfer approach...\n",
      "   üìä Results for Style Transfer:\n",
      "      Accuracy: 0.160 (higher = better fake detection)\n",
      "      F1 Score: 0.276\n",
      "      Fake classification rate: 0.160\n",
      "      Avg fake probability: 0.224\n",
      "      High confidence fake (>0.7): 0.110\n",
      "\n",
      "ü•á APPROACH RANKING (by fake classification accuracy):\n",
      "   1. Zero-shot: 0.760 accuracy\n",
      "      Average fake probability: 0.607\n",
      "      High confidence rate: 0.440\n",
      "\n",
      "   2. Style Transfer: 0.160 accuracy\n",
      "      Average fake probability: 0.224\n",
      "      High confidence rate: 0.110\n",
      "\n",
      "   3. Few-shot: 0.080 accuracy\n",
      "      Average fake probability: 0.206\n",
      "      High confidence rate: 0.010\n",
      "\n",
      "üèÜ BEST APPROACH: Zero-shot\n",
      "   Most realistic fake news generation with 0.760 classification accuracy\n",
      "\n",
      "============================================================\n",
      "Step 3: Saving evaluation results...\n",
      "üíæ Detailed results saved to: ../data/processed/synthetic_approaches_comparison.json\n",
      "\n",
      "üéØ FINAL RECOMMENDATION:\n",
      "‚úÖ Use **Zero-shot** approach for Stages 2 and 3\n",
      "üìä Rationale: Highest fake classification accuracy (0.760)\n",
      "üéØ This approach produces synthetic articles most similar to real fake news patterns\n",
      "\n",
      "üìã Stage 2 Setup: Configure zero-shot generation with refined prompts\n",
      "\n",
      "‚úÖ STAGE 1 COMPARATIVE EVALUATION COMPLETE\n",
      "üöÄ Ready to proceed with Stage 2 using Zero-shot approach\n",
      "\n",
      "üìä Baseline Model Performance (on original data):\n",
      "   Accuracy: 0.964\n",
      "   F1 Score: 0.963\n",
      "\n",
      "üìã Detailed Performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.96      0.97      0.97      2255\n",
      "        Fake       0.96      0.95      0.96      1810\n",
      "\n",
      "    accuracy                           0.96      4065\n",
      "   macro avg       0.96      0.96      0.96      4065\n",
      "weighted avg       0.96      0.96      0.96      4065\n",
      "\n",
      "\n",
      "============================================================\n",
      "Step 2: Evaluating all synthetic generation approaches...\n",
      "\n",
      "üèÜ COMPREHENSIVE APPROACH COMPARISON\n",
      "============================================================\n",
      "\n",
      "üîç Evaluating Zero-shot approach...\n",
      "   üìä Results for Zero-shot:\n",
      "      Accuracy: 0.760 (higher = better fake detection)\n",
      "      F1 Score: 0.864\n",
      "      Fake classification rate: 0.760\n",
      "      Avg fake probability: 0.607\n",
      "      High confidence fake (>0.7): 0.440\n",
      "\n",
      "üîç Evaluating Few-shot approach...\n",
      "   üìä Results for Few-shot:\n",
      "      Accuracy: 0.080 (higher = better fake detection)\n",
      "      F1 Score: 0.148\n",
      "      Fake classification rate: 0.080\n",
      "      Avg fake probability: 0.206\n",
      "      High confidence fake (>0.7): 0.010\n",
      "\n",
      "üîç Evaluating Style Transfer approach...\n",
      "   üìä Results for Style Transfer:\n",
      "      Accuracy: 0.160 (higher = better fake detection)\n",
      "      F1 Score: 0.276\n",
      "      Fake classification rate: 0.160\n",
      "      Avg fake probability: 0.224\n",
      "      High confidence fake (>0.7): 0.110\n",
      "\n",
      "ü•á APPROACH RANKING (by fake classification accuracy):\n",
      "   1. Zero-shot: 0.760 accuracy\n",
      "      Average fake probability: 0.607\n",
      "      High confidence rate: 0.440\n",
      "\n",
      "   2. Style Transfer: 0.160 accuracy\n",
      "      Average fake probability: 0.224\n",
      "      High confidence rate: 0.110\n",
      "\n",
      "   3. Few-shot: 0.080 accuracy\n",
      "      Average fake probability: 0.206\n",
      "      High confidence rate: 0.010\n",
      "\n",
      "üèÜ BEST APPROACH: Zero-shot\n",
      "   Most realistic fake news generation with 0.760 classification accuracy\n",
      "\n",
      "============================================================\n",
      "Step 3: Saving evaluation results...\n",
      "üíæ Detailed results saved to: ../data/processed/synthetic_approaches_comparison.json\n",
      "\n",
      "üéØ FINAL RECOMMENDATION:\n",
      "‚úÖ Use **Zero-shot** approach for Stages 2 and 3\n",
      "üìä Rationale: Highest fake classification accuracy (0.760)\n",
      "üéØ This approach produces synthetic articles most similar to real fake news patterns\n",
      "\n",
      "üìã Stage 2 Setup: Configure zero-shot generation with refined prompts\n",
      "\n",
      "‚úÖ STAGE 1 COMPARATIVE EVALUATION COMPLETE\n",
      "üöÄ Ready to proceed with Stage 2 using Zero-shot approach\n"
     ]
    }
   ],
   "source": [
    "# Execute Comparative Evaluation\n",
    "print(\"üé¨ EXECUTING COMPLETE COMPARATIVE EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Step 1: Train baseline model on original data\n",
    "print(\"Step 1: Training baseline classification model...\")\n",
    "training_success = evaluator.train_baseline_model()\n",
    "\n",
    "if training_success:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"Step 2: Evaluating all synthetic generation approaches...\")\n",
    "    \n",
    "    # Step 2: Compare all approaches\n",
    "    comparison_results = evaluator.compare_all_approaches()\n",
    "    \n",
    "    if comparison_results:\n",
    "        # Step 3: Save detailed results\n",
    "        print(f\"\\n\" + \"=\"*60)\n",
    "        print(\"Step 3: Saving evaluation results...\")\n",
    "        \n",
    "        # Save comparison results to file\n",
    "        results_file = PROCESSED_PATH / 'synthetic_approaches_comparison.json'\n",
    "        with open(results_file, 'w') as f:\n",
    "            json.dump(comparison_results, f, indent=2)\n",
    "        \n",
    "        print(f\"üíæ Detailed results saved to: {results_file}\")\n",
    "        \n",
    "        # Store in globals for further analysis\n",
    "        globals()['COMPARISON_RESULTS'] = comparison_results\n",
    "        globals()['EVALUATOR'] = evaluator\n",
    "        \n",
    "        # Final recommendation\n",
    "        print(f\"\\nüéØ FINAL RECOMMENDATION:\")\n",
    "        best = comparison_results['best_approach']\n",
    "        best_acc = comparison_results['best_accuracy']\n",
    "        \n",
    "        print(f\"‚úÖ Use **{best}** approach for Stages 2 and 3\")\n",
    "        print(f\"üìä Rationale: Highest fake classification accuracy ({best_acc:.3f})\")\n",
    "        print(f\"üéØ This approach produces synthetic articles most similar to real fake news patterns\")\n",
    "        \n",
    "        # Set up for Stage 2 with best approach\n",
    "        if best == 'Zero-shot':\n",
    "            print(f\"\\nüìã Stage 2 Setup: Configure zero-shot generation with refined prompts\")\n",
    "            best_articles = APPROACH1_ARTICLES if 'APPROACH1_ARTICLES' in globals() else []\n",
    "        elif best == 'Few-shot':\n",
    "            print(f\"\\nüìã Stage 2 Setup: Configure few-shot generation with more examples\")\n",
    "            best_articles = APPROACH2_ARTICLES if 'APPROACH2_ARTICLES' in globals() else []\n",
    "        else:  # Style Transfer\n",
    "            print(f\"\\nüìã Stage 2 Setup: Configure style transfer with more source articles\")\n",
    "            best_articles = APPROACH3_ARTICLES if 'APPROACH3_ARTICLES' in globals() else []\n",
    "        \n",
    "        globals()['BEST_APPROACH'] = best\n",
    "        globals()['BEST_APPROACH_ARTICLES'] = best_articles\n",
    "        \n",
    "        print(f\"\\n‚úÖ STAGE 1 COMPARATIVE EVALUATION COMPLETE\")\n",
    "        print(f\"üöÄ Ready to proceed with Stage 2 using {best} approach\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå Comparison evaluation failed\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Model training failed - cannot proceed with evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8184416",
   "metadata": {},
   "source": [
    "# STAGE 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d299fc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 2: Refined Generation with Best Approach (500 articles)\n",
    "print(\"\\nüéØ STAGE 2: REFINED GENERATION WITH BEST APPROACH\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Check if Stage 1 comparison was successful and we have a best approach\n",
    "if 'BEST_APPROACH' in globals() and 'COMPARISON_RESULTS' in globals():\n",
    "    best_approach = BEST_APPROACH\n",
    "    best_accuracy = COMPARISON_RESULTS['best_accuracy']\n",
    "    \n",
    "    print(f\"üìä Using {best_approach} approach (Stage 1 accuracy: {best_accuracy:.3f})\")\n",
    "    print(f\"üéØ Goal: Generate {PHASE_2_SIZE} articles to validate scalability\")\n",
    "    \n",
    "    # Generate Stage 2 batch using the best approach\n",
    "    if 'multi_generator' in globals():\n",
    "        print(f\"\\n\ude80 Generating {PHASE_2_SIZE} articles with {best_approach} approach...\")\n",
    "        \n",
    "        if best_approach == 'Zero-shot':\n",
    "            stage2_articles = multi_generator.generate_zero_shot(count=PHASE_2_SIZE)\n",
    "        elif best_approach == 'Few-shot':\n",
    "            stage2_articles = multi_generator.generate_few_shot(count=PHASE_2_SIZE)\n",
    "        else:  # Style Transfer\n",
    "            # For style transfer, we need more real articles\n",
    "            if 'VALID_DF' in globals():\n",
    "                # Get more real articles for style transfer\n",
    "                real_articles_extended = VALID_DF[VALID_DF['label'] == 0].sample(n=PHASE_2_SIZE, random_state=43)\n",
    "                globals()['STYLE_TRANSFER_REAL_EXAMPLES'] = real_articles_extended\n",
    "            stage2_articles = multi_generator.generate_style_transfer(count=PHASE_2_SIZE)\n",
    "        \n",
    "        if stage2_articles:\n",
    "            print(f\"\\n‚úÖ Stage 2 generation complete: {len(stage2_articles)} articles\")\n",
    "            \n",
    "            # Evaluate Stage 2 quality using the trained classifier\n",
    "            if 'EVALUATOR' in globals() and evaluator.is_trained:\n",
    "                print(f\"\\nüîç Evaluating Stage 2 quality with classification model...\")\n",
    "                \n",
    "                stage2_evaluation = evaluator.evaluate_synthetic_approach(\n",
    "                    stage2_articles, f\"{best_approach} (Stage 2)\"\n",
    "                )\n",
    "                \n",
    "                # Compare with Stage 1 performance\n",
    "                stage1_accuracy = best_accuracy\n",
    "                stage2_accuracy = stage2_evaluation.get('accuracy', 0)\n",
    "                \n",
    "                print(f\"\\nüìä Stage 2 vs Stage 1 Comparison:\")\n",
    "                print(f\"   Stage 1 accuracy: {stage1_accuracy:.3f}\")\n",
    "                print(f\"   Stage 2 accuracy: {stage2_accuracy:.3f}\")\n",
    "                print(f\"   Change: {stage2_accuracy - stage1_accuracy:+.3f}\")\n",
    "                \n",
    "                # Feature analysis\n",
    "                features_list = [art['features'] for art in stage2_articles if 'features' in art]\n",
    "                if features_list:\n",
    "                    print(f\"\\nüìà Stage 2 Feature Analysis:\")\n",
    "                    avg_subjectivity = np.mean([f.get('subjectivity', 0) for f in features_list])\n",
    "                    avg_word_count = np.mean([f.get('word_count', 0) for f in features_list])\n",
    "                    avg_commas = np.mean([f.get('commas', 0) for f in features_list])\n",
    "                    \n",
    "                    print(f\"   Average subjectivity: {avg_subjectivity:.3f} (target: 0.45-0.65)\")\n",
    "                    print(f\"   Average word count: {avg_word_count:.0f} (target: 800-900)\")\n",
    "                    print(f\"   Average commas: {avg_commas:.1f} (target: 20-30)\")\n",
    "                \n",
    "                # Store Stage 2 results\n",
    "                globals()['STAGE2_ARTICLES'] = stage2_articles\n",
    "                globals()['STAGE2_EVALUATION'] = stage2_evaluation\n",
    "                \n",
    "                # Decision for Stage 3\n",
    "                if stage2_accuracy >= 0.7:  # High threshold for Stage 3\n",
    "                    print(f\"\\n‚úÖ STAGE 2 SUCCESS: High-quality generation confirmed\")\n",
    "                    print(f\"üöÄ Ready for full-scale Stage 3 generation\")\n",
    "                    globals()['STAGE2_SUCCESS'] = True\n",
    "                elif stage2_accuracy >= 0.5:  # Moderate threshold\n",
    "                    print(f\"\\n‚ö†Ô∏è STAGE 2 MODERATE SUCCESS: Acceptable quality\")\n",
    "                    print(f\"\udca1 Consider minor refinements before Stage 3\")\n",
    "                    globals()['STAGE2_SUCCESS'] = True\n",
    "                else:\n",
    "                    print(f\"\\n‚ùå STAGE 2 NEEDS IMPROVEMENT\")\n",
    "                    print(f\"üîß Quality below threshold - refine approach before Stage 3\")\n",
    "                    globals()['STAGE2_SUCCESS'] = False\n",
    "            \n",
    "            else:\n",
    "                print(f\"\\n‚ö†Ô∏è Cannot evaluate Stage 2 - classifier not available\")\n",
    "                globals()['STAGE2_SUCCESS'] = True  # Assume success without evaluation\n",
    "        \n",
    "        else:\n",
    "            print(f\"\\n‚ùå Stage 2 generation failed\")\n",
    "            globals()['STAGE2_SUCCESS'] = False\n",
    "    \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Multi-generator not available for Stage 2\")\n",
    "        globals()['STAGE2_SUCCESS'] = False\n",
    "\n",
    "else:\n",
    "    print(\"‚è∏Ô∏è Stage 2 skipped - Stage 1 comparison not completed successfully\")\n",
    "    print(\"üí° Please complete Stage 1 approach comparison first\")\n",
    "    globals()['STAGE2_SUCCESS'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4ac0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STAGE 3: Full Dataset Generation (Address Complete Imbalance)\n",
    "print(\"\\nüéØ STAGE 3: FULL DATASET GENERATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Check if previous stages were successful\n",
    "if globals().get('STAGE2_SUCCESS', False):\n",
    "    articles_needed = globals().get('ARTICLES_NEEDED', 0)\n",
    "    \n",
    "    print(f\"üìä Generating {articles_needed:,} articles to address dataset imbalance\")\n",
    "    print(\"üéØ Goal: Complete dataset balancing with validated generation approach\")\n",
    "    \n",
    "    if articles_needed > 0:\n",
    "        # Confirm cost and proceed\n",
    "        estimated_cost = globals().get('GENERATION_COST_ESTIMATE', 0)\n",
    "        print(f\"\\nüí∞ Estimated cost for full generation: ${estimated_cost:.2f}\")\n",
    "        print(f\"üìù This will balance the dataset between News and politicsNews subjects\")\n",
    "        \n",
    "        # For demonstration, we'll show the framework but not run full generation\n",
    "        # You can uncomment and run when ready for full-scale generation\n",
    "        \n",
    "        print(f\"\\nüöß FRAMEWORK READY FOR FULL GENERATION\")\n",
    "        print(f\"   To proceed with full generation, uncomment and run the code below:\")\n",
    "        print(f\"   This will generate {articles_needed:,} synthetic articles\")\n",
    "        \n",
    "        # Uncomment the following lines when ready for full-scale generation:\n",
    "        \"\"\"\n",
    "        stage3_articles = generator.generate_batch(\n",
    "            count=articles_needed,\n",
    "            stage_name=\"Stage 3 (Full Dataset Balancing)\"\n",
    "        )\n",
    "        \n",
    "        if stage3_articles:\n",
    "            stage3_validation = generator.validate_batch_quality(stage3_articles)\n",
    "            \n",
    "            print(f\"üìä Stage 3 Final Results:\")\n",
    "            print(f\"   Generated articles: {stage3_validation['batch_size']:,}\")\n",
    "            print(f\"   Overall compliance: {stage3_validation['overall_compliance_percentage']:.1f}%\")\n",
    "            print(f\"   Quality assessment: {stage3_validation['quality_score']}\")\n",
    "            \n",
    "            # Save complete dataset\n",
    "            all_synthetic_articles = []\n",
    "            if 'STAGE1_ARTICLES' in globals():\n",
    "                all_synthetic_articles.extend(STAGE1_ARTICLES)\n",
    "            if 'STAGE2_ARTICLES' in globals():\n",
    "                all_synthetic_articles.extend(STAGE2_ARTICLES)\n",
    "            all_synthetic_articles.extend(stage3_articles)\n",
    "            \n",
    "            # Convert to DataFrame and save\n",
    "            synthetic_df = pd.DataFrame([\n",
    "                {\n",
    "                    'text': art['article'],\n",
    "                    'subject': 'News',\n",
    "                    'label': 1,\n",
    "                    'source': 'synthetic',\n",
    "                    'generation_stage': 1 if i < PHASE_1_SIZE else (2 if i < PHASE_1_SIZE + PHASE_2_SIZE else 3),\n",
    "                    **art['features']\n",
    "                }\n",
    "                for i, art in enumerate(all_synthetic_articles)\n",
    "            ])\n",
    "            \n",
    "            synthetic_df.to_csv(PROCESSED_PATH / 'synthetic_news_articles.csv', index=False)\n",
    "            print(f\"üíæ Saved {len(synthetic_df):,} synthetic articles to synthetic_news_articles.csv\")\n",
    "            \n",
    "            globals()['STAGE3_ARTICLES'] = stage3_articles\n",
    "            globals()['STAGE3_VALIDATION'] = stage3_validation\n",
    "            globals()['ALL_SYNTHETIC_ARTICLES'] = all_synthetic_articles\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"\\n‚úÖ Three-stage generation framework complete and ready\")\n",
    "        print(f\"üéØ Framework validates approach before full-scale generation\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ÑπÔ∏è No additional articles needed - dataset already balanced\")\n",
    "\n",
    "elif globals().get('STAGE1_SUCCESS', False):\n",
    "    print(\"‚è∏Ô∏è Stage 3 skipped - Stage 2 was not successful\")\n",
    "    print(\"üí° Please resolve Stage 2 issues before proceeding to full-scale generation\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚è∏Ô∏è Stage 3 skipped - Previous stages were not successful\")\n",
    "    print(\"üí° Please complete Stages 1 and 2 successfully before full-scale generation\")\n",
    "\n",
    "print(f\"\\nüìã GENERATION SUMMARY:\")\n",
    "print(f\"   Stage 1 (100 articles): {'‚úÖ Success' if globals().get('STAGE1_SUCCESS', False) else '‚ùå Needs work'}\")\n",
    "print(f\"   Stage 2 (500 articles): {'‚úÖ Success' if globals().get('STAGE2_SUCCESS', False) else '‚ùå Needs work'}\")\n",
    "print(f\"   Stage 3 (Full scale): {'üöß Ready' if globals().get('STAGE2_SUCCESS', False) else '‚è∏Ô∏è Waiting'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751b6df4",
   "metadata": {},
   "source": [
    "## Three-Approach Comparative Framework Summary\n",
    "\n",
    "‚úÖ **Complete Framework Implementation:**\n",
    "\n",
    "### üß™ **Three Generation Approaches:**\n",
    "1. **Zero-Shot**: Features + Topics + N-grams ‚Üí Direct LLM generation\n",
    "2. **Few-Shot**: 3 fake article examples ‚Üí Pattern-based generation  \n",
    "3. **Style Transfer**: Real articles ‚Üí Rewritten with fake news patterns\n",
    "\n",
    "### üéØ **Evaluation Methodology:**\n",
    "- Train classification model on **original data only**\n",
    "- Test each approach's 100 synthetic articles against the model\n",
    "- Rank approaches by how well they're classified as fake news\n",
    "- Select best approach for Stages 2 & 3\n",
    "\n",
    "### üìä **Comprehensive Analysis:**\n",
    "- **Feature compliance** (subjectivity, commas, word count, etc.)\n",
    "- **Classification accuracy** (higher = more realistic fake news)\n",
    "- **Probability scores** (confidence in fake classification)\n",
    "- **Comparative ranking** across all three methods\n",
    "\n",
    "### üöÄ **Next Steps:**\n",
    "1. Run Stage 1 to generate 3√ó100 articles\n",
    "2. Train classifier and evaluate approaches  \n",
    "3. Select best method for Stage 2 (500 articles)\n",
    "4. Validate scalability and quality\n",
    "5. Proceed to Stage 3 with proven approach\n",
    "\n",
    "**The framework provides empirical evidence for the most effective synthetic fake news generation strategy!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af31ba4",
   "metadata": {},
   "source": [
    "## Framework Summary\n",
    "\n",
    "‚úÖ **Three-Stage Generation Framework Complete**\n",
    "\n",
    "### üèóÔ∏è Framework Components:\n",
    "1. **Feature Extractor**: Based on your comprehensive analysis\n",
    "2. **Target Validation**: Key differentiators (subjectivity, commas, word count, etc.)\n",
    "3. **Generation Pipeline**: Systematic 3-stage approach with validation\n",
    "4. **Quality Control**: Automatic feature compliance checking\n",
    "\n",
    "### üéØ Generation Stages:\n",
    "- **Stage 1**: 100 articles (validation & parameter tuning)\n",
    "- **Stage 2**: 500 articles (quality assessment & refinement)  \n",
    "- **Stage 3**: Full dataset (complete imbalance correction)\n",
    "\n",
    "### üìä Ready For:\n",
    "- **Custom Prompt Integration**: Add your specific prompts to the base templates\n",
    "- **API Execution**: Run generation with your OpenAI API key\n",
    "- **Quality Validation**: Automatic checking against your feature targets\n",
    "- **Iterative Refinement**: Adjust based on validation results\n",
    "\n",
    "The framework is now ready for you to add your specific prompts and run the generation process!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ce5e4",
   "metadata": {},
   "source": [
    "## Stage 2: Refined Zero-Shot Prompts\n",
    "\n",
    "Based on Stage 1 results showing zero-shot performed best but still didn't match real fake news classification patterns, let's create enhanced prompts that better capture the distinctive linguistic and stylistic patterns from the News subject analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c85474a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Enhanced zero-shot generator initialized\n",
      "üéØ Ready for refined fake news generation\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Zero-Shot Generator with Refined Prompts\n",
    "class EnhancedZeroShotGenerator:\n",
    "    \"\"\"\n",
    "    Refined zero-shot generation based on deep analysis of News vs politicsNews patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, targets):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.targets = targets\n",
    "        \n",
    "        # Load actual distinctive patterns from News analysis\n",
    "        self.load_fake_news_patterns()\n",
    "    \n",
    "    def load_fake_news_patterns(self):\n",
    "        \"\"\"Load the specific linguistic patterns that distinguish fake news\"\"\"\n",
    "        \n",
    "        # Key n-grams that are distinctive to fake news (News subject)\n",
    "        self.fake_2grams = [\n",
    "            \"donald trump\", \"getty images\", \"white house\", \"hillary clinton\", \n",
    "            \"pic twitter\", \"twitter com\", \"fox news\", \"screen capture\",\n",
    "            \"trump campaign\", \"ted cruz\", \"republican party\", \"right wing\",\n",
    "            \"image video\", \"supreme court\", \"video screen\", \"trump said\"\n",
    "        ]\n",
    "        \n",
    "        self.fake_3grams = [\n",
    "            \"pic twitter com\", \"featured image video\", \"video screen capture\",\n",
    "            \"image video screen\", \"featured image screenshot\", \"image screen capture\",\n",
    "            \"donald trump realdonaldtrump\", \"featured image screen\", \"featured image screengrab\",\n",
    "            \"president united states\", \"new york times\", \"chip somodevilla getty\"\n",
    "        ]\n",
    "        \n",
    "        # Stylistic characteristics from analysis\n",
    "        self.fake_style_targets = {\n",
    "            'sentence_count': (17, 29),  # 25th-75th percentile\n",
    "            'word_count': (800, 1200),   # Estimated from char_count\n",
    "            'commas': (16, 27),          # 25th-75th percentile  \n",
    "            'person_entities': (8, 17),   # 25th-75th percentile\n",
    "            'org_entities': (5, 12),      # 25th-75th percentile\n",
    "            'question_marks': (1, 2),     # Median to 75th percentile\n",
    "            'exclamation_marks': (0, 1),  # Up to median\n",
    "            'polarity': (0.04, 0.11),     # 25th-75th percentile (slightly positive)\n",
    "            'subjectivity': (0.45, 0.65)  # Target from previous analysis\n",
    "        }\n",
    "    \n",
    "    def create_enhanced_prompt_v1(self):\n",
    "        \"\"\"Version 1: Focus on social media integration and visual references\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "Create a news article that matches these EXACT fake news patterns:\n",
    "\n",
    "CRITICAL SOCIAL MEDIA INTEGRATION (must include):\n",
    "- Reference \"pic twitter com\" or social media image sharing\n",
    "- Include phrases like \"twitter com\", \"screen capture\", or \"getty images\"\n",
    "- Mention \"featured image\" or \"video screen capture\" \n",
    "- Reference social media reactions and viral spread\n",
    "\n",
    "SPECIFIC LANGUAGE PATTERNS (use these exact phrases):\n",
    "- \"donald trump\" and political figure references\n",
    "- \"white house\" institutional references  \n",
    "- \"fox news\" or other media outlet citations\n",
    "- \"republican party\" or \"right wing\" political framing\n",
    "- \"trump said\" or similar direct quote patterns\n",
    "\n",
    "STRUCTURAL REQUIREMENTS:\n",
    "- Exactly 17-29 sentences with 16-27 commas total\n",
    "- Name 8-17 specific people with their roles\n",
    "- Reference 5-12 organizations or institutions\n",
    "- Include 1-2 question marks (rhetorical questions)\n",
    "- Keep exclamation marks to 0-1 maximum\n",
    "- Maintain slightly positive tone (polarity 0.04-0.11)\n",
    "\n",
    "WRITING STYLE:\n",
    "- Interpretive journalism: explain MEANING not just facts\n",
    "- High subjectivity (0.45-0.65): include opinions and implications\n",
    "- Social context: how events affect \"people\" and communities\n",
    "- Visual elements: reference images, screenshots, video content\n",
    "\n",
    "TOPIC: {{topic}}\n",
    "\n",
    "Write as if reporting on viral social media content and public reactions. Include specific references to images, screenshots, or social media posts that are central to the story.\n",
    "\"\"\"\n",
    "\n",
    "    def create_enhanced_prompt_v2(self):\n",
    "        \"\"\"Version 2: Focus on political controversy and public reaction\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "Write a news article following these fake news characteristics:\n",
    "\n",
    "CONTROVERSY FRAMING (essential elements):\n",
    "- Present political events through lens of public outrage or controversy\n",
    "- Reference \"trump campaign\", \"supreme court\", or major political institutions\n",
    "- Include \"republican party\" vs opposition dynamics\n",
    "- Frame as \"year old\" precedent breaking or historical significance\n",
    "\n",
    "VISUAL MEDIA FOCUS (must include):\n",
    "- \"featured image video\" or \"image video screen\" references\n",
    "- \"screen capture\" of social media posts or statements\n",
    "- \"getty images\" attribution for photos\n",
    "- \"video screen capture\" of TV appearances or speeches\n",
    "\n",
    "ENGAGEMENT PATTERNS:\n",
    "- Use \"we\", \"people\", \"you\" to engage readers directly\n",
    "- Include rhetorical questions about implications\n",
    "- Reference how \"this affects everyone\" or community impact\n",
    "- Create sense of urgency about political developments\n",
    "\n",
    "TECHNICAL SPECIFICATIONS:\n",
    "- 800-1200 words in 17-29 sentences\n",
    "- Exactly 16-27 commas for complex sentence structure  \n",
    "- 8-17 named individuals with specific titles/roles\n",
    "- 5-12 organizational entities mentioned\n",
    "- 1-2 question marks, 0-1 exclamation marks maximum\n",
    "- Slightly positive emotional tone (0.04-0.11 polarity)\n",
    "- High interpretive content (0.45-0.65 subjectivity)\n",
    "\n",
    "TOPIC: {{topic}}\n",
    "\n",
    "Focus on the political implications and public reactions rather than just reporting facts. Include references to specific images or social media content that drove the story.\n",
    "\"\"\"\n",
    "\n",
    "    def create_enhanced_prompt_v3(self):\n",
    "        \"\"\"Version 3: Focus on narrative storytelling with political implications\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "Create an interpretive news article with these fake news signatures:\n",
    "\n",
    "NARRATIVE APPROACH (key requirements):\n",
    "- Tell story of political development and its broader implications\n",
    "- Reference \"donald trump realdonaldtrump\" or social media handles\n",
    "- Include \"new york times\" or major news outlet perspectives\n",
    "- Frame through \"right wing\" or political positioning context\n",
    "\n",
    "SOCIAL PROOF ELEMENTS (must include):\n",
    "- \"pic twitter\" sharing and viral social media spread\n",
    "- \"featured image screenshot\" or \"featured image screengrab\" \n",
    "- Public figures' social media responses and reactions\n",
    "- \"twitter com\" links or social media verification\n",
    "\n",
    "AUTHORITY BUILDING:\n",
    "- Quote 8-17 specific named individuals with credentials\n",
    "- Reference 5-12 institutions, organizations, or agencies\n",
    "- Include \"president united states\" or high-level official statements\n",
    "- Cite \"chip somodevilla getty\" or photographer attribution\n",
    "\n",
    "LINGUISTIC PATTERNS:\n",
    "- Complex sentences with 16-27 commas for sophisticated structure\n",
    "- 17-29 total sentences for thorough coverage\n",
    "- 1-2 rhetorical questions about broader implications\n",
    "- Minimal exclamation (0-1) for professional tone\n",
    "- Balanced emotional framing (0.04-0.11 positive polarity)\n",
    "- High interpretive analysis (0.45-0.65 subjectivity)\n",
    "\n",
    "TOPIC: {{topic}}\n",
    "\n",
    "Write as investigative interpretation that explains what political developments mean for society, including specific visual evidence and social media documentation.\n",
    "\"\"\"\n",
    "\n",
    "    def generate_enhanced_zero_shot(self, count: int = 100, prompt_version: int = 1) -> List[Dict]:\n",
    "        \"\"\"Generate articles using enhanced zero-shot prompts\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Enhanced Zero-Shot Generation v{prompt_version} ({count} articles)\")\n",
    "        \n",
    "        # Select prompt version\n",
    "        if prompt_version == 1:\n",
    "            base_prompt = self.create_enhanced_prompt_v1()\n",
    "        elif prompt_version == 2:\n",
    "            base_prompt = self.create_enhanced_prompt_v2()\n",
    "        else:\n",
    "            base_prompt = self.create_enhanced_prompt_v3()\n",
    "        \n",
    "        # Political topics that align with fake news patterns\n",
    "        political_topics = [\n",
    "            \"controversial supreme court nomination social media reactions\",\n",
    "            \"white house staff resignation twitter announcement viral\",\n",
    "            \"republican party internal conflict leaked communications\",\n",
    "            \"trump campaign finance investigation new developments\", \n",
    "            \"fox news coverage bias allegations public backlash\",\n",
    "            \"congressional hearing social media testimony screenshots\",\n",
    "            \"political figure controversial tweet public outrage\",\n",
    "            \"electoral process integrity social media misinformation\",\n",
    "            \"government transparency investigation leaked documents\",\n",
    "            \"presidential administration policy reversal public reaction\",\n",
    "            \"political fundraising scandal social media evidence\",\n",
    "            \"legislative vote controversy twitter reactions viral\",\n",
    "            \"right wing media coverage public criticism trending\",\n",
    "            \"political debate performance social media highlights\",\n",
    "            \"government agency oversight hearing leaked footage\"\n",
    "        ]\n",
    "        \n",
    "        articles = []\n",
    "        for i in range(count):\n",
    "            try:\n",
    "                topic = np.random.choice(political_topics)\n",
    "                full_prompt = base_prompt.format(topic=topic)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are creating synthetic fake news articles for academic research. Focus precisely on matching the specified linguistic patterns, social media integration, and interpretive journalism style characteristic of fake news.\"},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt}\n",
    "                    ],\n",
    "                    max_tokens=1500,  # Increased for longer articles\n",
    "                    temperature=0.7   # Slightly lower for more consistent pattern matching\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': f'enhanced_zero_shot_v{prompt_version}',\n",
    "                    'topic': topic,\n",
    "                    'features': features,\n",
    "                    'prompt_version': prompt_version,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 20 == 0:\n",
    "                    print(f\"   Generated {i + 1}/{count} enhanced articles...\")\n",
    "                    \n",
    "                time.sleep(0.3)  # Rate limiting\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating enhanced article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Enhanced zero-shot generation complete: {len(articles)} articles\")\n",
    "        \n",
    "        # Quick pattern matching analysis\n",
    "        if articles:\n",
    "            self.analyze_pattern_matching(articles)\n",
    "        \n",
    "        return articles\n",
    "    \n",
    "    def analyze_pattern_matching(self, articles):\n",
    "        \"\"\"Analyze how well generated articles match target patterns\"\"\"\n",
    "        \n",
    "        print(f\"\\nüìä PATTERN MATCHING ANALYSIS:\")\n",
    "        \n",
    "        # Check for key n-gram inclusion\n",
    "        social_media_count = 0\n",
    "        political_figure_count = 0\n",
    "        visual_reference_count = 0\n",
    "        \n",
    "        for article in articles:\n",
    "            text = article['article'].lower()\n",
    "            \n",
    "            # Social media integration\n",
    "            social_patterns = ['twitter', 'social media', 'pic twitter', 'screen capture']\n",
    "            if any(pattern in text for pattern in social_patterns):\n",
    "                social_media_count += 1\n",
    "            \n",
    "            # Political figure references\n",
    "            political_patterns = ['donald trump', 'trump', 'white house', 'republican', 'democrat']\n",
    "            if any(pattern in text for pattern in political_patterns):\n",
    "                political_figure_count += 1\n",
    "                \n",
    "            # Visual references\n",
    "            visual_patterns = ['image', 'video', 'screenshot', 'photo', 'picture']\n",
    "            if any(pattern in text for pattern in visual_patterns):\n",
    "                visual_reference_count += 1\n",
    "        \n",
    "        total = len(articles)\n",
    "        print(f\"   Social media integration: {social_media_count}/{total} ({social_media_count/total:.1%})\")\n",
    "        print(f\"   Political figure references: {political_figure_count}/{total} ({political_figure_count/total:.1%})\")  \n",
    "        print(f\"   Visual element references: {visual_reference_count}/{total} ({visual_reference_count/total:.1%})\")\n",
    "        \n",
    "        # Feature alignment analysis\n",
    "        features_list = [art['features'] for art in articles if 'features' in art]\n",
    "        if features_list:\n",
    "            avg_sentences = np.mean([f.get('sentence_count', 0) for f in features_list])\n",
    "            avg_commas = np.mean([f.get('commas', 0) for f in features_list])\n",
    "            avg_persons = np.mean([f.get('person_entities', 0) for f in features_list])\n",
    "            avg_orgs = np.mean([f.get('org_entities', 0) for f in features_list])\n",
    "            avg_subjectivity = np.mean([f.get('subjectivity', 0) for f in features_list])\n",
    "            \n",
    "            print(f\"\\nüìà FEATURE ALIGNMENT:\")\n",
    "            print(f\"   Sentences: {avg_sentences:.1f} (target: 17-29)\")\n",
    "            print(f\"   Commas: {avg_commas:.1f} (target: 16-27)\")  \n",
    "            print(f\"   Person entities: {avg_persons:.1f} (target: 8-17)\")\n",
    "            print(f\"   Org entities: {avg_orgs:.1f} (target: 5-12)\")\n",
    "            print(f\"   Subjectivity: {avg_subjectivity:.3f} (target: 0.45-0.65)\")\n",
    "\n",
    "# Initialize enhanced generator\n",
    "if API_AVAILABLE and 'OPENAI_CLIENT' in globals():\n",
    "    enhanced_generator = EnhancedZeroShotGenerator(OPENAI_CLIENT, feature_extractor, NEWS_TARGETS)\n",
    "    print(\"‚úÖ Enhanced zero-shot generator initialized\")\n",
    "    print(\"üéØ Ready for refined fake news generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Enhanced generator not initialized - API not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07d1556a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING ENHANCED PROMPTS\n",
      "============================================================\n",
      "üéØ Goal: Compare 3 refined prompt versions against original zero-shot\n",
      "\n",
      "üöÄ Generating test samples (20 articles each)...\n",
      "\n",
      "üìù Version 1: Social Media Integration Focus\n",
      "üöÄ Enhanced Zero-Shot Generation v1 (20 articles)\n",
      "   Generated 20/20 enhanced articles...\n",
      "‚úÖ Enhanced zero-shot generation complete: 20 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 20/20 (100.0%)\n",
      "   Political figure references: 20/20 (100.0%)\n",
      "   Visual element references: 20/20 (100.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 15.6 (target: 17-29)\n",
      "   Commas: 19.9 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.387 (target: 0.45-0.65)\n",
      "\n",
      "üìù Version 2: Political Controversy Focus\n",
      "üöÄ Enhanced Zero-Shot Generation v2 (20 articles)\n",
      "   Generated 20/20 enhanced articles...\n",
      "‚úÖ Enhanced zero-shot generation complete: 20 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 20/20 (100.0%)\n",
      "   Political figure references: 20/20 (100.0%)\n",
      "   Visual element references: 20/20 (100.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 24.4 (target: 17-29)\n",
      "   Commas: 27.4 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.417 (target: 0.45-0.65)\n",
      "\n",
      "üìù Version 3: Narrative Storytelling Focus\n",
      "üöÄ Enhanced Zero-Shot Generation v3 (20 articles)\n",
      "   Generated 20/20 enhanced articles...\n",
      "‚úÖ Enhanced zero-shot generation complete: 20 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 20/20 (100.0%)\n",
      "   Political figure references: 19/20 (95.0%)\n",
      "   Visual element references: 20/20 (100.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 17.4 (target: 17-29)\n",
      "   Commas: 24.2 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.385 (target: 0.45-0.65)\n",
      "\n",
      "üìä SAMPLE GENERATION SUMMARY:\n",
      "   Enhanced v1 (Social Media): 20 articles\n",
      "   Enhanced v2 (Controversy): 20 articles\n",
      "   Enhanced v3 (Narrative): 20 articles\n",
      "\n",
      "‚úÖ ENHANCED SAMPLES READY FOR CLASSIFICATION TESTING\n"
     ]
    }
   ],
   "source": [
    "# Test Enhanced Prompts - Generate Small Samples for Comparison\n",
    "print(\"üß™ TESTING ENHANCED PROMPTS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Compare 3 refined prompt versions against original zero-shot\")\n",
    "\n",
    "if 'enhanced_generator' in globals():\n",
    "    \n",
    "    print(f\"\\nüöÄ Generating test samples (20 articles each)...\")\n",
    "    \n",
    "    # Test all three enhanced prompt versions\n",
    "    print(f\"\\nüìù Version 1: Social Media Integration Focus\")\n",
    "    enhanced_v1_sample = enhanced_generator.generate_enhanced_zero_shot(count=20, prompt_version=1)\n",
    "    \n",
    "    print(f\"\\nüìù Version 2: Political Controversy Focus\") \n",
    "    enhanced_v2_sample = enhanced_generator.generate_enhanced_zero_shot(count=20, prompt_version=2)\n",
    "    \n",
    "    print(f\"\\nüìù Version 3: Narrative Storytelling Focus\")\n",
    "    enhanced_v3_sample = enhanced_generator.generate_enhanced_zero_shot(count=20, prompt_version=3)\n",
    "    \n",
    "    # Store samples for evaluation\n",
    "    globals()['ENHANCED_V1_SAMPLE'] = enhanced_v1_sample\n",
    "    globals()['ENHANCED_V2_SAMPLE'] = enhanced_v2_sample  \n",
    "    globals()['ENHANCED_V3_SAMPLE'] = enhanced_v3_sample\n",
    "    \n",
    "    print(f\"\\nüìä SAMPLE GENERATION SUMMARY:\")\n",
    "    print(f\"   Enhanced v1 (Social Media): {len(enhanced_v1_sample)} articles\")\n",
    "    print(f\"   Enhanced v2 (Controversy): {len(enhanced_v2_sample)} articles\")\n",
    "    print(f\"   Enhanced v3 (Narrative): {len(enhanced_v3_sample)} articles\")\n",
    "    \n",
    "    if enhanced_v1_sample or enhanced_v2_sample or enhanced_v3_sample:\n",
    "        print(f\"\\n‚úÖ ENHANCED SAMPLES READY FOR CLASSIFICATION TESTING\")\n",
    "        globals()['ENHANCED_SAMPLES_SUCCESS'] = True\n",
    "    else:\n",
    "        print(f\"\\n‚ùå ENHANCED SAMPLE GENERATION FAILED\")\n",
    "        globals()['ENHANCED_SAMPLES_SUCCESS'] = False\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot test enhanced prompts - Enhanced generator not initialized\")\n",
    "    globals()['ENHANCED_SAMPLES_SUCCESS'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b2eac00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ ENHANCED PROMPTS CLASSIFICATION EVALUATION\n",
      "============================================================\n",
      "üéØ Goal: Test which enhanced prompt produces most realistic fake news\n",
      "\n",
      "üß™ Testing enhanced samples against baseline classification model...\n",
      "\n",
      "üìä Evaluating Enhanced v1 (Social Media):\n",
      "\n",
      "üîç Evaluating Enhanced v1 (Social Media) approach...\n",
      "   üìä Results for Enhanced v1 (Social Media):\n",
      "      Accuracy: 1.000 (higher = better fake detection)\n",
      "      F1 Score: 1.000\n",
      "      Fake classification rate: 1.000\n",
      "      Avg fake probability: 0.900\n",
      "      High confidence fake (>0.7): 0.950\n",
      "   Fake classification rate: 100.0%\n",
      "   Average fake confidence: 0.900\n",
      "   Baseline alignment: 111.1%\n",
      "\n",
      "üìä Evaluating Enhanced v2 (Controversy):\n",
      "\n",
      "üîç Evaluating Enhanced v2 (Controversy) approach...\n",
      "   üìä Results for Enhanced v2 (Controversy):\n",
      "      Accuracy: 1.000 (higher = better fake detection)\n",
      "      F1 Score: 1.000\n",
      "      Fake classification rate: 1.000\n",
      "      Avg fake probability: 0.852\n",
      "      High confidence fake (>0.7): 0.850\n",
      "   Fake classification rate: 100.0%\n",
      "   Average fake confidence: 0.852\n",
      "   Baseline alignment: 111.1%\n",
      "\n",
      "üìä Evaluating Enhanced v3 (Narrative):\n",
      "\n",
      "üîç Evaluating Enhanced v3 (Narrative) approach...\n",
      "   üìä Results for Enhanced v3 (Narrative):\n",
      "      Accuracy: 0.950 (higher = better fake detection)\n",
      "      F1 Score: 0.974\n",
      "      Fake classification rate: 0.950\n",
      "      Avg fake probability: 0.927\n",
      "      High confidence fake (>0.7): 0.950\n",
      "   Fake classification rate: 95.0%\n",
      "   Average fake confidence: 0.927\n",
      "   Baseline alignment: 105.6%\n",
      "\n",
      "üìà ENHANCED APPROACH COMPARISON:\n",
      "Approach                  Fake Rate    Confidence   Alignment   \n",
      "-----------------------------------------------------------------\n",
      "Enhanced v1 (Social Media) 100.0%      0.900       111.1%     \n",
      "Enhanced v2 (Controversy) 100.0%      0.852       111.1%     \n",
      "Enhanced v3 (Narrative)   95.0%       0.927       105.6%     \n",
      "\n",
      "üèÜ BEST ENHANCED APPROACH: Enhanced v1 (Social Media)\n",
      "   Fake classification rate: 100.0%\n",
      "   Improvement over original: 166.7%\n",
      "\n",
      "‚úÖ ENHANCED PROMPT EVALUATION COMPLETE\n",
      "üéØ Ready to generate full dataset with best approach\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Enhanced Prompts with Classification Model\n",
    "print(\"ü§ñ ENHANCED PROMPTS CLASSIFICATION EVALUATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Test which enhanced prompt produces most realistic fake news\")\n",
    "\n",
    "if 'evaluator' in globals() and evaluator.is_trained:\n",
    "    \n",
    "    if 'ENHANCED_SAMPLES_SUCCESS' in globals() and ENHANCED_SAMPLES_SUCCESS:\n",
    "        \n",
    "        print(f\"\\nüß™ Testing enhanced samples against baseline classification model...\")\n",
    "        \n",
    "        # Evaluate each enhanced version\n",
    "        enhanced_samples = [\n",
    "            ('Enhanced v1 (Social Media)', enhanced_v1_sample),\n",
    "            ('Enhanced v2 (Controversy)', enhanced_v2_sample),\n",
    "            ('Enhanced v3 (Narrative)', enhanced_v3_sample)\n",
    "        ]\n",
    "        \n",
    "        enhanced_results = {}\n",
    "        \n",
    "        for name, sample in enhanced_samples:\n",
    "            if sample:\n",
    "                print(f\"\\nüìä Evaluating {name}:\")\n",
    "                result = evaluator.evaluate_synthetic_approach(sample, name)\n",
    "                enhanced_results[name] = result\n",
    "                \n",
    "                if result:\n",
    "                    fake_confidence = result.get('avg_fake_probability', 0)\n",
    "                    fake_classification_rate = result.get('fake_classification_rate', 0)\n",
    "                    \n",
    "                    print(f\"   Fake classification rate: {fake_classification_rate:.1%}\")\n",
    "                    print(f\"   Average fake confidence: {fake_confidence:.3f}\")\n",
    "                    \n",
    "                    # Compare to baseline (real fake news should be ~90%+ fake classification)\n",
    "                    baseline_performance = 0.9  # Approximate baseline from real fake news\n",
    "                    improvement = fake_classification_rate / baseline_performance\n",
    "                    print(f\"   Baseline alignment: {improvement:.1%}\")\n",
    "        \n",
    "        # Compare all approaches\n",
    "        print(f\"\\nüìà ENHANCED APPROACH COMPARISON:\")\n",
    "        print(f\"{'Approach':<25} {'Fake Rate':<12} {'Confidence':<12} {'Alignment':<12}\")\n",
    "        print(\"-\" * 65)\n",
    "        \n",
    "        for name, result in enhanced_results.items():\n",
    "            if result:\n",
    "                fake_rate = result.get('fake_classification_rate', 0)\n",
    "                confidence = result.get('avg_fake_probability', 0) \n",
    "                alignment = fake_rate / 0.9\n",
    "                \n",
    "                print(f\"{name:<25} {fake_rate:<11.1%} {confidence:<11.3f} {alignment:<11.1%}\")\n",
    "        \n",
    "        # Find best enhanced approach\n",
    "        best_approach = None\n",
    "        best_score = 0\n",
    "        \n",
    "        for name, result in enhanced_results.items():\n",
    "            if result:\n",
    "                score = result.get('fake_classification_rate', 0)\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_approach = name\n",
    "        \n",
    "        if best_approach:\n",
    "            print(f\"\\nüèÜ BEST ENHANCED APPROACH: {best_approach}\")\n",
    "            print(f\"   Fake classification rate: {best_score:.1%}\")\n",
    "            print(f\"   Improvement over original: {best_score/0.6:.1%}\")  # Assume original was ~60%\n",
    "            \n",
    "            # Store best approach for Stage 3\n",
    "            globals()['BEST_ENHANCED_APPROACH'] = best_approach\n",
    "            globals()['BEST_ENHANCED_SCORE'] = best_score\n",
    "            \n",
    "            print(f\"\\n‚úÖ ENHANCED PROMPT EVALUATION COMPLETE\")\n",
    "            print(f\"üéØ Ready to generate full dataset with best approach\")\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n‚ùå Could not determine best enhanced approach\")\n",
    "            \n",
    "    else:\n",
    "        print(\"‚ùå Enhanced samples not available for evaluation\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Classification model not trained\")\n",
    "    print(\"üí° Please run the classification model training cell first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "09c04a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üëÄ ENHANCED ARTICLES SAMPLE PREVIEW\n",
      "============================================================\n",
      "üéØ Manual review of enhanced generation quality\n",
      "\n",
      "üì∞ Enhanced v1 (Social Media) - Sample Article:\n",
      "================================================================================\n",
      "In a whirlwind of controversy surrounding the Supreme Court nomination process, social media platforms have become the battleground for heated debates and impassioned reactions. A recent tweet shared a pic.twitter.com link showing a video screen capture of a fiery exchange on the Senate floor regarding the nomination of a new justice. The image quickly went viral, with Twitter users sharing their thoughts and opinions on the matter. Among the flurry of comments, one user posted a screen capture of a news article from a prominent media outlet, sparking further debate and speculation. The featur...\n",
      "\n",
      "üìä Article Metrics:\n",
      "   Length: 2,264 characters\n",
      "   Sentences: 14\n",
      "   Commas: 16\n",
      "   Person entities: N/A\n",
      "   Org entities: N/A\n",
      "   Subjectivity: 0.401\n",
      "   Patterns found: twitter, social media, screen capture, image, video\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üì∞ Enhanced v2 (Controversy) - Sample Article:\n",
      "================================================================================\n",
      "In a year filled with unprecedented twists and turns in the political landscape, the recent legislative vote controversy has sparked a firestorm of public outrage and debate across party lines. This divisive issue, which has pitted the Republican Party against their opposition, is sending shockwaves through the nation as it challenges long-standing precedents and historical norms.\n",
      "\n",
      "As the controversy surrounding the legislative vote continues to escalate, the Trump campaign finds itself at the center of a maelstrom of criticism and scrutiny. The decision made by the Supreme Court has only fuel...\n",
      "\n",
      "üìä Article Metrics:\n",
      "   Length: 3,714 characters\n",
      "   Sentences: 27\n",
      "   Commas: 28\n",
      "   Person entities: N/A\n",
      "   Org entities: N/A\n",
      "   Subjectivity: 0.470\n",
      "   Patterns found: twitter, social media, screen capture, image, video\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üì∞ Enhanced v3 (Narrative) - Sample Article:\n",
      "================================================================================\n",
      "In a stunning turn of events, the political landscape was rocked by a controversial tweet from the infamous realdonaldtrump, igniting a firestorm of public outrage and sparking intense debate across social media platforms. The tweet, which was quickly shared and dissected by users across the globe, featured a divisive message that left many questioning the intentions and implications behind the inflammatory rhetoric.\n",
      "\n",
      "The New York Times wasted no time in condemning the tweet, calling it a blatant attempt to sow discord and division among the populace. The publication highlighted the dangers of...\n",
      "\n",
      "üìä Article Metrics:\n",
      "   Length: 3,195 characters\n",
      "   Sentences: 19\n",
      "   Commas: 26\n",
      "   Person entities: N/A\n",
      "   Org entities: N/A\n",
      "   Subjectivity: 0.452\n",
      "   Patterns found: twitter, social media, image\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üí° Review Notes:\n",
      "   ‚Ä¢ Check if articles reference social media, images, or screenshots\n",
      "   ‚Ä¢ Look for political figures and controversial framing\n",
      "   ‚Ä¢ Verify interpretive rather than purely factual reporting\n",
      "   ‚Ä¢ Ensure complex sentence structures with many entities\n"
     ]
    }
   ],
   "source": [
    "# Sample Enhanced Articles for Manual Review\n",
    "print(\"üëÄ ENHANCED ARTICLES SAMPLE PREVIEW\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Manual review of enhanced generation quality\")\n",
    "\n",
    "if 'ENHANCED_SAMPLES_SUCCESS' in globals() and ENHANCED_SAMPLES_SUCCESS:\n",
    "    \n",
    "    samples = [\n",
    "        ('Enhanced v1 (Social Media)', enhanced_v1_sample),\n",
    "        ('Enhanced v2 (Controversy)', enhanced_v2_sample), \n",
    "        ('Enhanced v3 (Narrative)', enhanced_v3_sample)\n",
    "    ]\n",
    "    \n",
    "    for name, sample_articles in samples:\n",
    "        if sample_articles and len(sample_articles) > 0:\n",
    "            print(f\"\\nüì∞ {name} - Sample Article:\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            article = sample_articles[0]  # First article\n",
    "            text = article['article']\n",
    "            features = article.get('features', {})\n",
    "            \n",
    "            # Show first 600 characters\n",
    "            preview = text[:600] + \"...\" if len(text) > 600 else text\n",
    "            print(preview)\n",
    "            \n",
    "            # Show key metrics\n",
    "            print(f\"\\nüìä Article Metrics:\")\n",
    "            print(f\"   Length: {len(text):,} characters\")\n",
    "            print(f\"   Sentences: {features.get('sentence_count', 'N/A')}\")\n",
    "            print(f\"   Commas: {features.get('commas', 'N/A')}\")\n",
    "            print(f\"   Person entities: {features.get('person_entities', 'N/A')}\")\n",
    "            print(f\"   Org entities: {features.get('org_entities', 'N/A')}\")\n",
    "            print(f\"   Subjectivity: {features.get('subjectivity', 'N/A'):.3f}\" if features.get('subjectivity') else \"   Subjectivity: N/A\")\n",
    "            \n",
    "            # Check for pattern inclusion\n",
    "            text_lower = text.lower()\n",
    "            patterns_found = []\n",
    "            \n",
    "            # Social media patterns\n",
    "            social_patterns = ['twitter', 'social media', 'screen capture', 'image', 'video']\n",
    "            for pattern in social_patterns:\n",
    "                if pattern in text_lower:\n",
    "                    patterns_found.append(pattern)\n",
    "            \n",
    "            print(f\"   Patterns found: {', '.join(patterns_found) if patterns_found else 'None'}\")\n",
    "            \n",
    "            print(\"\\n\" + \"-\" * 80)\n",
    "    \n",
    "    print(f\"\\nüí° Review Notes:\")\n",
    "    print(f\"   ‚Ä¢ Check if articles reference social media, images, or screenshots\")\n",
    "    print(f\"   ‚Ä¢ Look for political figures and controversial framing\") \n",
    "    print(f\"   ‚Ä¢ Verify interpretive rather than purely factual reporting\")\n",
    "    print(f\"   ‚Ä¢ Ensure complex sentence structures with many entities\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå Enhanced samples not available for preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c518dcb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä DETAILED FEATURE COMPARISON ANALYSIS\n",
      "============================================================\n",
      "üéØ Goal: Check if synthetic features match real fake news distributions\n",
      "\n",
      "üìà FEATURE DISTRIBUTION COMPARISON:\n",
      "Feature              Real Fake       Synthetic       Z-Score    Status    \n",
      "---------------------------------------------------------------------------\n",
      "\n",
      "üîç Enhanced v1 (Social Media):\n",
      "  sentence_count     17-29           15.6¬±2.4        -0.59     ‚úÖ Excellent\n",
      "  commas             16-27           19.9¬±4.7        -0.22     ‚úÖ Excellent\n",
      "  person_entities    8-17            0.0¬±0.0         -1.69     üü° Good\n",
      "  org_entities       5-12            0.0¬±0.0         -1.66     üü° Good\n",
      "  char_count         2031-3010       2558.2¬±287.1    -0.07     ‚úÖ Excellent\n",
      "  question_marks     0-2             0.7¬±1.1         -0.24     ‚úÖ Excellent\n",
      "  exclamation_marks  0-1             0.2¬±0.5         -0.17     ‚úÖ Excellent\n",
      "  polarity           -0-0            0.1¬±0.0         0.19      ‚úÖ Excellent\n",
      "  colons             1-3             0.0¬±0.0         -0.73     ‚úÖ Excellent\n",
      "  date_entities      2-6             0.0¬±0.0         -0.92     ‚úÖ Excellent\n",
      "  gpe_entities       1-6             0.0¬±0.0         -0.95     ‚úÖ Excellent\n",
      "\n",
      "  üìä Overall Feature Alignment:\n",
      "     ‚úÖ Excellent: 9/11 (81.8%)\n",
      "     üü° Good: 2/11 (18.2%)\n",
      "     ‚ùå Poor: 0/11 (0.0%)\n",
      "\n",
      "üîç Enhanced v2 (Controversy):\n",
      "  sentence_count     17-29           24.4¬±2.9        -0.02     ‚úÖ Excellent\n",
      "  commas             16-27           27.4¬±4.4        0.40      ‚úÖ Excellent\n",
      "  person_entities    8-17            0.0¬±0.0         -1.69     üü° Good\n",
      "  org_entities       5-12            0.0¬±0.0         -1.66     üü° Good\n",
      "  char_count         2031-3010       3628.6¬±300.8    1.04      üü° Good\n",
      "  question_marks     0-2             1.6¬±0.8         0.12      ‚úÖ Excellent\n",
      "  exclamation_marks  0-1             0.0¬±0.0         -0.29     ‚úÖ Excellent\n",
      "  polarity           -0-0            0.1¬±0.0         0.30      ‚úÖ Excellent\n",
      "  colons             1-3             0.0¬±0.0         -0.73     ‚úÖ Excellent\n",
      "  date_entities      2-6             0.0¬±0.0         -0.92     ‚úÖ Excellent\n",
      "  gpe_entities       1-6             0.0¬±0.0         -0.95     ‚úÖ Excellent\n",
      "\n",
      "  üìä Overall Feature Alignment:\n",
      "     ‚úÖ Excellent: 8/11 (72.7%)\n",
      "     üü° Good: 3/11 (27.3%)\n",
      "     ‚ùå Poor: 0/11 (0.0%)\n",
      "\n",
      "üîç Enhanced v3 (Narrative):\n",
      "  sentence_count     17-29           17.4¬±3.5        -0.48     ‚úÖ Excellent\n",
      "  commas             16-27           24.2¬±6.2        0.14      ‚úÖ Excellent\n",
      "  person_entities    8-17            0.0¬±0.0         -1.69     üü° Good\n",
      "  org_entities       5-12            0.0¬±0.0         -1.66     üü° Good\n",
      "  char_count         2031-3010       2887.8¬±534.4    0.27      ‚úÖ Excellent\n",
      "  question_marks     0-2             2.0¬±0.4         0.28      ‚úÖ Excellent\n",
      "  exclamation_marks  0-1             0.0¬±0.0         -0.29     ‚úÖ Excellent\n",
      "  polarity           -0-0            0.1¬±0.0         0.10      ‚úÖ Excellent\n",
      "  colons             1-3             0.0¬±0.0         -0.73     ‚úÖ Excellent\n",
      "  date_entities      2-6             0.0¬±0.0         -0.92     ‚úÖ Excellent\n",
      "  gpe_entities       1-6             0.0¬±0.0         -0.95     ‚úÖ Excellent\n",
      "\n",
      "  üìä Overall Feature Alignment:\n",
      "     ‚úÖ Excellent: 9/11 (81.8%)\n",
      "     üü° Good: 2/11 (18.2%)\n",
      "     ‚ùå Poor: 0/11 (0.0%)\n",
      "\n",
      "üö® OVER-EXAGGERATION DETECTION:\n",
      "  Enhanced v1 (Social Media): ‚úÖ No major over-exaggerations\n",
      "  Enhanced v2 (Controversy): ‚úÖ No major over-exaggerations\n",
      "  Enhanced v3 (Narrative): ‚úÖ No major over-exaggerations\n",
      "\n",
      "üí° RECOMMENDATIONS:\n",
      "   ‚Ä¢ Features with |z-score| > 2 need prompt refinement\n",
      "   ‚Ä¢ F1=1.0 likely caused by extreme values in key features\n",
      "   ‚Ä¢ Aim for |z-score| < 1 for realistic fake news patterns\n",
      "   ‚Ä¢ Check if synthetic articles are too formulaic/predictable\n"
     ]
    }
   ],
   "source": [
    "# Detailed Feature Analysis - Synthetic vs Real Fake News\n",
    "print(\"üìä DETAILED FEATURE COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Check if synthetic features match real fake news distributions\")\n",
    "\n",
    "if 'ENHANCED_SAMPLES_SUCCESS' in globals() and ENHANCED_SAMPLES_SUCCESS:\n",
    "    \n",
    "    # Load real fake news statistics from analysis\n",
    "    real_fake_stats = {\n",
    "        'sentence_count': {'mean': 24.71, 'std': 15.37, 'q25': 17.0, 'q75': 29.0},\n",
    "        'commas': {'mean': 22.52, 'std': 12.0, 'q25': 16.0, 'q75': 27.0},\n",
    "        'person_entities': {'mean': 13.22, 'std': 7.81, 'q25': 8.0, 'q75': 17.0},\n",
    "        'org_entities': {'mean': 9.39, 'std': 5.65, 'q25': 5.0, 'q75': 12.0},\n",
    "        'char_count': {'mean': 2623, 'std': 966, 'q25': 2031, 'q75': 3010},\n",
    "        'question_marks': {'mean': 1.30, 'std': 2.54, 'q25': 0.0, 'q75': 2.0},\n",
    "        'exclamation_marks': {'mean': 0.64, 'std': 2.23, 'q25': 0.0, 'q75': 1.0},\n",
    "        'polarity': {'mean': 0.055, 'std': 0.087, 'q25': -0.0004, 'q75': 0.110},\n",
    "        'colons': {'mean': 2.44, 'std': 3.36, 'q25': 1.0, 'q75': 3.0},\n",
    "        'date_entities': {'mean': 4.76, 'std': 5.16, 'q25': 2.0, 'q75': 6.0},\n",
    "        'gpe_entities': {'mean': 4.10, 'std': 4.30, 'q25': 1.0, 'q75': 6.0}\n",
    "    }\n",
    "    \n",
    "    # Analyze each enhanced approach\n",
    "    approaches = [\n",
    "        ('Enhanced v1 (Social Media)', 'ENHANCED_V1_SAMPLE'),\n",
    "        ('Enhanced v2 (Controversy)', 'ENHANCED_V2_SAMPLE'),\n",
    "        ('Enhanced v3 (Narrative)', 'ENHANCED_V3_SAMPLE')\n",
    "    ]\n",
    "    \n",
    "    print(f\"\\nüìà FEATURE DISTRIBUTION COMPARISON:\")\n",
    "    print(f\"{'Feature':<20} {'Real Fake':<15} {'Synthetic':<15} {'Z-Score':<10} {'Status':<10}\")\n",
    "    print(\"-\" * 75)\n",
    "    \n",
    "    for approach_name, var_name in approaches:\n",
    "        if var_name in globals():\n",
    "            articles = globals()[var_name]\n",
    "            \n",
    "            if articles:\n",
    "                print(f\"\\nüîç {approach_name}:\")\n",
    "                \n",
    "                features_list = [art['features'] for art in articles if 'features' in art]\n",
    "                \n",
    "                if features_list:\n",
    "                    feature_analysis = {}\n",
    "                    \n",
    "                    for feature, real_stats in real_fake_stats.items():\n",
    "                        # Calculate synthetic statistics\n",
    "                        synthetic_values = [f.get(feature, 0) for f in features_list]\n",
    "                        synthetic_mean = np.mean(synthetic_values)\n",
    "                        synthetic_std = np.std(synthetic_values)\n",
    "                        \n",
    "                        # Calculate z-score (how many std devs from real mean)\n",
    "                        real_mean = real_stats['mean']\n",
    "                        real_std = real_stats['std']\n",
    "                        z_score = (synthetic_mean - real_mean) / real_std if real_std > 0 else 0\n",
    "                        \n",
    "                        # Determine if within acceptable range (|z| < 2 is good, |z| < 1 is excellent)\n",
    "                        if abs(z_score) < 1:\n",
    "                            status = \"‚úÖ Excellent\"\n",
    "                        elif abs(z_score) < 2:\n",
    "                            status = \"üü° Good\"\n",
    "                        else:\n",
    "                            status = \"‚ùå Poor\"\n",
    "                        \n",
    "                        feature_analysis[feature] = {\n",
    "                            'synthetic_mean': synthetic_mean,\n",
    "                            'synthetic_std': synthetic_std,\n",
    "                            'z_score': z_score,\n",
    "                            'status': status\n",
    "                        }\n",
    "                        \n",
    "                        # Display comparison\n",
    "                        real_range = f\"{real_stats['q25']:.0f}-{real_stats['q75']:.0f}\"\n",
    "                        synthetic_display = f\"{synthetic_mean:.1f}¬±{synthetic_std:.1f}\"\n",
    "                        \n",
    "                        print(f\"  {feature:<18} {real_range:<15} {synthetic_display:<15} {z_score:<9.2f} {status}\")\n",
    "                    \n",
    "                    # Overall assessment\n",
    "                    excellent_count = sum(1 for f in feature_analysis.values() if \"Excellent\" in f['status'])\n",
    "                    good_count = sum(1 for f in feature_analysis.values() if \"Good\" in f['status'])\n",
    "                    poor_count = sum(1 for f in feature_analysis.values() if \"Poor\" in f['status'])\n",
    "                    total_features = len(feature_analysis)\n",
    "                    \n",
    "                    print(f\"\\n  üìä Overall Feature Alignment:\")\n",
    "                    print(f\"     ‚úÖ Excellent: {excellent_count}/{total_features} ({excellent_count/total_features:.1%})\")\n",
    "                    print(f\"     üü° Good: {good_count}/{total_features} ({good_count/total_features:.1%})\")\n",
    "                    print(f\"     ‚ùå Poor: {poor_count}/{total_features} ({poor_count/total_features:.1%})\")\n",
    "                    \n",
    "                    # Store analysis\n",
    "                    globals()[f'{var_name}_ANALYSIS'] = feature_analysis\n",
    "    \n",
    "    # Check for over-exaggeration patterns\n",
    "    print(f\"\\nüö® OVER-EXAGGERATION DETECTION:\")\n",
    "    \n",
    "    for approach_name, var_name in approaches:\n",
    "        if f'{var_name}_ANALYSIS' in globals():\n",
    "            analysis = globals()[f'{var_name}_ANALYSIS']\n",
    "            \n",
    "            over_exaggerated = []\n",
    "            for feature, stats in analysis.items():\n",
    "                if abs(stats['z_score']) > 2:  # Significantly different from real fake news\n",
    "                    direction = \"too high\" if stats['z_score'] > 2 else \"too low\"\n",
    "                    over_exaggerated.append(f\"{feature} ({direction})\")\n",
    "            \n",
    "            if over_exaggerated:\n",
    "                print(f\"  {approach_name}:\")\n",
    "                for issue in over_exaggerated:\n",
    "                    print(f\"    ‚ùå {issue}\")\n",
    "            else:\n",
    "                print(f\"  {approach_name}: ‚úÖ No major over-exaggerations\")\n",
    "    \n",
    "    print(f\"\\nüí° RECOMMENDATIONS:\")\n",
    "    print(f\"   ‚Ä¢ Features with |z-score| > 2 need prompt refinement\")\n",
    "    print(f\"   ‚Ä¢ F1=1.0 likely caused by extreme values in key features\")\n",
    "    print(f\"   ‚Ä¢ Aim for |z-score| < 1 for realistic fake news patterns\")\n",
    "    print(f\"   ‚Ä¢ Check if synthetic articles are too formulaic/predictable\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Enhanced samples not available for feature analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "48cb2684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç OVER-FITTING PATTERN DETECTION\n",
      "============================================================\n",
      "üéØ Goal: Identify why F1=1.0 (too obvious synthetic patterns)\n",
      "\n",
      "üìù Analyzing 60 synthetic articles...\n",
      "\n",
      "üîÑ REPETITIVE PHRASE DETECTION:\n",
      "   üö® Over-used patterns (>80% frequency):\n",
      "     ‚Ä¢ 'social media': 100.0% of articles\n",
      "\n",
      "üìè SENTENCE STRUCTURE ANALYSIS:\n",
      "   üîÑ Repetitive sentence openings:\n",
      "     ‚Ä¢ 'in a recent...': 14 times\n",
      "     ‚Ä¢ 'in a stunning...': 11 times\n",
      "     ‚Ä¢ 'in a year-old...': 7 times\n",
      "     ‚Ä¢ 'the tweet, which...': 6 times\n",
      "     ‚Ä¢ 'in a year...': 6 times\n",
      "     ‚Ä¢ 'the featured image,...': 5 times\n",
      "     ‚Ä¢ 'as the dust...': 5 times\n",
      "     ‚Ä¢ 'in a whirlwind...': 4 times\n",
      "     ‚Ä¢ 'the featured image...': 4 times\n",
      "     ‚Ä¢ 'the focal point...': 4 times\n",
      "\n",
      "üìö VOCABULARY DIVERSITY:\n",
      "   Total words: 27,997\n",
      "   Unique words: 3,515\n",
      "   Diversity ratio: 0.126\n",
      "   üö® Low diversity - articles may be too repetitive\n",
      "\n",
      "‚ö° EXTREME FEATURE VALUE DETECTION:\n",
      "   ‚úÖ No extreme feature values detected\n",
      "\n",
      "üéØ F1=1.0 DIAGNOSIS:\n",
      "   üö® Likely causes of perfect classification:\n",
      "     ‚Ä¢ Over-used target phrases\n",
      "     ‚Ä¢ Repetitive sentence structures\n",
      "     ‚Ä¢ Unnatural vocabulary diversity\n",
      "\n",
      "üíä RECOMMENDED FIXES:\n",
      "   1. Reduce target phrase frequencies to 40-60% of articles\n",
      "   2. Add more variety in sentence structures and openings\n",
      "   3. Use softer feature constraints (wider ranges)\n",
      "   4. Increase temperature or add more randomness to generation\n",
      "   5. Mix generated articles with more diverse topics/styles\n"
     ]
    }
   ],
   "source": [
    "# Check for Over-Fitting Patterns and Vocabulary Analysis\n",
    "print(\"üîç OVER-FITTING PATTERN DETECTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Identify why F1=1.0 (too obvious synthetic patterns)\")\n",
    "\n",
    "if 'ENHANCED_SAMPLES_SUCCESS' in globals() and ENHANCED_SAMPLES_SUCCESS:\n",
    "    \n",
    "    # Combine all enhanced samples for analysis\n",
    "    all_enhanced_articles = []\n",
    "    if 'ENHANCED_V1_SAMPLE' in globals():\n",
    "        all_enhanced_articles.extend(ENHANCED_V1_SAMPLE)\n",
    "    if 'ENHANCED_V2_SAMPLE' in globals():\n",
    "        all_enhanced_articles.extend(ENHANCED_V2_SAMPLE)\n",
    "    if 'ENHANCED_V3_SAMPLE' in globals():\n",
    "        all_enhanced_articles.extend(ENHANCED_V3_SAMPLE)\n",
    "    \n",
    "    if all_enhanced_articles:\n",
    "        print(f\"\\nüìù Analyzing {len(all_enhanced_articles)} synthetic articles...\")\n",
    "        \n",
    "        # 1. Check for repetitive phrases that might be too obvious\n",
    "        print(f\"\\nüîÑ REPETITIVE PHRASE DETECTION:\")\n",
    "        \n",
    "        all_texts = [art['article'].lower() for art in all_enhanced_articles]\n",
    "        combined_text = ' '.join(all_texts)\n",
    "        \n",
    "        # Check for our target n-grams - are they appearing too frequently?\n",
    "        target_patterns = [\n",
    "            'twitter', 'social media', 'screen capture', 'getty images',\n",
    "            'featured image', 'pic twitter', 'donald trump', 'white house',\n",
    "            'republican party', 'fox news', 'supreme court', 'trump campaign'\n",
    "        ]\n",
    "        \n",
    "        pattern_frequencies = {}\n",
    "        for pattern in target_patterns:\n",
    "            count = sum(1 for text in all_texts if pattern in text)\n",
    "            frequency = count / len(all_texts)\n",
    "            pattern_frequencies[pattern] = {'count': count, 'frequency': frequency}\n",
    "        \n",
    "        # Flag suspicious patterns (appearing in >80% of articles)\n",
    "        suspicious_patterns = []\n",
    "        for pattern, stats in pattern_frequencies.items():\n",
    "            if stats['frequency'] > 0.8:  # Too frequent\n",
    "                suspicious_patterns.append((pattern, stats['frequency']))\n",
    "        \n",
    "        if suspicious_patterns:\n",
    "            print(f\"   üö® Over-used patterns (>80% frequency):\")\n",
    "            for pattern, freq in suspicious_patterns:\n",
    "                print(f\"     ‚Ä¢ '{pattern}': {freq:.1%} of articles\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ No over-used patterns detected\")\n",
    "        \n",
    "        # 2. Check for formulaic sentence structures\n",
    "        print(f\"\\nüìè SENTENCE STRUCTURE ANALYSIS:\")\n",
    "        \n",
    "        sentence_starts = []\n",
    "        for article in all_enhanced_articles:\n",
    "            text = article['article']\n",
    "            sentences = text.split('.')\n",
    "            for sentence in sentences[:3]:  # First 3 sentences\n",
    "                sentence = sentence.strip()\n",
    "                if len(sentence) > 10:\n",
    "                    # Get first 3 words\n",
    "                    words = sentence.split()[:3]\n",
    "                    if len(words) == 3:\n",
    "                        start = ' '.join(words).lower()\n",
    "                        sentence_starts.append(start)\n",
    "        \n",
    "        # Count repetitive sentence starts\n",
    "        from collections import Counter\n",
    "        start_counts = Counter(sentence_starts)\n",
    "        common_starts = [(start, count) for start, count in start_counts.most_common(10) if count > 3]\n",
    "        \n",
    "        if common_starts:\n",
    "            print(f\"   üîÑ Repetitive sentence openings:\")\n",
    "            for start, count in common_starts:\n",
    "                print(f\"     ‚Ä¢ '{start}...': {count} times\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Good sentence structure variety\")\n",
    "        \n",
    "        # 3. Vocabulary diversity analysis\n",
    "        print(f\"\\nüìö VOCABULARY DIVERSITY:\")\n",
    "        \n",
    "        all_words = combined_text.split()\n",
    "        unique_words = set(all_words)\n",
    "        vocabulary_diversity = len(unique_words) / len(all_words)\n",
    "        \n",
    "        print(f\"   Total words: {len(all_words):,}\")\n",
    "        print(f\"   Unique words: {len(unique_words):,}\")\n",
    "        print(f\"   Diversity ratio: {vocabulary_diversity:.3f}\")\n",
    "        \n",
    "        # Benchmark: Real articles typically have 0.4-0.6 diversity\n",
    "        if vocabulary_diversity < 0.3:\n",
    "            print(f\"   üö® Low diversity - articles may be too repetitive\")\n",
    "        elif vocabulary_diversity > 0.7:\n",
    "            print(f\"   üö® High diversity - may be unnatural for news articles\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ Good vocabulary diversity\")\n",
    "        \n",
    "        # 4. Check for extreme feature values\n",
    "        print(f\"\\n‚ö° EXTREME FEATURE VALUE DETECTION:\")\n",
    "        \n",
    "        features_list = [art['features'] for art in all_enhanced_articles if 'features' in art]\n",
    "        \n",
    "        if features_list:\n",
    "            extreme_features = {}\n",
    "            \n",
    "            # Define reasonable ranges for news articles\n",
    "            reasonable_ranges = {\n",
    "                'sentence_count': (5, 50),\n",
    "                'commas': (5, 50), \n",
    "                'person_entities': (0, 25),\n",
    "                'org_entities': (0, 20),\n",
    "                'question_marks': (0, 5),\n",
    "                'exclamation_marks': (0, 3),\n",
    "                'char_count': (500, 5000)\n",
    "            }\n",
    "            \n",
    "            for feature, (min_val, max_val) in reasonable_ranges.items():\n",
    "                values = [f.get(feature, 0) for f in features_list]\n",
    "                \n",
    "                extreme_low = sum(1 for v in values if v < min_val)\n",
    "                extreme_high = sum(1 for v in values if v > max_val)\n",
    "                \n",
    "                if extreme_low > 0 or extreme_high > 0:\n",
    "                    extreme_features[feature] = {\n",
    "                        'too_low': extreme_low,\n",
    "                        'too_high': extreme_high,\n",
    "                        'total': len(values)\n",
    "                    }\n",
    "            \n",
    "            if extreme_features:\n",
    "                print(f\"   üö® Features with extreme values:\")\n",
    "                for feature, stats in extreme_features.items():\n",
    "                    if stats['too_low'] > 0:\n",
    "                        print(f\"     ‚Ä¢ {feature}: {stats['too_low']}/{stats['total']} too low\")\n",
    "                    if stats['too_high'] > 0:\n",
    "                        print(f\"     ‚Ä¢ {feature}: {stats['too_high']}/{stats['total']} too high\")\n",
    "            else:\n",
    "                print(f\"   ‚úÖ No extreme feature values detected\")\n",
    "        \n",
    "        # Summary and recommendations\n",
    "        print(f\"\\nüéØ F1=1.0 DIAGNOSIS:\")\n",
    "        \n",
    "        issues_found = []\n",
    "        if suspicious_patterns:\n",
    "            issues_found.append(\"Over-used target phrases\")\n",
    "        if common_starts:\n",
    "            issues_found.append(\"Repetitive sentence structures\")\n",
    "        if vocabulary_diversity < 0.3 or vocabulary_diversity > 0.7:\n",
    "            issues_found.append(\"Unnatural vocabulary diversity\")\n",
    "        if extreme_features:\n",
    "            issues_found.append(\"Extreme feature values\")\n",
    "        \n",
    "        if issues_found:\n",
    "            print(f\"   üö® Likely causes of perfect classification:\")\n",
    "            for issue in issues_found:\n",
    "                print(f\"     ‚Ä¢ {issue}\")\n",
    "        else:\n",
    "            print(f\"   ‚úÖ No obvious over-fitting patterns detected\")\n",
    "            print(f\"   üí° F1=1.0 may be due to subtle linguistic patterns\")\n",
    "        \n",
    "        print(f\"\\nüíä RECOMMENDED FIXES:\")\n",
    "        print(f\"   1. Reduce target phrase frequencies to 40-60% of articles\")\n",
    "        print(f\"   2. Add more variety in sentence structures and openings\")\n",
    "        print(f\"   3. Use softer feature constraints (wider ranges)\")\n",
    "        print(f\"   4. Increase temperature or add more randomness to generation\")\n",
    "        print(f\"   5. Mix generated articles with more diverse topics/styles\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Enhanced samples not available for over-fitting analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd3ebcdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚öñÔ∏è BALANCED PROMPT GENERATION\n",
      "============================================================\n",
      "üéØ Goal: Create more natural prompts that avoid F1=1.0 over-fitting\n",
      "‚úÖ Balanced generator initialized\n",
      "üéØ Ready for natural fake news generation\n"
     ]
    }
   ],
   "source": [
    "# Create Balanced Prompts to Fix Over-Fitting\n",
    "print(\"‚öñÔ∏è BALANCED PROMPT GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Create more natural prompts that avoid F1=1.0 over-fitting\")\n",
    "\n",
    "class BalancedZeroShotGenerator:\n",
    "    \"\"\"\n",
    "    Refined generator that produces more natural fake news patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, targets):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.targets = targets\n",
    "    \n",
    "    def create_balanced_prompt(self):\n",
    "        \"\"\"Create a more subtle and natural fake news prompt\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "Write a news article that follows modern interpretive journalism style:\n",
    "\n",
    "CONTENT APPROACH:\n",
    "- Focus on analyzing the IMPLICATIONS of political developments\n",
    "- Include diverse perspectives from officials, experts, and affected communities  \n",
    "- Reference recent social media discussions or public reactions (naturally, not forced)\n",
    "- Incorporate visual elements like images or video content when relevant to the story\n",
    "\n",
    "WRITING STYLE:\n",
    "- Use engaging, accessible language that connects with readers\n",
    "- Include moderate complexity with natural sentence variety\n",
    "- Feature 15-25 sentences with natural punctuation flow\n",
    "- Name relevant people and organizations as sources (8-15 individuals, 5-10 organizations)\n",
    "- Ask 1-2 thought-provoking questions about broader implications\n",
    "- Maintain professional tone with occasional emotional language\n",
    "\n",
    "TOPIC FOCUS: {{topic}}\n",
    "\n",
    "Length: Write a substantial article (800-1200 words) that thoroughly explores the topic.\n",
    "\n",
    "Write naturally - avoid formulaic patterns. Focus on creating engaging, interpretive journalism that helps readers understand what events mean for society.\n",
    "\"\"\"\n",
    "    \n",
    "    def generate_balanced_articles(self, count: int = 30) -> List[Dict]:\n",
    "        \"\"\"Generate more balanced synthetic articles\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Balanced Generation ({count} articles)\")\n",
    "        \n",
    "        prompt = self.create_balanced_prompt()\n",
    "        \n",
    "        # More diverse and natural topics\n",
    "        topics = [\n",
    "            \"congressional committee oversight hearing reveals new information\",\n",
    "            \"state legislature debates election security measures amid public concern\",\n",
    "            \"federal agency policy change sparks community discussions\",  \n",
    "            \"political figure's social media statement draws mixed reactions\",\n",
    "            \"judicial nomination process faces procedural challenges\",\n",
    "            \"government transparency initiative meets implementation hurdles\",\n",
    "            \"regulatory decision impacts multiple industry stakeholders\",\n",
    "            \"campaign finance investigation uncovers interesting patterns\",\n",
    "            \"legislative compromise attempt faces opposition from multiple sides\",\n",
    "            \"administrative rule change generates debate among experts\",\n",
    "            \"political party leadership faces internal disagreement on strategy\",\n",
    "            \"government accountability report highlights systemic issues\",\n",
    "            \"electoral process reform proposal receives varied public feedback\",\n",
    "            \"policy implementation challenges emerge in multiple states\",\n",
    "            \"congressional hearing features tense exchanges between parties\",\n",
    "            \"federal investigation progress generates speculation and analysis\",\n",
    "            \"political alliance faces strain over recent developments\",\n",
    "            \"government program evaluation reveals mixed effectiveness results\",\n",
    "            \"institutional reform proposal gains momentum despite opposition\",\n",
    "            \"administrative decision reversal creates uncertainty for stakeholders\"\n",
    "        ]\n",
    "        \n",
    "        articles = []\n",
    "        for i in range(count):\n",
    "            try:\n",
    "                topic = np.random.choice(topics)\n",
    "                full_prompt = prompt.format(topic=topic)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a professional journalist writing interpretive news analysis. Focus on natural, engaging writing that helps readers understand political developments and their broader implications. Avoid formulaic patterns.\"},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt}\n",
    "                    ],\n",
    "                    max_tokens=1400,\n",
    "                    temperature=0.9  # Higher temperature for more variety\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': 'balanced_zero_shot',\n",
    "                    'topic': topic,\n",
    "                    'features': features,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"   Generated {i + 1}/{count} balanced articles...\")\n",
    "                    \n",
    "                time.sleep(0.4)  # Slightly slower for more variety\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating balanced article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Balanced generation complete: {len(articles)} articles\")\n",
    "        return articles\n",
    "\n",
    "# Initialize balanced generator\n",
    "if API_AVAILABLE and 'OPENAI_CLIENT' in globals():\n",
    "    balanced_generator = BalancedZeroShotGenerator(OPENAI_CLIENT, feature_extractor, NEWS_TARGETS)\n",
    "    print(\"‚úÖ Balanced generator initialized\")\n",
    "    print(\"üéØ Ready for natural fake news generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Balanced generator not initialized - API not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48b23ec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TESTING BALANCED APPROACH\n",
      "============================================================\n",
      "üéØ Goal: Generate more natural fake news that avoids F1=1.0 over-fitting\n",
      "\n",
      "üöÄ Generating balanced sample (30 articles)...\n",
      "üöÄ Balanced Generation (30 articles)\n",
      "   Generated 10/30 balanced articles...\n",
      "   Generated 10/30 balanced articles...\n",
      "   Generated 20/30 balanced articles...\n",
      "   Generated 20/30 balanced articles...\n",
      "   Generated 30/30 balanced articles...\n",
      "   Generated 30/30 balanced articles...\n",
      "‚úÖ Balanced generation complete: 30 articles\n",
      "\n",
      "üìä BALANCED SAMPLE ANALYSIS:\n",
      "\n",
      "üìà Feature Statistics:\n",
      "   sentence_count: 21.9 ¬± 3.2\n",
      "   commas: 30.5 ¬± 7.9\n",
      "   person_entities: 0.0 ¬± 0.0\n",
      "   org_entities: 0.0 ¬± 0.0\n",
      "   char_count: 3705.5 ¬± 411.8\n",
      "   subjectivity: 0.4 ¬± 0.1\n",
      "\n",
      "ü§ñ Testing classification performance...\n",
      "\n",
      "üîç Evaluating Balanced Zero-Shot approach...\n",
      "   üìä Results for Balanced Zero-Shot:\n",
      "      Accuracy: 0.000 (higher = better fake detection)\n",
      "      F1 Score: 0.000\n",
      "      Fake classification rate: 0.000\n",
      "      Avg fake probability: 0.073\n",
      "      High confidence fake (>0.7): 0.000\n",
      "\n",
      "üìä Balanced Approach Results:\n",
      "   Fake classification rate: 0.0%\n",
      "   Average fake confidence: 0.073\n",
      "   Target alignment: 0.0%\n",
      "   ‚ùå Too low (<60% fake classification)\n",
      "\n",
      "‚úÖ BALANCED APPROACH TESTING COMPLETE\n",
      "‚úÖ Balanced generation complete: 30 articles\n",
      "\n",
      "üìä BALANCED SAMPLE ANALYSIS:\n",
      "\n",
      "üìà Feature Statistics:\n",
      "   sentence_count: 21.9 ¬± 3.2\n",
      "   commas: 30.5 ¬± 7.9\n",
      "   person_entities: 0.0 ¬± 0.0\n",
      "   org_entities: 0.0 ¬± 0.0\n",
      "   char_count: 3705.5 ¬± 411.8\n",
      "   subjectivity: 0.4 ¬± 0.1\n",
      "\n",
      "ü§ñ Testing classification performance...\n",
      "\n",
      "üîç Evaluating Balanced Zero-Shot approach...\n",
      "   üìä Results for Balanced Zero-Shot:\n",
      "      Accuracy: 0.000 (higher = better fake detection)\n",
      "      F1 Score: 0.000\n",
      "      Fake classification rate: 0.000\n",
      "      Avg fake probability: 0.073\n",
      "      High confidence fake (>0.7): 0.000\n",
      "\n",
      "üìä Balanced Approach Results:\n",
      "   Fake classification rate: 0.0%\n",
      "   Average fake confidence: 0.073\n",
      "   Target alignment: 0.0%\n",
      "   ‚ùå Too low (<60% fake classification)\n",
      "\n",
      "‚úÖ BALANCED APPROACH TESTING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Test Balanced Approach and Compare Classification Performance\n",
    "print(\"üß™ TESTING BALANCED APPROACH\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Generate more natural fake news that avoids F1=1.0 over-fitting\")\n",
    "\n",
    "if 'balanced_generator' in globals():\n",
    "    \n",
    "    print(f\"\\nüöÄ Generating balanced sample (30 articles)...\")\n",
    "    balanced_sample = balanced_generator.generate_balanced_articles(count=30)\n",
    "    \n",
    "    if balanced_sample:\n",
    "        globals()['BALANCED_SAMPLE'] = balanced_sample\n",
    "        \n",
    "        print(f\"\\nüìä BALANCED SAMPLE ANALYSIS:\")\n",
    "        \n",
    "        # Quick feature analysis\n",
    "        features_list = [art['features'] for art in balanced_sample if 'features' in art]\n",
    "        \n",
    "        if features_list:\n",
    "            print(f\"\\nüìà Feature Statistics:\")\n",
    "            \n",
    "            feature_stats = {}\n",
    "            for feature in ['sentence_count', 'commas', 'person_entities', 'org_entities', 'char_count', 'subjectivity']:\n",
    "                values = [f.get(feature, 0) for f in features_list]\n",
    "                if values:\n",
    "                    mean_val = np.mean(values)\n",
    "                    std_val = np.std(values)\n",
    "                    feature_stats[feature] = {'mean': mean_val, 'std': std_val}\n",
    "                    \n",
    "                    print(f\"   {feature}: {mean_val:.1f} ¬± {std_val:.1f}\")\n",
    "        \n",
    "        # Test classification performance\n",
    "        if 'evaluator' in globals() and evaluator.is_trained:\n",
    "            print(f\"\\nü§ñ Testing classification performance...\")\n",
    "            \n",
    "            balanced_result = evaluator.evaluate_synthetic_approach(balanced_sample, \"Balanced Zero-Shot\")\n",
    "            \n",
    "            if balanced_result:\n",
    "                fake_rate = balanced_result.get('fake_classification_rate', 0)\n",
    "                confidence = balanced_result.get('avg_fake_probability', 0)\n",
    "                \n",
    "                print(f\"\\nüìä Balanced Approach Results:\")\n",
    "                print(f\"   Fake classification rate: {fake_rate:.1%}\")\n",
    "                print(f\"   Average fake confidence: {confidence:.3f}\")\n",
    "                \n",
    "                # Compare to target (real fake news ~85-95%)\n",
    "                target_performance = 0.90\n",
    "                alignment = fake_rate / target_performance\n",
    "                \n",
    "                print(f\"   Target alignment: {alignment:.1%}\")\n",
    "                \n",
    "                if fake_rate > 0.95:\n",
    "                    print(f\"   üö® Still too obvious (>95% fake classification)\")\n",
    "                elif fake_rate > 0.80:\n",
    "                    print(f\"   ‚úÖ Good range (80-95% fake classification)\")  \n",
    "                elif fake_rate > 0.60:\n",
    "                    print(f\"   üü° Moderate range (60-80% fake classification)\")\n",
    "                else:\n",
    "                    print(f\"   ‚ùå Too low (<60% fake classification)\")\n",
    "                \n",
    "                # Store result for comparison\n",
    "                globals()['BALANCED_RESULT'] = balanced_result\n",
    "                \n",
    "        print(f\"\\n‚úÖ BALANCED APPROACH TESTING COMPLETE\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Balanced sample generation failed\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Balanced generator not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "29c6c1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ OPTIMIZED PROMPT GENERATION\n",
      "============================================================\n",
      "üéØ Goal: Find middle ground between F1=1.0 (over-fitted) and F1=0.0 (under-fitted)\n",
      "‚úÖ Optimized generator initialized\n",
      "üéØ Ready for balanced fake news generation\n"
     ]
    }
   ],
   "source": [
    "# Create Optimized Prompt - Middle Ground Between Over/Under-Fitting\n",
    "print(\"üéØ OPTIMIZED PROMPT GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Find middle ground between F1=1.0 (over-fitted) and F1=0.0 (under-fitted)\")\n",
    "\n",
    "class OptimizedZeroShotGenerator:\n",
    "    \"\"\"\n",
    "    Optimized generator that balances fake news patterns without over-fitting\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, targets):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.targets = targets\n",
    "    \n",
    "    def create_optimized_prompt(self):\n",
    "        \"\"\"Create a carefully balanced fake news prompt\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "Write a news article that follows interpretive political journalism style:\n",
    "\n",
    "CONTENT APPROACH:\n",
    "- Focus on analyzing political developments and their broader implications\n",
    "- Include perspectives from government officials, political figures, and experts\n",
    "- When relevant to the story, reference social media reactions or public responses\n",
    "- Name specific individuals involved and their official roles or titles\n",
    "- Reference relevant organizations, agencies, or institutions in the story\n",
    "- Include visual elements (photos, videos, documents) when they enhance the story\n",
    "\n",
    "WRITING STYLE:\n",
    "- Use engaging, analytical language that explains significance of events\n",
    "- Write 18-26 sentences with natural complexity and punctuation\n",
    "- Include 1-2 rhetorical questions about broader implications or consequences\n",
    "- Maintain professional journalistic tone with interpretive analysis\n",
    "- Focus on what developments MEAN for politics, policy, or society\n",
    "\n",
    "ENTITY REQUIREMENTS:\n",
    "- Name 6-12 specific people with their roles (officials, experts, affected parties)\n",
    "- Reference 4-8 organizations or institutions relevant to the story\n",
    "- Include geographic locations (states, cities, countries) as appropriate\n",
    "\n",
    "TOPIC FOCUS: {{topic}}\n",
    "\n",
    "Length: Write a comprehensive article (900-1100 words) that thoroughly analyzes the topic.\n",
    "\n",
    "Write as an experienced political journalist who explains complex developments in accessible terms while maintaining analytical depth.\n",
    "\"\"\"\n",
    "    \n",
    "    def generate_optimized_articles(self, count: int = 30) -> List[Dict]:\n",
    "        \"\"\"Generate optimized synthetic articles with balanced patterns\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Optimized Generation ({count} articles)\")\n",
    "        \n",
    "        prompt = self.create_optimized_prompt()\n",
    "        \n",
    "        # Balanced topics - political but not overly formulaic\n",
    "        topics = [\n",
    "            \"congressional committee investigation reveals new evidence in ongoing inquiry\",\n",
    "            \"state election officials respond to federal oversight proposal with mixed reactions\", \n",
    "            \"supreme court decision creates uncertainty for pending legislation across multiple states\",\n",
    "            \"political figure's testimony before house committee draws bipartisan scrutiny\",\n",
    "            \"federal agency rule change faces legal challenges from industry groups\",\n",
    "            \"government transparency report highlights accountability gaps in multiple departments\",\n",
    "            \"bipartisan legislation faces obstacles despite initial cross-party support\",\n",
    "            \"judicial nomination hearing features contentious exchanges over judicial philosophy\",\n",
    "            \"campaign finance investigation expands to include additional political organizations\",\n",
    "            \"regulatory agency decision impacts multiple stakeholders across different sectors\",\n",
    "            \"political party leadership meeting addresses strategy ahead of upcoming elections\",\n",
    "            \"government accountability office report criticizes implementation of federal program\",\n",
    "            \"congressional hearing on oversight reveals tensions between legislative and executive branches\",\n",
    "            \"federal investigation into government contracts raises questions about procurement processes\",\n",
    "            \"policy implementation challenges emerge as states adapt to new federal guidelines\",\n",
    "            \"political alliance shows signs of strain over disagreements on key legislative priorities\",\n",
    "            \"government ethics investigation examines conduct of multiple public officials\",\n",
    "            \"regulatory reform proposal generates debate among business groups and consumer advocates\",\n",
    "            \"congressional subpoena fight escalates as executive branch claims privilege\",\n",
    "            \"federal court ruling creates precedent that may affect similar cases nationwide\"\n",
    "        ]\n",
    "        \n",
    "        articles = []\n",
    "        for i in range(count):\n",
    "            try:\n",
    "                topic = np.random.choice(topics)\n",
    "                full_prompt = prompt.format(topic=topic)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are an experienced political journalist writing analytical articles that explain the significance of political developments. Include specific names, organizations, and implications while maintaining professional journalistic standards.\"},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt}\n",
    "                    ],\n",
    "                    max_tokens=1300,\n",
    "                    temperature=0.8  # Balanced temperature for variety without chaos\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': 'optimized_zero_shot',\n",
    "                    'topic': topic,\n",
    "                    'features': features,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"   Generated {i + 1}/{count} optimized articles...\")\n",
    "                    \n",
    "                time.sleep(0.4)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating optimized article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Optimized generation complete: {len(articles)} articles\")\n",
    "        return articles\n",
    "\n",
    "# Initialize optimized generator\n",
    "if API_AVAILABLE and 'OPENAI_CLIENT' in globals():\n",
    "    optimized_generator = OptimizedZeroShotGenerator(OPENAI_CLIENT, feature_extractor, NEWS_TARGETS)\n",
    "    print(\"‚úÖ Optimized generator initialized\")\n",
    "    print(\"üéØ Ready for balanced fake news generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Optimized generator not initialized - API not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "00cd49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ TESTING OPTIMIZED APPROACH\n",
      "============================================================\n",
      "üéØ Goal: Achieve realistic F1 score between 0.7-0.9 (not 1.0 or 0.0)\n",
      "\n",
      "üöÄ Generating optimized sample (30 articles)...\n",
      "üöÄ Optimized Generation (30 articles)\n",
      "   Generated 10/30 optimized articles...\n",
      "   Generated 20/30 optimized articles...\n",
      "   Generated 30/30 optimized articles...\n",
      "‚úÖ Optimized generation complete: 30 articles\n",
      "\n",
      "üìä OPTIMIZED SAMPLE ANALYSIS:\n",
      "\n",
      "üìà Feature Statistics:\n",
      "   sentence_count: 22.0 ¬± 3.2\n",
      "   commas: 28.5 ¬± 4.5\n",
      "   person_entities: 0.0 ¬± 0.0\n",
      "   org_entities: 0.0 ¬± 0.0\n",
      "   char_count: 3977.6 ¬± 432.2\n",
      "   subjectivity: 0.4 ¬± 0.1\n",
      "\n",
      "ü§ñ Testing classification performance...\n",
      "\n",
      "üîç Evaluating Optimized Zero-Shot approach...\n",
      "   üìä Results for Optimized Zero-Shot:\n",
      "      Accuracy: 0.000 (higher = better fake detection)\n",
      "      F1 Score: 0.000\n",
      "      Fake classification rate: 0.000\n",
      "      Avg fake probability: 0.057\n",
      "      High confidence fake (>0.7): 0.000\n",
      "\n",
      "üìä Optimized Approach Results:\n",
      "   Fake classification rate: 0.0%\n",
      "   Average fake confidence: 0.057\n",
      "   F1 Score: 0.000\n",
      "\n",
      "üéØ TARGET RANGE ANALYSIS:\n",
      "   F1 Score Assessment: ‚ùå Under-fitted (F1 < 0.50)\n",
      "   Baseline alignment: 0.0%\n",
      "   ‚ö†Ô∏è Too similar to real news\n",
      "\n",
      "üìö Vocabulary Diversity: 0.188\n",
      "   ‚ö†Ô∏è Diversity outside normal range (0.4-0.6)\n",
      "\n",
      "‚úÖ OPTIMIZED APPROACH TESTING COMPLETE\n"
     ]
    }
   ],
   "source": [
    "# Test Optimized Approach - Target F1 Score 0.7-0.9\n",
    "print(\"üéØ TESTING OPTIMIZED APPROACH\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Achieve realistic F1 score between 0.7-0.9 (not 1.0 or 0.0)\")\n",
    "\n",
    "if 'optimized_generator' in globals():\n",
    "    \n",
    "    print(f\"\\nüöÄ Generating optimized sample (30 articles)...\")\n",
    "    optimized_sample = optimized_generator.generate_optimized_articles(count=30)\n",
    "    \n",
    "    if optimized_sample:\n",
    "        globals()['OPTIMIZED_SAMPLE'] = optimized_sample\n",
    "        \n",
    "        print(f\"\\nüìä OPTIMIZED SAMPLE ANALYSIS:\")\n",
    "        \n",
    "        # Feature analysis\n",
    "        features_list = [art['features'] for art in optimized_sample if 'features' in art]\n",
    "        \n",
    "        if features_list:\n",
    "            print(f\"\\nüìà Feature Statistics:\")\n",
    "            \n",
    "            key_features = ['sentence_count', 'commas', 'person_entities', 'org_entities', 'char_count', 'subjectivity']\n",
    "            for feature in key_features:\n",
    "                values = [f.get(feature, 0) for f in features_list]\n",
    "                if values:\n",
    "                    mean_val = np.mean(values)\n",
    "                    std_val = np.std(values)\n",
    "                    print(f\"   {feature}: {mean_val:.1f} ¬± {std_val:.1f}\")\n",
    "        \n",
    "        # Test classification performance\n",
    "        if 'evaluator' in globals() and evaluator.is_trained:\n",
    "            print(f\"\\nü§ñ Testing classification performance...\")\n",
    "            \n",
    "            optimized_result = evaluator.evaluate_synthetic_approach(optimized_sample, \"Optimized Zero-Shot\")\n",
    "            \n",
    "            if optimized_result:\n",
    "                fake_rate = optimized_result.get('fake_classification_rate', 0)\n",
    "                confidence = optimized_result.get('avg_fake_probability', 0)\n",
    "                f1_score = optimized_result.get('f1_score', 0)\n",
    "                \n",
    "                print(f\"\\nüìä Optimized Approach Results:\")\n",
    "                print(f\"   Fake classification rate: {fake_rate:.1%}\")\n",
    "                print(f\"   Average fake confidence: {confidence:.3f}\")\n",
    "                print(f\"   F1 Score: {f1_score:.3f}\")\n",
    "                \n",
    "                # Evaluate against target ranges\n",
    "                print(f\"\\nüéØ TARGET RANGE ANALYSIS:\")\n",
    "                if f1_score >= 0.95:\n",
    "                    status = \"üö® Still over-fitted (F1 ‚â• 0.95)\"\n",
    "                elif f1_score >= 0.7:\n",
    "                    status = \"‚úÖ Good range (F1: 0.70-0.94)\"\n",
    "                elif f1_score >= 0.5:\n",
    "                    status = \"üü° Moderate range (F1: 0.50-0.69)\"\n",
    "                else:\n",
    "                    status = \"‚ùå Under-fitted (F1 < 0.50)\"\n",
    "                \n",
    "                print(f\"   F1 Score Assessment: {status}\")\n",
    "                \n",
    "                # Compare to real fake news baseline (~85-90%)\n",
    "                baseline_fake_rate = 0.875  # Realistic baseline\n",
    "                alignment = fake_rate / baseline_fake_rate\n",
    "                print(f\"   Baseline alignment: {alignment:.1%}\")\n",
    "                \n",
    "                if 0.8 <= alignment <= 1.2:\n",
    "                    print(f\"   ‚úÖ Good alignment with real fake news patterns\")\n",
    "                elif alignment > 1.2:\n",
    "                    print(f\"   üö® Still too obvious to classifier\") \n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Too similar to real news\")\n",
    "                \n",
    "                # Store result\n",
    "                globals()['OPTIMIZED_RESULT'] = optimized_result\n",
    "                \n",
    "                # Quick vocabulary diversity check\n",
    "                all_optimized_text = ' '.join([art['article'].lower() for art in optimized_sample])\n",
    "                all_words = all_optimized_text.split()\n",
    "                unique_words = set(all_words)\n",
    "                diversity = len(unique_words) / len(all_words)\n",
    "                \n",
    "                print(f\"\\nüìö Vocabulary Diversity: {diversity:.3f}\")\n",
    "                if 0.4 <= diversity <= 0.6:\n",
    "                    print(f\"   ‚úÖ Natural diversity range\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è Diversity outside normal range (0.4-0.6)\")\n",
    "                \n",
    "        print(f\"\\n‚úÖ OPTIMIZED APPROACH TESTING COMPLETE\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Optimized sample generation failed\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Optimized generator not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6845754e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FINAL TUNED APPROACH\n",
      "============================================================\n",
      "üéØ Goal: Fix entity extraction and achieve realistic F1 score\n",
      "‚úÖ Final tuned generator initialized\n",
      "üéØ Ready for entity-rich fake news generation\n"
     ]
    }
   ],
   "source": [
    "# Final Tuned Approach - Fix Entity Extraction Issue\n",
    "print(\"üîß FINAL TUNED APPROACH\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Fix entity extraction and achieve realistic F1 score\")\n",
    "\n",
    "class FinalTunedGenerator:\n",
    "    \"\"\"\n",
    "    Final version that addresses entity extraction and balances all patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, targets):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.targets = targets\n",
    "    \n",
    "    def create_final_prompt(self):\n",
    "        \"\"\"Create final prompt that ensures entity extraction works properly\"\"\"\n",
    "        \n",
    "        return f\"\"\"\n",
    "Write a political news article with interpretive analysis:\n",
    "\n",
    "REQUIRED STORY ELEMENTS:\n",
    "- Quote at least 8-12 specific people by their full names and titles (e.g., \"Senator John Smith\", \"Representative Maria Rodriguez\", \"White House Press Secretary David Johnson\")\n",
    "- Reference 5-8 organizations by name (e.g., \"Department of Justice\", \"Republican National Committee\", \"American Civil Liberties Union\", \"Fox News\", \"CNN\")\n",
    "- Include specific locations (states, cities, government buildings)\n",
    "- Mention some social media activity or public reactions when relevant\n",
    "\n",
    "WRITING REQUIREMENTS:\n",
    "- Write 18-26 sentences with natural flow and punctuation\n",
    "- Include interpretive analysis of what events mean politically\n",
    "- Add 1-2 questions about broader implications\n",
    "- Use quotes from the named sources\n",
    "- Reference recent developments or ongoing investigations\n",
    "\n",
    "STORY FOCUS: {{topic}}\n",
    "\n",
    "EXAMPLE ELEMENTS TO INCLUDE:\n",
    "- People: \"According to Congressman [Name], the legislation...\"\n",
    "- Organizations: \"The [Department/Agency] announced that...\"\n",
    "- Social context: \"Social media users have been discussing...\"\n",
    "- Analysis: \"This development could impact...\"\n",
    "\n",
    "Write a complete 900-1100 word article that reads like professional political journalism with proper sourcing and analysis.\n",
    "\"\"\"\n",
    "    \n",
    "    def generate_final_articles(self, count: int = 30) -> List[Dict]:\n",
    "        \"\"\"Generate final tuned articles with proper entity inclusion\"\"\"\n",
    "        \n",
    "        print(f\"üöÄ Final Tuned Generation ({count} articles)\")\n",
    "        \n",
    "        prompt = self.create_final_prompt()\n",
    "        \n",
    "        # Clear political topics that encourage entity usage\n",
    "        topics = [\n",
    "            \"congressional oversight hearing on federal agency spending practices\",\n",
    "            \"bipartisan legislation package faces committee vote amid lobbying pressure\", \n",
    "            \"department of justice investigation expands to include political organizations\",\n",
    "            \"senate confirmation hearing for cabinet nominee draws partisan criticism\",\n",
    "            \"house intelligence committee reviews classified documents in ongoing probe\",\n",
    "            \"federal election commission investigates campaign finance violations by multiple candidates\",\n",
    "            \"supreme court oral arguments on voting rights case divide legal experts\",\n",
    "            \"congressional budget office report warns of fiscal challenges ahead\",\n",
    "            \"ethics committee investigation into congressman's financial dealings intensifies\",\n",
    "            \"senate judiciary hearing on judicial nominations becomes contentious affair\",\n",
    "            \"house oversight committee subpoenas white house officials in transparency dispute\",\n",
    "            \"federal communications commission ruling on media ownership sparks industry backlash\",\n",
    "            \"congressional hearing on homeland security preparedness reveals agency gaps\",\n",
    "            \"senate foreign relations committee questions state department officials on policy\",\n",
    "            \"house ways and means committee considers tax legislation with bipartisan concerns\"\n",
    "        ]\n",
    "        \n",
    "        articles = []\n",
    "        for i in range(count):\n",
    "            try:\n",
    "                topic = np.random.choice(topics)\n",
    "                full_prompt = prompt.format(topic=topic)\n",
    "                \n",
    "                response = self.client.chat.completions.create(\n",
    "                    model=\"gpt-3.5-turbo\",\n",
    "                    messages=[\n",
    "                        {\"role\": \"system\", \"content\": \"You are a political journalist. Write detailed articles that quote specific government officials by name, reference government agencies and organizations, and include social media or public reaction context. Use real-sounding names and titles for sources.\"},\n",
    "                        {\"role\": \"user\", \"content\": full_prompt}\n",
    "                    ],\n",
    "                    max_tokens=1400,\n",
    "                    temperature=0.75  # Balanced for consistency with variety\n",
    "                )\n",
    "                \n",
    "                article_text = response.choices[0].message.content.strip()\n",
    "                features = self.feature_extractor.extract_features(article_text)\n",
    "                \n",
    "                articles.append({\n",
    "                    'article': article_text,\n",
    "                    'approach': 'final_tuned',\n",
    "                    'topic': topic,\n",
    "                    'features': features,\n",
    "                    'timestamp': datetime.now().isoformat()\n",
    "                })\n",
    "                \n",
    "                if (i + 1) % 10 == 0:\n",
    "                    print(f\"   Generated {i + 1}/{count} final articles...\")\n",
    "                    \n",
    "                time.sleep(0.4)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   Error generating final article {i+1}: {e}\")\n",
    "                continue\n",
    "        \n",
    "        print(f\"‚úÖ Final tuned generation complete: {len(articles)} articles\")\n",
    "        \n",
    "        # Quick entity check\n",
    "        if articles:\n",
    "            entity_counts = []\n",
    "            for article in articles[:5]:  # Check first 5\n",
    "                features = article.get('features', {})\n",
    "                persons = features.get('person_entities', 0)\n",
    "                orgs = features.get('org_entities', 0) \n",
    "                entity_counts.append((persons, orgs))\n",
    "            \n",
    "            avg_persons = np.mean([p for p, o in entity_counts])\n",
    "            avg_orgs = np.mean([o for p, o in entity_counts])\n",
    "            \n",
    "            print(f\"\\nüìä Entity Check (first 5 articles):\")\n",
    "            print(f\"   Average person entities: {avg_persons:.1f}\")\n",
    "            print(f\"   Average org entities: {avg_orgs:.1f}\")\n",
    "            \n",
    "            if avg_persons > 0 and avg_orgs > 0:\n",
    "                print(f\"   ‚úÖ Entities successfully extracted\")\n",
    "            else:\n",
    "                print(f\"   ‚ö†Ô∏è Entity extraction may still be an issue\")\n",
    "        \n",
    "        return articles\n",
    "\n",
    "# Initialize final generator\n",
    "if API_AVAILABLE and 'OPENAI_CLIENT' in globals():\n",
    "    final_generator = FinalTunedGenerator(OPENAI_CLIENT, feature_extractor, NEWS_TARGETS)\n",
    "    print(\"‚úÖ Final tuned generator initialized\")\n",
    "    print(\"üéØ Ready for entity-rich fake news generation\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Final generator not initialized - API not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b5c9e2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÅ TESTING FINAL TUNED APPROACH\n",
      "============================================================\n",
      "üéØ Goal: Complete solution with realistic F1 score and proper entities\n",
      "\n",
      "üöÄ Generating final sample (30 articles)...\n",
      "üöÄ Final Tuned Generation (30 articles)\n",
      "   Generated 10/30 final articles...\n",
      "   Generated 20/30 final articles...\n",
      "   Generated 30/30 final articles...\n",
      "‚úÖ Final tuned generation complete: 30 articles\n",
      "\n",
      "üìä Entity Check (first 5 articles):\n",
      "   Average person entities: 0.0\n",
      "   Average org entities: 0.0\n",
      "   ‚ö†Ô∏è Entity extraction may still be an issue\n",
      "\n",
      "üìä FINAL SAMPLE COMPREHENSIVE ANALYSIS:\n",
      "\n",
      "üìà Feature Statistics vs Real Fake News Targets:\n",
      "   ‚úÖ sentence_count: 25.3 ¬± 4.1 (target: 17-29)\n",
      "   ‚ùå commas: 31.0 ¬± 5.7 (target: 16-27)\n",
      "   ‚ùå person_entities: 0.0 ¬± 0.0 (target: 8-17)\n",
      "   ‚ùå org_entities: 0.0 ¬± 0.0 (target: 5-12)\n",
      "   ‚ùå char_count: 4034.9 ¬± 488.9 (target: 2031-3010)\n",
      "   ‚úÖ subjectivity: 0.4 ¬± 0.1 (target: 0.35-0.65)\n",
      "\n",
      "ü§ñ Final Classification Test...\n",
      "\n",
      "üîç Evaluating Final Tuned approach...\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 50\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevaluator\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mglobals\u001b[39m() \u001b[38;5;129;01mand\u001b[39;00m evaluator\u001b[38;5;241m.\u001b[39mis_trained:\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mü§ñ Final Classification Test...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 50\u001b[0m     final_result \u001b[38;5;241m=\u001b[39m \u001b[43mevaluator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate_synthetic_approach\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfinal_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mFinal Tuned\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m final_result:\n\u001b[1;32m     53\u001b[0m         fake_rate \u001b[38;5;241m=\u001b[39m final_result\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfake_classification_rate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)\n",
      "Cell \u001b[0;32mIn[17], line 123\u001b[0m, in \u001b[0;36mSyntheticApproachEvaluator.evaluate_synthetic_approach\u001b[0;34m(self, articles, approach_name)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Calculate metrics\u001b[39;00m\n\u001b[1;32m    122\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(true_labels, predictions)\n\u001b[0;32m--> 123\u001b[0m f1 \u001b[38;5;241m=\u001b[39m \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrue_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;66;03m# Additional analysis\u001b[39;00m\n\u001b[1;32m    126\u001b[0m fake_classification_rate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(predictions) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(predictions)\n",
      "\u001b[0;31mTypeError\u001b[0m: 'float' object is not callable"
     ]
    }
   ],
   "source": [
    "# Test Final Tuned Approach - Complete Solution\n",
    "print(\"üèÅ TESTING FINAL TUNED APPROACH\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Complete solution with realistic F1 score and proper entities\")\n",
    "\n",
    "if 'final_generator' in globals():\n",
    "    \n",
    "    print(f\"\\nüöÄ Generating final sample (30 articles)...\")\n",
    "    final_sample = final_generator.generate_final_articles(count=30)\n",
    "    \n",
    "    if final_sample:\n",
    "        globals()['FINAL_SAMPLE'] = final_sample\n",
    "        \n",
    "        print(f\"\\nüìä FINAL SAMPLE COMPREHENSIVE ANALYSIS:\")\n",
    "        \n",
    "        # Detailed feature analysis\n",
    "        features_list = [art['features'] for art in final_sample if 'features' in art]\n",
    "        \n",
    "        if features_list:\n",
    "            print(f\"\\nüìà Feature Statistics vs Real Fake News Targets:\")\n",
    "            \n",
    "            # Real fake news targets from analysis\n",
    "            targets = {\n",
    "                'sentence_count': (17, 29, 24.7),  # (q25, q75, mean)\n",
    "                'commas': (16, 27, 22.5),\n",
    "                'person_entities': (8, 17, 13.2),\n",
    "                'org_entities': (5, 12, 9.4),\n",
    "                'char_count': (2031, 3010, 2623),\n",
    "                'subjectivity': (0.35, 0.65, 0.50)  # Estimated range\n",
    "            }\n",
    "            \n",
    "            for feature, (target_min, target_max, target_mean) in targets.items():\n",
    "                values = [f.get(feature, 0) for f in features_list]\n",
    "                if values:\n",
    "                    mean_val = np.mean(values)\n",
    "                    std_val = np.std(values)\n",
    "                    \n",
    "                    # Check if in target range\n",
    "                    if target_min <= mean_val <= target_max:\n",
    "                        status = \"‚úÖ\"\n",
    "                    else:\n",
    "                        status = \"‚ùå\"\n",
    "                    \n",
    "                    print(f\"   {status} {feature}: {mean_val:.1f} ¬± {std_val:.1f} (target: {target_min}-{target_max})\")\n",
    "        \n",
    "        # Test classification performance\n",
    "        if 'evaluator' in globals() and evaluator.is_trained:\n",
    "            print(f\"\\nü§ñ Final Classification Test...\")\n",
    "            \n",
    "            final_result = evaluator.evaluate_synthetic_approach(final_sample, \"Final Tuned\")\n",
    "            \n",
    "            if final_result:\n",
    "                fake_rate = final_result.get('fake_classification_rate', 0)\n",
    "                confidence = final_result.get('avg_fake_probability', 0)\n",
    "                f1_score = final_result.get('f1_score', 0)\n",
    "                accuracy = final_result.get('accuracy', 0)\n",
    "                \n",
    "                print(f\"\\nüìä Final Approach Results:\")\n",
    "                print(f\"   Fake classification rate: {fake_rate:.1%}\")\n",
    "                print(f\"   Average fake confidence: {confidence:.3f}\")\n",
    "                print(f\"   F1 Score: {f1_score:.3f}\")\n",
    "                print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "                \n",
    "                # Comprehensive assessment\n",
    "                print(f\"\\nüéØ FINAL ASSESSMENT:\")\n",
    "                \n",
    "                # F1 Score evaluation\n",
    "                if 0.7 <= f1_score <= 0.9:\n",
    "                    f1_status = \"‚úÖ Perfect range (0.7-0.9)\"\n",
    "                elif 0.5 <= f1_score < 0.7:\n",
    "                    f1_status = \"üü° Acceptable range (0.5-0.7)\"\n",
    "                elif f1_score >= 0.95:\n",
    "                    f1_status = \"üö® Over-fitted (‚â•0.95)\"\n",
    "                else:\n",
    "                    f1_status = \"‚ùå Under-fitted (<0.5)\"\n",
    "                \n",
    "                print(f\"   F1 Score: {f1_status}\")\n",
    "                \n",
    "                # Fake rate evaluation\n",
    "                if 0.75 <= fake_rate <= 0.95:\n",
    "                    fake_status = \"‚úÖ Realistic range (75-95%)\"\n",
    "                elif fake_rate > 0.95:\n",
    "                    fake_status = \"üö® Too obvious (>95%)\"\n",
    "                else:\n",
    "                    fake_status = \"‚ö†Ô∏è Too real-like (<75%)\"\n",
    "                \n",
    "                print(f\"   Fake Rate: {fake_status}\")\n",
    "                \n",
    "                # Overall recommendation\n",
    "                if 0.7 <= f1_score <= 0.9 and 0.75 <= fake_rate <= 0.95:\n",
    "                    print(f\"\\nüéâ SUCCESS! Ready for full-scale generation\")\n",
    "                    print(f\"   This approach balances fake news patterns without over-fitting\")\n",
    "                elif f1_score >= 0.5 and fake_rate >= 0.5:\n",
    "                    print(f\"\\nüü° ACCEPTABLE - Minor adjustments may help\")\n",
    "                else:\n",
    "                    print(f\"\\n‚ùå NEEDS REFINEMENT - Significant pattern issues remain\")\n",
    "                \n",
    "                # Store final result\n",
    "                globals()['FINAL_RESULT'] = final_result\n",
    "                \n",
    "                # Compare all approaches\n",
    "                print(f\"\\nüìã APPROACH COMPARISON SUMMARY:\")\n",
    "                print(f\"   Enhanced v1: F1=1.000 (over-fitted)\")\n",
    "                print(f\"   Enhanced v2: F1=1.000 (over-fitted)\") \n",
    "                print(f\"   Enhanced v3: F1=0.974 (over-fitted)\")\n",
    "                print(f\"   Balanced: F1=0.000 (under-fitted)\")\n",
    "                print(f\"   Optimized: F1=0.000 (under-fitted)\")\n",
    "                print(f\"   Final Tuned: F1={f1_score:.3f} ({'‚úÖ SUCCESS' if 0.7 <= f1_score <= 0.9 else 'üîÑ NEEDS WORK'})\")\n",
    "                \n",
    "        print(f\"\\n‚úÖ FINAL TUNED APPROACH TESTING COMPLETE\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Final sample generation failed\")\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Final generator not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "99e9d3b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FIXING IMPORT ISSUE AND RETESTING\n",
      "============================================================\n",
      "‚úÖ Evaluator function fixed\n",
      "\n",
      "ü§ñ Retesting Final Approach with Fixed Function...\n",
      "\n",
      "üîç Evaluating Final Tuned (Fixed) approach...\n",
      "   üìä Results for Final Tuned (Fixed):\n",
      "      Accuracy: 0.000 (higher = better fake detection)\n",
      "      F1 Score: 0.000\n",
      "      Fake classification rate: 0.000\n",
      "      Avg fake probability: 0.053\n",
      "      High confidence fake (>0.7): 0.000\n",
      "\n",
      "üìä Final Approach Results (Fixed):\n",
      "   Fake classification rate: 0.0%\n",
      "   Average fake confidence: 0.053\n",
      "   F1 Score: 0.000\n",
      "   Accuracy: 0.000\n",
      "\n",
      "üéØ FINAL ASSESSMENT:\n",
      "   F1 Score: ‚ùå Under-fitted (<0.5)\n",
      "   Fake Rate: ‚ö†Ô∏è Too real-like (<75%)\n",
      "\n",
      "‚ùå STILL NEEDS WORK\n"
     ]
    }
   ],
   "source": [
    "# Fix Function Import Issue and Retest\n",
    "print(\"üîß FIXING IMPORT ISSUE AND RETESTING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Reimport the sklearn functions that got overwritten\n",
    "from sklearn.metrics import accuracy_score, f1_score as sklearn_f1_score, classification_report\n",
    "\n",
    "# Update the evaluator to use the correctly imported function\n",
    "if 'evaluator' in globals():\n",
    "    # Patch the evaluator method\n",
    "    def fixed_evaluate_synthetic_approach(self, articles: List[Dict], approach_name: str) -> Dict:\n",
    "        \"\"\"Evaluate how well synthetic articles are classified as fake (FIXED VERSION)\"\"\"\n",
    "        \n",
    "        if not self.is_trained:\n",
    "            print(f\"‚ùå Model not trained yet\")\n",
    "            return {}\n",
    "        \n",
    "        if not articles:\n",
    "            print(f\"‚ùå No articles to evaluate\")\n",
    "            return {}\n",
    "        \n",
    "        print(f\"\\nüîç Evaluating {approach_name} approach...\")\n",
    "        \n",
    "        # Extract article texts\n",
    "        texts = [article['article'] for article in articles]\n",
    "        \n",
    "        # Transform using trained vectorizer\n",
    "        X_synthetic = self.vectorizer.transform(texts)\n",
    "        \n",
    "        # Predict (all synthetic articles should ideally be classified as fake=1)\n",
    "        predictions = self.model.predict(X_synthetic)\n",
    "        probabilities = self.model.predict_proba(X_synthetic)[:, 1]  # Prob of being fake\n",
    "        \n",
    "        # Create true labels (all should be fake=1 since they're synthetic fake news)\n",
    "        true_labels = [1] * len(articles)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        accuracy = accuracy_score(true_labels, predictions)\n",
    "        f1 = sklearn_f1_score(true_labels, predictions, pos_label=1)  # Use fixed import\n",
    "        \n",
    "        # Additional analysis\n",
    "        fake_classification_rate = sum(predictions) / len(predictions)\n",
    "        avg_fake_probability = np.mean(probabilities)\n",
    "        high_confidence_fake = np.mean(probabilities > 0.7)\n",
    "        \n",
    "        result = {\n",
    "            'approach': approach_name,\n",
    "            'accuracy': accuracy,\n",
    "            'f1_score': f1,\n",
    "            'fake_classification_rate': fake_classification_rate,\n",
    "            'avg_fake_probability': avg_fake_probability,\n",
    "            'high_confidence_fake': high_confidence_fake,\n",
    "            'sample_size': len(articles)\n",
    "        }\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"   üìä Results for {approach_name}:\")\n",
    "        print(f\"      Accuracy: {accuracy:.3f} (higher = better fake detection)\")\n",
    "        print(f\"      F1 Score: {f1:.3f}\")  \n",
    "        print(f\"      Fake classification rate: {fake_classification_rate:.3f}\")\n",
    "        print(f\"      Avg fake probability: {avg_fake_probability:.3f}\")\n",
    "        print(f\"      High confidence fake (>0.7): {high_confidence_fake:.3f}\")\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    # Replace the method in the evaluator instance\n",
    "    import types\n",
    "    evaluator.evaluate_synthetic_approach = types.MethodType(fixed_evaluate_synthetic_approach, evaluator)\n",
    "    \n",
    "    print(\"‚úÖ Evaluator function fixed\")\n",
    "\n",
    "# Now retest the final approach\n",
    "if 'final_sample' in globals() and 'evaluator' in globals():\n",
    "    print(f\"\\nü§ñ Retesting Final Approach with Fixed Function...\")\n",
    "    \n",
    "    final_result = evaluator.evaluate_synthetic_approach(FINAL_SAMPLE, \"Final Tuned (Fixed)\")\n",
    "    \n",
    "    if final_result:\n",
    "        fake_rate = final_result.get('fake_classification_rate', 0)\n",
    "        confidence = final_result.get('avg_fake_probability', 0)\n",
    "        f1_score = final_result.get('f1_score', 0)\n",
    "        accuracy = final_result.get('accuracy', 0)\n",
    "        \n",
    "        print(f\"\\nüìä Final Approach Results (Fixed):\")\n",
    "        print(f\"   Fake classification rate: {fake_rate:.1%}\")\n",
    "        print(f\"   Average fake confidence: {confidence:.3f}\")\n",
    "        print(f\"   F1 Score: {f1_score:.3f}\")\n",
    "        print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "        # Assessment\n",
    "        print(f\"\\nüéØ FINAL ASSESSMENT:\")\n",
    "        \n",
    "        if 0.7 <= f1_score <= 0.9:\n",
    "            f1_status = \"‚úÖ Perfect range (0.7-0.9)\"\n",
    "        elif 0.5 <= f1_score < 0.7:\n",
    "            f1_status = \"üü° Acceptable range (0.5-0.7)\"\n",
    "        elif f1_score >= 0.95:\n",
    "            f1_status = \"üö® Over-fitted (‚â•0.95)\"\n",
    "        else:\n",
    "            f1_status = \"‚ùå Under-fitted (<0.5)\"\n",
    "        \n",
    "        print(f\"   F1 Score: {f1_status}\")\n",
    "        \n",
    "        if 0.75 <= fake_rate <= 0.95:\n",
    "            fake_status = \"‚úÖ Realistic range (75-95%)\"\n",
    "        elif fake_rate > 0.95:\n",
    "            fake_status = \"üö® Too obvious (>95%)\"\n",
    "        else:\n",
    "            fake_status = \"‚ö†Ô∏è Too real-like (<75%)\"\n",
    "        \n",
    "        print(f\"   Fake Rate: {fake_status}\")\n",
    "        \n",
    "        # Final recommendation\n",
    "        if 0.7 <= f1_score <= 0.9 and 0.75 <= fake_rate <= 0.95:\n",
    "            print(f\"\\nüéâ SUCCESS! Optimal balance achieved\")\n",
    "        elif f1_score >= 0.5 and fake_rate >= 0.5:\n",
    "            print(f\"\\nüü° ACCEPTABLE - Workable results\")\n",
    "        else:\n",
    "            print(f\"\\n‚ùå STILL NEEDS WORK\")\n",
    "        \n",
    "        globals()['FINAL_RESULT_FIXED'] = final_result\n",
    "        \n",
    "else:\n",
    "    print(\"‚ùå Cannot retest - missing sample or evaluator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1acdd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç INVESTIGATING ENTITY EXTRACTION ISSUE\n",
      "============================================================\n",
      "üéØ Goal: Understand why generated articles have 0 entities\n",
      "\n",
      "üì∞ SAMPLE ARTICLE ANALYSIS:\n",
      "Preview (first 500 chars):\n",
      "In a high-stakes session at the Senate Foreign Relations Committee, top State Department officials faced intense scrutiny over the administration's foreign policy decisions. The hearing, held at the Capitol building in Washington, D.C., saw Senators from both parties questioning the officials on a range of critical issues impacting global relations. Chairman of the committee, Senator Rebecca Thompson, set the tone for the hearing by emphasizing the importance of the State Department's role in sh...\n",
      "\n",
      "üîç Manual Entity Extraction:\n",
      "   PERSON entities: 16 - ['Rebecca Thompson', 'Thompson', 'Samuel Harris', 'Harris', 'Michael Reynolds']\n",
      "   ORG entities: 15 - ['the Senate Foreign Relations Committee', 'State Department', \"the State Department's\", 'State', \"the State Department's\"]\n",
      "   GPE entities: 9 - ['Washington', 'D.C.', 'U.S.', 'America', 'U.S.']\n",
      "\n",
      "‚úÖ Entities found - may be feature extractor issue\n",
      "\n",
      "üß™ Testing Feature Extractor:\n",
      "   Feature extractor PERSON: 0\n",
      "   Feature extractor ORG: 0\n",
      "   Feature extractor GPE: 0\n",
      "\n",
      "üö® MISMATCH: Feature extractor gives different results than spaCy\n",
      "\n",
      "üîç TEXT PATTERN ANALYSIS:\n",
      "   Title patterns found: 16\n",
      "   Examples: ['Senator Rebecca', 'Senator Thompson', 'Senator Michael', 'Senator Reynolds', 'Senator Reynolds']\n",
      "   Organization patterns found: 7\n",
      "   Examples: ['Relations Committee', 'the committee', 'the committee', 'the committee', 'the committee']\n",
      "\n",
      "üí° INSIGHT: Articles contain name/org patterns but entities not extracted\n",
      "   This suggests entity recognition is the bottleneck\n"
     ]
    }
   ],
   "source": [
    "# Investigate Entity Extraction Issue\n",
    "print(\"üîç INVESTIGATING ENTITY EXTRACTION ISSUE\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Understand why generated articles have 0 entities\")\n",
    "\n",
    "if 'final_sample' in globals() and len(FINAL_SAMPLE) > 0:\n",
    "    \n",
    "    # Check first article manually\n",
    "    sample_article = FINAL_SAMPLE[0]\n",
    "    article_text = sample_article['article']\n",
    "    \n",
    "    print(f\"\\nüì∞ SAMPLE ARTICLE ANALYSIS:\")\n",
    "    print(f\"Preview (first 500 chars):\")\n",
    "    print(f\"{article_text[:500]}...\")\n",
    "    \n",
    "    # Manual entity check\n",
    "    import spacy\n",
    "    \n",
    "    # Load spacy model for entity extraction (same as feature extractor likely uses)\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "        doc = nlp(article_text)\n",
    "        \n",
    "        print(f\"\\nüîç Manual Entity Extraction:\")\n",
    "        \n",
    "        persons = []\n",
    "        orgs = []\n",
    "        gpes = []\n",
    "        \n",
    "        for ent in doc.ents:\n",
    "            if ent.label_ == \"PERSON\":\n",
    "                persons.append(ent.text)\n",
    "            elif ent.label_ == \"ORG\":\n",
    "                orgs.append(ent.text)\n",
    "            elif ent.label_ == \"GPE\":\n",
    "                gpes.append(ent.text)\n",
    "        \n",
    "        print(f\"   PERSON entities: {len(persons)} - {persons[:5]}\")  # Show first 5\n",
    "        print(f\"   ORG entities: {len(orgs)} - {orgs[:5]}\")\n",
    "        print(f\"   GPE entities: {len(gpes)} - {gpes[:5]}\")\n",
    "        \n",
    "        if len(persons) == 0 and len(orgs) == 0:\n",
    "            print(f\"\\nüö® PROBLEM IDENTIFIED: No entities found in generated text\")\n",
    "            print(f\"   Likely causes:\")\n",
    "            print(f\"   ‚Ä¢ LLM not generating specific names despite prompts\")\n",
    "            print(f\"   ‚Ä¢ Generated names not recognized by spaCy\")\n",
    "            print(f\"   ‚Ä¢ Feature extractor using different entity recognition\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Entities found - may be feature extractor issue\")\n",
    "            \n",
    "        # Check if our feature extractor gets same results\n",
    "        print(f\"\\nüß™ Testing Feature Extractor:\")\n",
    "        extracted_features = feature_extractor.extract_features(article_text)\n",
    "        \n",
    "        fe_persons = extracted_features.get('person_entities', 0)\n",
    "        fe_orgs = extracted_features.get('org_entities', 0)\n",
    "        fe_gpes = extracted_features.get('gpe_entities', 0)\n",
    "        \n",
    "        print(f\"   Feature extractor PERSON: {fe_persons}\")\n",
    "        print(f\"   Feature extractor ORG: {fe_orgs}\")  \n",
    "        print(f\"   Feature extractor GPE: {fe_gpes}\")\n",
    "        \n",
    "        if fe_persons != len(persons) or fe_orgs != len(orgs):\n",
    "            print(f\"\\nüö® MISMATCH: Feature extractor gives different results than spaCy\")\n",
    "        else:\n",
    "            print(f\"\\n‚úÖ Feature extractor matches spaCy results\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Could not load spaCy model: {e}\")\n",
    "        print(f\"üí° Try: python -m spacy download en_core_web_sm\")\n",
    "    \n",
    "    # Check for common name patterns in text\n",
    "    print(f\"\\nüîç TEXT PATTERN ANALYSIS:\")\n",
    "    \n",
    "    # Look for title patterns that suggest names\n",
    "    import re\n",
    "    \n",
    "    # Common title patterns\n",
    "    title_patterns = [\n",
    "        r'Senator \\w+',\n",
    "        r'Representative \\w+', \n",
    "        r'Congressman \\w+',\n",
    "        r'President \\w+',\n",
    "        r'Secretary \\w+',\n",
    "        r'Director \\w+',\n",
    "        r'Chairman \\w+',\n",
    "        r'Justice \\w+'\n",
    "    ]\n",
    "    \n",
    "    found_titles = []\n",
    "    for pattern in title_patterns:\n",
    "        matches = re.findall(pattern, article_text, re.IGNORECASE)\n",
    "        found_titles.extend(matches)\n",
    "    \n",
    "    print(f\"   Title patterns found: {len(found_titles)}\")\n",
    "    print(f\"   Examples: {found_titles[:5]}\")\n",
    "    \n",
    "    # Look for organization patterns\n",
    "    org_patterns = [\n",
    "        r'Department of \\w+',\n",
    "        r'\\w+ Committee',\n",
    "        r'\\w+ Commission',\n",
    "        r'\\w+ Agency',\n",
    "        r'House of Representatives',\n",
    "        r'Supreme Court',\n",
    "        r'White House'\n",
    "    ]\n",
    "    \n",
    "    found_orgs = []\n",
    "    for pattern in org_patterns:\n",
    "        matches = re.findall(pattern, article_text, re.IGNORECASE)\n",
    "        found_orgs.extend(matches)\n",
    "    \n",
    "    print(f\"   Organization patterns found: {len(found_orgs)}\")\n",
    "    print(f\"   Examples: {found_orgs[:5]}\")\n",
    "    \n",
    "    if len(found_titles) > 0 or len(found_orgs) > 0:\n",
    "        print(f\"\\nüí° INSIGHT: Articles contain name/org patterns but entities not extracted\")\n",
    "        print(f\"   This suggests entity recognition is the bottleneck\")\n",
    "    else:\n",
    "        print(f\"\\nüí° INSIGHT: Articles lack proper name/organization patterns\")\n",
    "        print(f\"   This suggests generation prompts need improvement\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No final sample available for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fb157881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß FIXING FEATURE EXTRACTOR\n",
      "============================================================\n",
      "üéØ Goal: Update feature extractor to use spaCy entity recognition\n",
      "‚úÖ spaCy model loaded successfully\n",
      "\n",
      "üß™ Testing Improved Feature Extractor:\n",
      "   Improved person_entities: 14\n",
      "   Improved org_entities: 7\n",
      "   Improved gpe_entities: 4\n",
      "   Original person_mentions: 33\n",
      "   Original org_mentions: 9\n",
      "   ‚úÖ Improved extractor works - entities detected!\n",
      "   üîÑ Global feature extractor updated\n",
      "\n",
      "üîÑ Regenerating features for final sample...\n",
      "   ‚úÖ Final sample features updated\n"
     ]
    }
   ],
   "source": [
    "# Fix Feature Extractor to Use Proper Entity Recognition\n",
    "print(\"üîß FIXING FEATURE EXTRACTOR\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Update feature extractor to use spaCy entity recognition\")\n",
    "\n",
    "# Create improved feature extractor that uses spaCy properly\n",
    "class ImprovedArticleFeatureExtractor:\n",
    "    \"\"\"\n",
    "    Improved feature extractor that uses proper spaCy entity recognition\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Download required NLTK data\n",
    "        try:\n",
    "            nltk.download('punkt', quiet=True)\n",
    "            nltk.download('stopwords', quiet=True)\n",
    "            nltk.download('vader_lexicon', quiet=True)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        self.stop_words = set(stopwords.words('english')) if nltk else set()\n",
    "        \n",
    "        # Load spaCy model\n",
    "        try:\n",
    "            import spacy\n",
    "            self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "            self.spacy_available = True\n",
    "            print(\"‚úÖ spaCy model loaded successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è spaCy not available: {e}\")\n",
    "            self.spacy_available = False\n",
    "    \n",
    "    def extract_features(self, text: str) -> Dict[str, float]:\n",
    "        \"\"\"Extract comprehensive features with proper entity recognition\"\"\"\n",
    "        if not isinstance(text, str) or len(text.strip()) == 0:\n",
    "            return {}\n",
    "        \n",
    "        features = {}\n",
    "        \n",
    "        # Basic text statistics\n",
    "        words = text.split()\n",
    "        sentences = sent_tokenize(text)\n",
    "        \n",
    "        features['word_count'] = len(words)\n",
    "        features['char_count'] = len(text)\n",
    "        features['sentence_count'] = len(sentences)\n",
    "        features['avg_sentence_length'] = len(words) / max(len(sentences), 1)\n",
    "        features['avg_word_length'] = np.mean([len(word) for word in words]) if words else 0\n",
    "        \n",
    "        # Subjectivity and polarity\n",
    "        try:\n",
    "            blob = TextBlob(text)\n",
    "            features['subjectivity'] = blob.sentiment.subjectivity\n",
    "            features['polarity'] = blob.sentiment.polarity\n",
    "        except:\n",
    "            features['subjectivity'] = 0\n",
    "            features['polarity'] = 0\n",
    "        \n",
    "        # Punctuation features\n",
    "        features['commas'] = text.count(',')\n",
    "        features['semicolons'] = text.count(';')\n",
    "        features['colons'] = text.count(':')\n",
    "        features['dashes'] = text.count('-')\n",
    "        features['question_marks'] = text.count('?')\n",
    "        features['exclamation_marks'] = text.count('!')\n",
    "        features['quotation_marks'] = text.count('\"') + text.count(\"'\")\n",
    "        features['ellipsis'] = text.count('...')\n",
    "        \n",
    "        # PROPER ENTITY RECOGNITION using spaCy\n",
    "        if self.spacy_available:\n",
    "            try:\n",
    "                doc = self.nlp(text)\n",
    "                \n",
    "                # Count unique entities by type\n",
    "                persons = set()\n",
    "                orgs = set()\n",
    "                gpes = set()\n",
    "                dates = set()\n",
    "                \n",
    "                for ent in doc.ents:\n",
    "                    if ent.label_ == \"PERSON\":\n",
    "                        persons.add(ent.text.lower())\n",
    "                    elif ent.label_ == \"ORG\":\n",
    "                        orgs.add(ent.text.lower())\n",
    "                    elif ent.label_ == \"GPE\":  # Geopolitical entities\n",
    "                        gpes.add(ent.text.lower())\n",
    "                    elif ent.label_ == \"DATE\":\n",
    "                        dates.add(ent.text.lower())\n",
    "                \n",
    "                # Use actual counts (this is the fix!)\n",
    "                features['person_entities'] = len(persons)\n",
    "                features['org_entities'] = len(orgs)\n",
    "                features['gpe_entities'] = len(gpes)\n",
    "                features['date_entities'] = len(dates)\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"   spaCy error: {e}\")\n",
    "                # Fallback to zero if spaCy fails\n",
    "                features['person_entities'] = 0\n",
    "                features['org_entities'] = 0\n",
    "                features['gpe_entities'] = 0\n",
    "                features['date_entities'] = 0\n",
    "        else:\n",
    "            # Fallback if spaCy not available\n",
    "            features['person_entities'] = 0\n",
    "            features['org_entities'] = 0\n",
    "            features['gpe_entities'] = 0\n",
    "            features['date_entities'] = 0\n",
    "        \n",
    "        # Readability metrics\n",
    "        try:\n",
    "            features['gunning_fog'] = textstat.gunning_fog(text)\n",
    "            features['flesch_reading_ease'] = textstat.flesch_reading_ease(text)\n",
    "            features['smog_index'] = textstat.smog_index(text)\n",
    "        except:\n",
    "            features['gunning_fog'] = 0\n",
    "            features['flesch_reading_ease'] = 0\n",
    "            features['smog_index'] = 0\n",
    "        \n",
    "        # Social media and pattern indicators\n",
    "        social_indicators = ['twitter', 'facebook', 'social media', 'video', 'image']\n",
    "        features['social_media_mentions'] = sum(text.lower().count(indicator) for indicator in social_indicators)\n",
    "        \n",
    "        return features\n",
    "    \n",
    "    def validate_against_targets(self, features: Dict, targets: Dict) -> Dict:\n",
    "        \"\"\"Validate features against target ranges\"\"\"\n",
    "        validation = {}\n",
    "        \n",
    "        for feature, target_range in targets.items():\n",
    "            if feature in features:\n",
    "                value = features[feature]\n",
    "                min_val, max_val = target_range\n",
    "                \n",
    "                validation[feature] = {\n",
    "                    'value': value,\n",
    "                    'target_min': min_val,\n",
    "                    'target_max': max_val,\n",
    "                    'in_range': min_val <= value <= max_val,\n",
    "                    'distance_from_target': min(abs(value - min_val), abs(value - max_val)) if not (min_val <= value <= max_val) else 0\n",
    "                }\n",
    "        \n",
    "        return validation\n",
    "\n",
    "# Replace the global feature extractor\n",
    "improved_extractor = ImprovedArticleFeatureExtractor()\n",
    "\n",
    "# Test on our sample article\n",
    "if 'final_sample' in globals() and len(FINAL_SAMPLE) > 0:\n",
    "    \n",
    "    test_article = FINAL_SAMPLE[0]['article']\n",
    "    \n",
    "    print(f\"\\nüß™ Testing Improved Feature Extractor:\")\n",
    "    \n",
    "    # Extract with improved extractor\n",
    "    improved_features = improved_extractor.extract_features(test_article)\n",
    "    \n",
    "    print(f\"   Improved person_entities: {improved_features.get('person_entities', 0)}\")\n",
    "    print(f\"   Improved org_entities: {improved_features.get('org_entities', 0)}\")\n",
    "    print(f\"   Improved gpe_entities: {improved_features.get('gpe_entities', 0)}\")\n",
    "    \n",
    "    # Compare to original\n",
    "    original_features = feature_extractor.extract_features(test_article)\n",
    "    \n",
    "    print(f\"   Original person_mentions: {original_features.get('person_mentions', 0)}\")\n",
    "    print(f\"   Original org_mentions: {original_features.get('org_mentions', 0)}\")\n",
    "    \n",
    "    if improved_features.get('person_entities', 0) > 0 or improved_features.get('org_entities', 0) > 0:\n",
    "        print(f\"   ‚úÖ Improved extractor works - entities detected!\")\n",
    "        \n",
    "        # Update the global feature extractor\n",
    "        globals()['feature_extractor'] = improved_extractor\n",
    "        print(f\"   üîÑ Global feature extractor updated\")\n",
    "        \n",
    "        # Regenerate features for final sample using improved extractor\n",
    "        print(f\"\\nüîÑ Regenerating features for final sample...\")\n",
    "        for article in FINAL_SAMPLE:\n",
    "            article['features'] = improved_extractor.extract_features(article['article'])\n",
    "        \n",
    "        print(f\"   ‚úÖ Final sample features updated\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"   ‚ùå Still no entities detected - may need spaCy installation\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå No final sample available for testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "110cadde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéâ RETESTING WITH FIXED ENTITY EXTRACTION\n",
      "============================================================\n",
      "üéØ Goal: Test classification performance with proper entity counts\n",
      "\n",
      "üìä Updated Feature Summary (first 5 articles):\n",
      "   Article 1: 14 people, 7 orgs, 4 locations\n",
      "   Article 2: 9 people, 8 orgs, 2 locations\n",
      "   Article 3: 10 people, 8 orgs, 5 locations\n",
      "   Article 4: 11 people, 8 orgs, 1 locations\n",
      "   Article 5: 11 people, 10 orgs, 7 locations\n",
      "\n",
      "üìà Updated Average Features:\n",
      "   Person entities: 9.6 (target: 8-17)\n",
      "   Org entities: 8.9 (target: 5-12)\n",
      "   Sentences: 25.3 (target: 17-29)\n",
      "   Commas: 31.0 (target: 16-27)\n",
      "   Subjectivity: 0.414 (target: 0.45-0.65)\n",
      "\n",
      "ü§ñ Retesting Classification with Proper Entities...\n",
      "\n",
      "üîç Evaluating Final Fixed Entities approach...\n",
      "   üìä Results for Final Fixed Entities:\n",
      "      Accuracy: 0.000 (higher = better fake detection)\n",
      "      F1 Score: 0.000\n",
      "      Fake classification rate: 0.000\n",
      "      Avg fake probability: 0.053\n",
      "      High confidence fake (>0.7): 0.000\n",
      "\n",
      "üéØ FINAL RESULTS WITH PROPER ENTITIES:\n",
      "   Fake classification rate: 0.0%\n",
      "   Average fake confidence: 0.053\n",
      "   F1 Score: 0.000\n",
      "   Accuracy: 0.000\n",
      "\n",
      "üìã FINAL ASSESSMENT:\n",
      "   F1 Score: ‚ùå Under-fitted (<0.5)\n",
      "   Fake Rate: ‚ö†Ô∏è Too real-like (<75%)\n",
      "   Entities: ‚úÖ Good entity counts\n",
      "\n",
      "============================================================\n",
      "‚ùå STILL NEEDS SIGNIFICANT WORK\n",
      "   F1 Score: 0.000 (problematic)\n",
      "\n",
      "üìä COMPLETE APPROACH COMPARISON:\n",
      "   Enhanced v1-v3: F1=1.0 (over-fitted - too obvious)\n",
      "   Balanced/Optimized: F1=0.0 (under-fitted - no entities)\n",
      "   Final + Fixed Entities: F1=0.000 (NEEDS WORK)\n"
     ]
    }
   ],
   "source": [
    "# Retest Final Approach with Fixed Entity Extraction\n",
    "print(\"üéâ RETESTING WITH FIXED ENTITY EXTRACTION\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Test classification performance with proper entity counts\")\n",
    "\n",
    "if 'final_sample' in globals() and 'evaluator' in globals():\n",
    "    \n",
    "    # Quick feature check of updated sample\n",
    "    print(f\"\\nüìä Updated Feature Summary (first 5 articles):\")\n",
    "    \n",
    "    for i in range(min(5, len(FINAL_SAMPLE))):\n",
    "        features = FINAL_SAMPLE[i]['features']\n",
    "        persons = features.get('person_entities', 0)\n",
    "        orgs = features.get('org_entities', 0)\n",
    "        gpes = features.get('gpe_entities', 0)\n",
    "        print(f\"   Article {i+1}: {persons} people, {orgs} orgs, {gpes} locations\")\n",
    "    \n",
    "    # Calculate average features\n",
    "    all_features = [art['features'] for art in FINAL_SAMPLE]\n",
    "    \n",
    "    avg_persons = np.mean([f.get('person_entities', 0) for f in all_features])\n",
    "    avg_orgs = np.mean([f.get('org_entities', 0) for f in all_features])\n",
    "    avg_sentences = np.mean([f.get('sentence_count', 0) for f in all_features])\n",
    "    avg_commas = np.mean([f.get('commas', 0) for f in all_features])\n",
    "    avg_subjectivity = np.mean([f.get('subjectivity', 0) for f in all_features])\n",
    "    \n",
    "    print(f\"\\nüìà Updated Average Features:\")\n",
    "    print(f\"   Person entities: {avg_persons:.1f} (target: 8-17)\")\n",
    "    print(f\"   Org entities: {avg_orgs:.1f} (target: 5-12)\")\n",
    "    print(f\"   Sentences: {avg_sentences:.1f} (target: 17-29)\")\n",
    "    print(f\"   Commas: {avg_commas:.1f} (target: 16-27)\")\n",
    "    print(f\"   Subjectivity: {avg_subjectivity:.3f} (target: 0.45-0.65)\")\n",
    "    \n",
    "    # Now retest classification\n",
    "    print(f\"\\nü§ñ Retesting Classification with Proper Entities...\")\n",
    "    \n",
    "    final_result_fixed = evaluator.evaluate_synthetic_approach(FINAL_SAMPLE, \"Final Fixed Entities\")\n",
    "    \n",
    "    if final_result_fixed:\n",
    "        fake_rate = final_result_fixed.get('fake_classification_rate', 0)\n",
    "        confidence = final_result_fixed.get('avg_fake_probability', 0)\n",
    "        f1_score = final_result_fixed.get('f1_score', 0)\n",
    "        accuracy = final_result_fixed.get('accuracy', 0)\n",
    "        \n",
    "        print(f\"\\nüéØ FINAL RESULTS WITH PROPER ENTITIES:\")\n",
    "        print(f\"   Fake classification rate: {fake_rate:.1%}\")\n",
    "        print(f\"   Average fake confidence: {confidence:.3f}\")\n",
    "        print(f\"   F1 Score: {f1_score:.3f}\")\n",
    "        print(f\"   Accuracy: {accuracy:.3f}\")\n",
    "        \n",
    "        # Assessment\n",
    "        print(f\"\\nüìã FINAL ASSESSMENT:\")\n",
    "        \n",
    "        if 0.7 <= f1_score <= 0.9:\n",
    "            f1_status = \"üéâ PERFECT RANGE! (0.7-0.9)\"\n",
    "            success = True\n",
    "        elif 0.5 <= f1_score < 0.7:\n",
    "            f1_status = \"üü° Acceptable (0.5-0.7)\"\n",
    "            success = True\n",
    "        elif f1_score >= 0.95:\n",
    "            f1_status = \"üö® Over-fitted (‚â•0.95)\"\n",
    "            success = False\n",
    "        else:\n",
    "            f1_status = \"‚ùå Under-fitted (<0.5)\"\n",
    "            success = False\n",
    "        \n",
    "        print(f\"   F1 Score: {f1_status}\")\n",
    "        \n",
    "        if 0.75 <= fake_rate <= 0.95:\n",
    "            fake_status = \"‚úÖ Realistic range (75-95%)\"\n",
    "        elif fake_rate > 0.95:\n",
    "            fake_status = \"üö® Too obvious (>95%)\"\n",
    "        else:\n",
    "            fake_status = \"‚ö†Ô∏è Too real-like (<75%)\"\n",
    "        \n",
    "        print(f\"   Fake Rate: {fake_status}\")\n",
    "        \n",
    "        # Entity alignment check\n",
    "        entity_check = (5 <= avg_persons <= 20) and (3 <= avg_orgs <= 15)\n",
    "        entity_status = \"‚úÖ Good entity counts\" if entity_check else \"‚ö†Ô∏è Entity counts off\"\n",
    "        print(f\"   Entities: {entity_status}\")\n",
    "        \n",
    "        # Final verdict\n",
    "        print(f\"\\n{'='*60}\")\n",
    "        if success and 0.75 <= fake_rate <= 0.95 and entity_check:\n",
    "            print(f\"üéâ SUCCESS! READY FOR FULL-SCALE GENERATION\")\n",
    "            print(f\"   F1 Score: {f1_score:.3f} (optimal range)\")\n",
    "            print(f\"   Fake Rate: {fake_rate:.1%} (realistic)\")\n",
    "            print(f\"   Entity counts: Properly balanced\")\n",
    "            print(f\"   ‚úÖ This approach can generate realistic fake news patterns\")\n",
    "        elif success:\n",
    "            print(f\"üü° GOOD PROGRESS - Minor refinements needed\")\n",
    "            print(f\"   F1 Score: {f1_score:.3f} (acceptable)\")\n",
    "            print(f\"   Can proceed with cautious scaling\")\n",
    "        else:\n",
    "            print(f\"‚ùå STILL NEEDS SIGNIFICANT WORK\")\n",
    "            print(f\"   F1 Score: {f1_score:.3f} (problematic)\")\n",
    "        \n",
    "        # Store final result\n",
    "        globals()['FINAL_RESULT_WITH_ENTITIES'] = final_result_fixed\n",
    "        \n",
    "        # Compare all approaches summary\n",
    "        print(f\"\\nüìä COMPLETE APPROACH COMPARISON:\")\n",
    "        print(f\"   Enhanced v1-v3: F1=1.0 (over-fitted - too obvious)\")\n",
    "        print(f\"   Balanced/Optimized: F1=0.0 (under-fitted - no entities)\")\n",
    "        print(f\"   Final + Fixed Entities: F1={f1_score:.3f} ({'SUCCESS' if success else 'NEEDS WORK'})\")\n",
    "        \n",
    "    else:\n",
    "        print(f\"\\n‚ùå Classification test failed\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Missing final sample or evaluator for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acea2d1f",
   "metadata": {},
   "source": [
    "## Large Sample Testing: 100 Articles per Enhanced Approach\n",
    "\n",
    "Testing hypothesis that F1=1.0 was due to small sample size (20 articles). \n",
    "Generating 100 articles for each enhanced approach (v1, v2, v3) to get more reliable F1 scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d2984650",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Generating 100 articles for each enhanced approach...\n",
      "This will test if F1=1.0 was due to small sample size or actual over-fitting\n",
      "\n",
      "üì∞ Generating 100 articles for Enhanced v1 (prompt version 1)...\n",
      "üöÄ Enhanced Zero-Shot Generation v1 (100 articles)\n",
      "   Generated 20/100 enhanced articles...\n",
      "   Generated 20/100 enhanced articles...\n",
      "   Generated 40/100 enhanced articles...\n",
      "   Generated 40/100 enhanced articles...\n",
      "   Generated 60/100 enhanced articles...\n",
      "   Generated 60/100 enhanced articles...\n",
      "   Generated 80/100 enhanced articles...\n",
      "   Generated 80/100 enhanced articles...\n",
      "   Generated 100/100 enhanced articles...\n",
      "   Generated 100/100 enhanced articles...\n",
      "‚úÖ Enhanced zero-shot generation complete: 100 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 100/100 (100.0%)\n",
      "   Political figure references: 100/100 (100.0%)\n",
      "   Visual element references: 100/100 (100.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 16.0 (target: 17-29)\n",
      "   Commas: 20.0 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.386 (target: 0.45-0.65)\n",
      "‚úÖ Generated 100 articles for v1\n",
      "   Preview: In a recent twist of events, leaked communications within the Republican Party have stirred up a storm on social media platforms, sparking heated debates and discussions across the political spectrum....\n",
      "\n",
      "üì∞ Generating 100 articles for Enhanced v2 (prompt version 2)...\n",
      "üöÄ Enhanced Zero-Shot Generation v2 (100 articles)\n",
      "‚úÖ Enhanced zero-shot generation complete: 100 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 100/100 (100.0%)\n",
      "   Political figure references: 100/100 (100.0%)\n",
      "   Visual element references: 100/100 (100.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 16.0 (target: 17-29)\n",
      "   Commas: 20.0 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.386 (target: 0.45-0.65)\n",
      "‚úÖ Generated 100 articles for v1\n",
      "   Preview: In a recent twist of events, leaked communications within the Republican Party have stirred up a storm on social media platforms, sparking heated debates and discussions across the political spectrum....\n",
      "\n",
      "üì∞ Generating 100 articles for Enhanced v2 (prompt version 2)...\n",
      "üöÄ Enhanced Zero-Shot Generation v2 (100 articles)\n",
      "   Generated 20/100 enhanced articles...\n",
      "   Generated 20/100 enhanced articles...\n",
      "   Generated 40/100 enhanced articles...\n",
      "   Generated 40/100 enhanced articles...\n",
      "   Generated 60/100 enhanced articles...\n",
      "   Generated 60/100 enhanced articles...\n",
      "   Generated 80/100 enhanced articles...\n",
      "   Generated 80/100 enhanced articles...\n",
      "   Generated 100/100 enhanced articles...\n",
      "   Generated 100/100 enhanced articles...\n",
      "‚úÖ Enhanced zero-shot generation complete: 100 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 99/100 (99.0%)\n",
      "   Political figure references: 100/100 (100.0%)\n",
      "   Visual element references: 99/100 (99.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 23.2 (target: 17-29)\n",
      "   Commas: 25.6 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.425 (target: 0.45-0.65)\n",
      "‚úÖ Generated 100 articles for v2\n",
      "   Preview: In a year-old precedent-breaking move that has sent shockwaves through the political landscape, a controversial tweet from a prominent political figure has ignited a firestorm of public outrage and de...\n",
      "\n",
      "üì∞ Generating 100 articles for Enhanced v3 (prompt version 3)...\n",
      "üöÄ Enhanced Zero-Shot Generation v3 (100 articles)\n",
      "‚úÖ Enhanced zero-shot generation complete: 100 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 99/100 (99.0%)\n",
      "   Political figure references: 100/100 (100.0%)\n",
      "   Visual element references: 99/100 (99.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 23.2 (target: 17-29)\n",
      "   Commas: 25.6 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.425 (target: 0.45-0.65)\n",
      "‚úÖ Generated 100 articles for v2\n",
      "   Preview: In a year-old precedent-breaking move that has sent shockwaves through the political landscape, a controversial tweet from a prominent political figure has ignited a firestorm of public outrage and de...\n",
      "\n",
      "üì∞ Generating 100 articles for Enhanced v3 (prompt version 3)...\n",
      "üöÄ Enhanced Zero-Shot Generation v3 (100 articles)\n",
      "   Generated 20/100 enhanced articles...\n",
      "   Generated 20/100 enhanced articles...\n",
      "   Generated 40/100 enhanced articles...\n",
      "   Generated 40/100 enhanced articles...\n",
      "   Generated 60/100 enhanced articles...\n",
      "   Generated 60/100 enhanced articles...\n",
      "   Generated 80/100 enhanced articles...\n",
      "   Generated 80/100 enhanced articles...\n",
      "   Generated 100/100 enhanced articles...\n",
      "   Generated 100/100 enhanced articles...\n",
      "‚úÖ Enhanced zero-shot generation complete: 100 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 100/100 (100.0%)\n",
      "   Political figure references: 99/100 (99.0%)\n",
      "   Visual element references: 99/100 (99.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 17.6 (target: 17-29)\n",
      "   Commas: 23.9 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.405 (target: 0.45-0.65)\n",
      "‚úÖ Generated 100 articles for v3\n",
      "   Preview: In a whirlwind of political upheaval, the latest controversial tweet from none other than Donald Trump, known by his handle @realdonaldtrump, has ignited a firestorm of public outrage and debate acros...\n",
      "\n",
      "üéØ Large sample generation complete!\n",
      "Total articles generated: 300\n",
      "Enhanced v1: 100 articles\n",
      "Enhanced v2: 100 articles\n",
      "Enhanced v3: 100 articles\n",
      "‚úÖ Enhanced zero-shot generation complete: 100 articles\n",
      "\n",
      "üìä PATTERN MATCHING ANALYSIS:\n",
      "   Social media integration: 100/100 (100.0%)\n",
      "   Political figure references: 99/100 (99.0%)\n",
      "   Visual element references: 99/100 (99.0%)\n",
      "\n",
      "üìà FEATURE ALIGNMENT:\n",
      "   Sentences: 17.6 (target: 17-29)\n",
      "   Commas: 23.9 (target: 16-27)\n",
      "   Person entities: 0.0 (target: 8-17)\n",
      "   Org entities: 0.0 (target: 5-12)\n",
      "   Subjectivity: 0.405 (target: 0.45-0.65)\n",
      "‚úÖ Generated 100 articles for v3\n",
      "   Preview: In a whirlwind of political upheaval, the latest controversial tweet from none other than Donald Trump, known by his handle @realdonaldtrump, has ignited a firestorm of public outrage and debate acros...\n",
      "\n",
      "üéØ Large sample generation complete!\n",
      "Total articles generated: 300\n",
      "Enhanced v1: 100 articles\n",
      "Enhanced v2: 100 articles\n",
      "Enhanced v3: 100 articles\n"
     ]
    }
   ],
   "source": [
    "# Large Sample Generation for Enhanced Approaches\n",
    "print(\"üîÑ Generating 100 articles for each enhanced approach...\")\n",
    "print(\"This will test if F1=1.0 was due to small sample size or actual over-fitting\")\n",
    "print()\n",
    "\n",
    "# Configuration for large sample test\n",
    "LARGE_SAMPLE_SIZE = 100\n",
    "ENHANCED_VERSIONS = {\n",
    "    'v1': 1,\n",
    "    'v2': 2, \n",
    "    'v3': 3\n",
    "}\n",
    "\n",
    "# Initialize storage for large samples\n",
    "LARGE_ENHANCED_SAMPLES = {}\n",
    "LARGE_SAMPLE_RESULTS = {}\n",
    "\n",
    "# Generate samples\n",
    "for version, prompt_version in ENHANCED_VERSIONS.items():\n",
    "    print(f\"üì∞ Generating {LARGE_SAMPLE_SIZE} articles for Enhanced {version} (prompt version {prompt_version})...\")\n",
    "    \n",
    "    try:\n",
    "        # Generate large sample using enhanced generator with correct method\n",
    "        large_sample = enhanced_generator.generate_enhanced_zero_shot(\n",
    "            count=LARGE_SAMPLE_SIZE,\n",
    "            prompt_version=prompt_version\n",
    "        )\n",
    "        \n",
    "        LARGE_ENHANCED_SAMPLES[version] = large_sample\n",
    "        print(f\"‚úÖ Generated {len(large_sample)} articles for {version}\")\n",
    "        \n",
    "        # Show preview of first article\n",
    "        if large_sample:\n",
    "            preview_text = large_sample[0].get('article', large_sample[0].get('text', ''))[:200] + \"...\"\n",
    "            print(f\"   Preview: {preview_text}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating {version}: {str(e)}\")\n",
    "        LARGE_ENHANCED_SAMPLES[version] = []\n",
    "    \n",
    "    print()\n",
    "\n",
    "print(f\"üéØ Large sample generation complete!\")\n",
    "print(f\"Total articles generated: {sum(len(articles) for articles in LARGE_ENHANCED_SAMPLES.values())}\")\n",
    "\n",
    "# Summary\n",
    "for version, articles in LARGE_ENHANCED_SAMPLES.items():\n",
    "    print(f\"Enhanced {version}: {len(articles)} articles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b0f8b4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî¨ Evaluating large samples with fake news classification...\n",
      "\n",
      "üìä Testing Enhanced v1 with 100 articles...\n",
      "\n",
      "üîç Evaluating Enhanced_v1_Large_Sample approach...\n",
      "   üìä Results for Enhanced_v1_Large_Sample:\n",
      "      Accuracy: 0.990 (higher = better fake detection)\n",
      "      F1 Score: 0.995\n",
      "      Fake classification rate: 0.990\n",
      "      Avg fake probability: 0.905\n",
      "      High confidence fake (>0.7): 0.950\n",
      "   F1 Score: 0.995\n",
      "   Accuracy: 0.990\n",
      "   Fake Classification Rate: 99.0%\n",
      "   Status: üö® OVER-FITTED (F1 ‚â• 0.95)\n",
      "\n",
      "üìä Testing Enhanced v2 with 100 articles...\n",
      "\n",
      "üîç Evaluating Enhanced_v2_Large_Sample approach...\n",
      "   üìä Results for Enhanced_v2_Large_Sample:\n",
      "      Accuracy: 0.970 (higher = better fake detection)\n",
      "      F1 Score: 0.985\n",
      "      Fake classification rate: 0.970\n",
      "      Avg fake probability: 0.833\n",
      "      High confidence fake (>0.7): 0.850\n",
      "   F1 Score: 0.985\n",
      "   Accuracy: 0.970\n",
      "   Fake Classification Rate: 97.0%\n",
      "   Status: üö® OVER-FITTED (F1 ‚â• 0.95)\n",
      "\n",
      "üìä Testing Enhanced v3 with 100 articles...\n",
      "\n",
      "üîç Evaluating Enhanced_v3_Large_Sample approach...\n",
      "   üìä Results for Enhanced_v3_Large_Sample:\n",
      "      Accuracy: 0.990 (higher = better fake detection)\n",
      "      F1 Score: 0.995\n",
      "      Fake classification rate: 0.990\n",
      "      Avg fake probability: 0.923\n",
      "      High confidence fake (>0.7): 0.950\n",
      "   F1 Score: 0.995\n",
      "   Accuracy: 0.990\n",
      "   Fake Classification Rate: 99.0%\n",
      "   Status: üö® OVER-FITTED (F1 ‚â• 0.95)\n",
      "\n",
      "üìà LARGE SAMPLE RESULTS SUMMARY:\n",
      "==================================================\n",
      "Enhanced v1: F1=0.995, Fake Rate=99.0%\n",
      "Enhanced v2: F1=0.985, Fake Rate=97.0%\n",
      "Enhanced v3: F1=0.995, Fake Rate=99.0%\n",
      "\n",
      "‚ö†Ô∏è  No approaches in ideal F1 range (0.7-0.9)\n",
      "   Closest to range: Enhanced v2 (F1=0.985)\n",
      "\n",
      "üîç This test will show if small sample size was causing F1=1.0 artifacts\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Large Samples with Classification\n",
    "print(\"üî¨ Evaluating large samples with fake news classification...\")\n",
    "print()\n",
    "\n",
    "for version, articles in LARGE_ENHANCED_SAMPLES.items():\n",
    "    if not articles:\n",
    "        print(f\"‚ùå Skipping {version} - no articles generated\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"üìä Testing Enhanced {version} with {len(articles)} articles...\")\n",
    "    \n",
    "    try:\n",
    "        # Evaluate with classification using correct method name\n",
    "        result = evaluator.evaluate_synthetic_approach(\n",
    "            articles, \n",
    "            approach_name=f\"Enhanced_{version}_Large_Sample\"\n",
    "        )\n",
    "        \n",
    "        LARGE_SAMPLE_RESULTS[version] = result\n",
    "        \n",
    "        # Display results\n",
    "        print(f\"   F1 Score: {result['f1_score']:.3f}\")\n",
    "        print(f\"   Accuracy: {result['accuracy']:.3f}\")\n",
    "        print(f\"   Fake Classification Rate: {result['fake_classification_rate']:.1%}\")\n",
    "        \n",
    "        # Status assessment\n",
    "        f1 = result['f1_score']\n",
    "        if f1 >= 0.95:\n",
    "            status = \"üö® OVER-FITTED (F1 ‚â• 0.95)\"\n",
    "        elif f1 >= 0.7:\n",
    "            status = \"‚úÖ GOOD RANGE (0.7 ‚â§ F1 < 0.95)\"\n",
    "        elif f1 >= 0.3:\n",
    "            status = \"‚ö†Ô∏è  MODERATE (0.3 ‚â§ F1 < 0.7)\"\n",
    "        else:\n",
    "            status = \"‚ùå UNDER-FITTED (F1 < 0.3)\"\n",
    "            \n",
    "        print(f\"   Status: {status}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error evaluating {version}: {str(e)}\")\n",
    "        LARGE_SAMPLE_RESULTS[version] = None\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Summary comparison\n",
    "print(\"üìà LARGE SAMPLE RESULTS SUMMARY:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if LARGE_SAMPLE_RESULTS:\n",
    "    for version, result in LARGE_SAMPLE_RESULTS.items():\n",
    "        if result:\n",
    "            f1 = result['f1_score']\n",
    "            fake_rate = result['fake_classification_rate']\n",
    "            print(f\"Enhanced {version}: F1={f1:.3f}, Fake Rate={fake_rate:.1%}\")\n",
    "        else:\n",
    "            print(f\"Enhanced {version}: Failed to evaluate\")\n",
    "            \n",
    "    # Find best performing approach\n",
    "    valid_results = {v: r for v, r in LARGE_SAMPLE_RESULTS.items() if r is not None}\n",
    "    if valid_results:\n",
    "        # Best approach based on F1 score in good range (0.7-0.9)\n",
    "        good_range_results = {v: r for v, r in valid_results.items() \n",
    "                            if 0.7 <= r['f1_score'] <= 0.9}\n",
    "        \n",
    "        if good_range_results:\n",
    "            best_version = max(good_range_results.keys(), \n",
    "                             key=lambda v: good_range_results[v]['f1_score'])\n",
    "            print(f\"\\nüèÜ Best approach in good range: Enhanced {best_version} \"\n",
    "                  f\"(F1={good_range_results[best_version]['f1_score']:.3f})\")\n",
    "        else:\n",
    "            print(f\"\\n‚ö†Ô∏è  No approaches in ideal F1 range (0.7-0.9)\")\n",
    "            # Show closest to ideal range\n",
    "            closest = min(valid_results.keys(), \n",
    "                        key=lambda v: min(abs(valid_results[v]['f1_score'] - 0.7),\n",
    "                                        abs(valid_results[v]['f1_score'] - 0.9)))\n",
    "            print(f\"   Closest to range: Enhanced {closest} \"\n",
    "                  f\"(F1={valid_results[closest]['f1_score']:.3f})\")\n",
    "else:\n",
    "    print(\"‚ùå No successful evaluations\")\n",
    "\n",
    "print()\n",
    "print(\"üîç This test will show if small sample size was causing F1=1.0 artifacts\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fc6b56",
   "metadata": {},
   "source": [
    "## Critical Analysis: High F1 = Good Fake News Match or Over-fitting?\n",
    "\n",
    "ü§î **Key Question**: Do our F1 scores of 0.985-0.995 indicate:\n",
    "1. **SUCCESS**: Our synthetic articles match real fake news patterns perfectly\n",
    "2. **OVER-FITTING**: Our articles are too obviously synthetic/formulaic\n",
    "\n",
    "Let's analyze this by comparing against real fake news baseline performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a8b9b7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç REAL FAKE NEWS BASELINE ANALYSIS\n",
      "============================================================\n",
      "üéØ Goal: Determine if high F1 scores indicate success or over-fitting\n",
      "\n",
      "üìä Testing classifier on REAL FAKE NEWS (100 articles)...\n",
      "\n",
      "üîç Evaluating Real Fake News Baseline approach...\n",
      "   üìä Results for Real Fake News Baseline:\n",
      "      Accuracy: 0.970 (higher = better fake detection)\n",
      "      F1 Score: 0.985\n",
      "      Fake classification rate: 0.970\n",
      "      Avg fake probability: 0.943\n",
      "      High confidence fake (>0.7): 0.940\n",
      "\n",
      "üìà REAL FAKE NEWS PERFORMANCE:\n",
      "   F1 Score: 0.985\n",
      "   Fake classification rate: 97.0%\n",
      "   Average confidence: 0.943\n",
      "\n",
      "üî¨ COMPARISON WITH SYNTHETIC RESULTS:\n",
      "Approach             F1 Score   Fake Rate    Confidence  \n",
      "-------------------------------------------------------\n",
      "Real Fake News       0.985     97.0%       0.943      \n",
      "Synthetic v1         0.995     99.0%       0.905      \n",
      "Synthetic v2         0.985     97.0%       0.833      \n",
      "Synthetic v3         0.995     99.0%       0.923      \n",
      "\n",
      "üéØ CRITICAL INTERPRETATION:\n",
      "   üö® Real fake news also has F1 ‚â• 0.95!\n",
      "   üí° This suggests the classifier is VERY GOOD at detecting fake news\n",
      "   ‚úÖ Our synthetic F1 scores (0.985-0.995) are REALISTIC\n",
      "\n",
      "üîç CONFIDENCE ANALYSIS:\n",
      "   ‚úÖ Synthetic confidence (0.887) matches real (0.943)\n",
      "\n",
      "üèÜ FINAL VERDICT:\n",
      "   ‚úÖ HIGH F1 SCORES = SUCCESS!\n",
      "   üí° Our synthetic articles match real fake news patterns correctly\n",
      "   üéâ The enhanced approaches are working as intended\n"
     ]
    }
   ],
   "source": [
    "# Test Real Fake News Baseline Performance\n",
    "print(\"üîç REAL FAKE NEWS BASELINE ANALYSIS\")\n",
    "print(\"=\" * 60)\n",
    "print(\"üéØ Goal: Determine if high F1 scores indicate success or over-fitting\")\n",
    "\n",
    "if 'evaluator' in globals() and evaluator.is_trained and 'VALID_DF' in globals():\n",
    "    \n",
    "    # Get real fake news articles from validation set\n",
    "    real_fake_articles = VALID_DF[VALID_DF['label'] == 1]\n",
    "    \n",
    "    if len(real_fake_articles) > 100:\n",
    "        # Sample 100 real fake news articles for comparison\n",
    "        real_fake_sample = real_fake_articles.sample(n=100, random_state=42)\n",
    "        \n",
    "        print(f\"\\nüìä Testing classifier on REAL FAKE NEWS (100 articles)...\")\n",
    "        \n",
    "        # Convert to format expected by evaluator\n",
    "        real_fake_as_articles = []\n",
    "        for idx, row in real_fake_sample.iterrows():\n",
    "            real_fake_as_articles.append({\n",
    "                'article': row['text'], \n",
    "                'approach': 'real_fake_news',\n",
    "                'features': feature_extractor.extract_features(row['text'])\n",
    "            })\n",
    "        \n",
    "        # Test classification performance on real fake news\n",
    "        real_baseline_result = evaluator.evaluate_synthetic_approach(\n",
    "            real_fake_as_articles, \n",
    "            \"Real Fake News Baseline\"\n",
    "        )\n",
    "        \n",
    "        if real_baseline_result:\n",
    "            real_f1 = real_baseline_result['f1_score']\n",
    "            real_fake_rate = real_baseline_result['fake_classification_rate']\n",
    "            real_confidence = real_baseline_result['avg_fake_probability']\n",
    "            \n",
    "            print(f\"\\nüìà REAL FAKE NEWS PERFORMANCE:\")\n",
    "            print(f\"   F1 Score: {real_f1:.3f}\")\n",
    "            print(f\"   Fake classification rate: {real_fake_rate:.1%}\")\n",
    "            print(f\"   Average confidence: {real_confidence:.3f}\")\n",
    "            \n",
    "            # Compare to our synthetic results\n",
    "            print(f\"\\nüî¨ COMPARISON WITH SYNTHETIC RESULTS:\")\n",
    "            print(f\"{'Approach':<20} {'F1 Score':<10} {'Fake Rate':<12} {'Confidence':<12}\")\n",
    "            print(\"-\" * 55)\n",
    "            print(f\"{'Real Fake News':<20} {real_f1:<9.3f} {real_fake_rate:<11.1%} {real_confidence:<11.3f}\")\n",
    "            \n",
    "            if 'LARGE_SAMPLE_RESULTS' in globals():\n",
    "                for version, result in LARGE_SAMPLE_RESULTS.items():\n",
    "                    if result:\n",
    "                        synth_f1 = result['f1_score']\n",
    "                        synth_fake_rate = result['fake_classification_rate']\n",
    "                        synth_confidence = result['avg_fake_probability']\n",
    "                        print(f\"{'Synthetic ' + version:<20} {synth_f1:<9.3f} {synth_fake_rate:<11.1%} {synth_confidence:<11.3f}\")\n",
    "            \n",
    "            # Analysis and interpretation\n",
    "            print(f\"\\nüéØ CRITICAL INTERPRETATION:\")\n",
    "            \n",
    "            if real_f1 >= 0.95:\n",
    "                print(f\"   üö® Real fake news also has F1 ‚â• 0.95!\")\n",
    "                print(f\"   üí° This suggests the classifier is VERY GOOD at detecting fake news\")\n",
    "                print(f\"   ‚úÖ Our synthetic F1 scores (0.985-0.995) are REALISTIC\")\n",
    "                interpretation = \"SUCCESS\"\n",
    "            elif real_f1 >= 0.85:\n",
    "                print(f\"   ‚úÖ Real fake news has high F1 (‚â• 0.85)\")\n",
    "                print(f\"   üí° Classifier performs well on real fake news\")\n",
    "                if max([r['f1_score'] for r in LARGE_SAMPLE_RESULTS.values() if r]) > real_f1 + 0.05:\n",
    "                    print(f\"   ‚ö†Ô∏è Our synthetic F1 is noticeably higher than real baseline\")\n",
    "                    print(f\"   üîç May indicate some over-fitting, but still reasonable\")\n",
    "                    interpretation = \"MOSTLY_SUCCESS\"\n",
    "                else:\n",
    "                    print(f\"   ‚úÖ Our synthetic F1 matches real fake news performance\")\n",
    "                    interpretation = \"SUCCESS\"\n",
    "            else:\n",
    "                print(f\"   üìä Real fake news has moderate F1 ({real_f1:.3f})\")\n",
    "                print(f\"   üö® Our synthetic F1 (0.985-0.995) is MUCH higher than baseline\")\n",
    "                print(f\"   ‚ùå This strongly suggests OVER-FITTING\")\n",
    "                interpretation = \"OVER_FITTING\"\n",
    "            \n",
    "            # Confidence analysis\n",
    "            print(f\"\\nüîç CONFIDENCE ANALYSIS:\")\n",
    "            synthetic_confidences = [r['avg_fake_probability'] for r in LARGE_SAMPLE_RESULTS.values() if r]\n",
    "            avg_synth_confidence = np.mean(synthetic_confidences) if synthetic_confidences else 0\n",
    "            \n",
    "            if avg_synth_confidence > real_confidence + 0.1:\n",
    "                print(f\"   ‚ö†Ô∏è Synthetic confidence ({avg_synth_confidence:.3f}) much higher than real ({real_confidence:.3f})\")\n",
    "                print(f\"   üí° Suggests classifier is MORE certain about synthetic articles\")\n",
    "                confidence_assessment = \"TOO_CONFIDENT\"\n",
    "            elif abs(avg_synth_confidence - real_confidence) <= 0.1:\n",
    "                print(f\"   ‚úÖ Synthetic confidence ({avg_synth_confidence:.3f}) matches real ({real_confidence:.3f})\")\n",
    "                confidence_assessment = \"GOOD_MATCH\"\n",
    "            else:\n",
    "                print(f\"   üìä Synthetic confidence ({avg_synth_confidence:.3f}) vs real ({real_confidence:.3f})\")\n",
    "                confidence_assessment = \"MIXED\"\n",
    "            \n",
    "            # Final verdict\n",
    "            print(f\"\\nüèÜ FINAL VERDICT:\")\n",
    "            \n",
    "            if interpretation == \"SUCCESS\" and confidence_assessment in [\"GOOD_MATCH\"]:\n",
    "                print(f\"   ‚úÖ HIGH F1 SCORES = SUCCESS!\")\n",
    "                print(f\"   üí° Our synthetic articles match real fake news patterns correctly\")\n",
    "                print(f\"   üéâ The enhanced approaches are working as intended\")\n",
    "            elif interpretation in [\"SUCCESS\", \"MOSTLY_SUCCESS\"]:\n",
    "                print(f\"   üü° MOSTLY SUCCESS with minor concerns\")\n",
    "                print(f\"   üí° Synthetic articles are realistic but may be slightly too obvious\")\n",
    "                print(f\"   ‚öñÔ∏è Good balance between quality and realism\")\n",
    "            else:\n",
    "                print(f\"   üö® HIGH F1 SCORES = OVER-FITTING\")\n",
    "                print(f\"   üí° Synthetic articles are too easy for classifier to identify\")\n",
    "                print(f\"   üîß Need to reduce pattern obviousness\")\n",
    "            \n",
    "            globals()['REAL_BASELINE_RESULT'] = real_baseline_result\n",
    "            globals()['INTERPRETATION'] = interpretation\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚ùå Not enough real fake news articles for baseline (need 100, have {len(real_fake_articles)})\")\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot test baseline - missing evaluator or validation data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc115987",
   "metadata": {},
   "source": [
    "# üéØ Production Synthetic Article Generation System\n",
    "\n",
    "## Summary of Findings\n",
    "‚úÖ **Enhanced approaches are successful** - F1 scores of 0.985-0.995 match real fake news baseline (F1=0.985)  \n",
    "‚úÖ **Generated 300 high-quality articles** across three enhanced approaches  \n",
    "‚úÖ **Enhanced v2 (Controversy Focus) is optimal** - exact match with real fake news patterns  \n",
    "\n",
    "## Production Generation Plan\n",
    "- Save existing 300 articles as checkpoint\n",
    "- Calculate remaining articles needed for dataset balance\n",
    "- Generate remaining articles using Enhanced v2 approach\n",
    "- Implement robust checkpointing every 100 articles\n",
    "- Final dataset integration and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f14f6b16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíæ SAVING EXISTING GENERATED ARTICLES\n",
      "============================================================\n",
      "‚úÖ Enhanced v1: 100 articles\n",
      "‚úÖ Enhanced v2: 100 articles\n",
      "‚úÖ Enhanced v3: 100 articles\n",
      "\n",
      "üìä Total existing articles: 300\n",
      "\n",
      "üíæ Checkpoint saved: ../data/articles/synthetic/checkpoints/synthetic_articles_initial_300_20251116_163843.json\n",
      "üìä CSV analysis file: ../data/articles/synthetic/checkpoints/synthetic_articles_initial_300_20251116_163843.csv\n",
      "\n",
      "‚úÖ Initial checkpoint complete - ready for production generation\n",
      "\n",
      "üßÆ CALCULATING REMAINING ARTICLES NEEDED:\n",
      "   Current fake articles: 9,050\n",
      "   Current real articles: 11,272\n",
      "   Generated synthetic: 300\n",
      "   Articles still needed: 1,922\n",
      "   Target total fake articles: 11,272\n",
      "\n",
      "üéØ Production generation target: 1,922 additional articles\n"
     ]
    }
   ],
   "source": [
    "# Save Existing 300 Generated Articles as Checkpoint\n",
    "print(\"üíæ SAVING EXISTING GENERATED ARTICLES\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Combine all existing generated articles\n",
    "all_generated_articles = []\n",
    "\n",
    "# Add enhanced v1 large sample (100 articles)\n",
    "if 'LARGE_ENHANCED_SAMPLES' in globals() and 'v1' in LARGE_ENHANCED_SAMPLES:\n",
    "    v1_articles = LARGE_ENHANCED_SAMPLES['v1']\n",
    "    for article in v1_articles:\n",
    "        article['generation_batch'] = 'enhanced_v1_large'\n",
    "        article['approach'] = 'enhanced_zero_shot_v1'\n",
    "    all_generated_articles.extend(v1_articles)\n",
    "    print(f\"‚úÖ Enhanced v1: {len(v1_articles)} articles\")\n",
    "\n",
    "# Add enhanced v2 large sample (100 articles)  \n",
    "if 'LARGE_ENHANCED_SAMPLES' in globals() and 'v2' in LARGE_ENHANCED_SAMPLES:\n",
    "    v2_articles = LARGE_ENHANCED_SAMPLES['v2']\n",
    "    for article in v2_articles:\n",
    "        article['generation_batch'] = 'enhanced_v2_large'\n",
    "        article['approach'] = 'enhanced_zero_shot_v2'\n",
    "    all_generated_articles.extend(v2_articles)\n",
    "    print(f\"‚úÖ Enhanced v2: {len(v2_articles)} articles\")\n",
    "\n",
    "# Add enhanced v3 large sample (100 articles)\n",
    "if 'LARGE_ENHANCED_SAMPLES' in globals() and 'v3' in LARGE_ENHANCED_SAMPLES:\n",
    "    v3_articles = LARGE_ENHANCED_SAMPLES['v3']\n",
    "    for article in v3_articles:\n",
    "        article['generation_batch'] = 'enhanced_v3_large'\n",
    "        article['approach'] = 'enhanced_zero_shot_v3'\n",
    "    all_generated_articles.extend(v3_articles)\n",
    "    print(f\"‚úÖ Enhanced v3: {len(v3_articles)} articles\")\n",
    "\n",
    "print(f\"\\nüìä Total existing articles: {len(all_generated_articles)}\")\n",
    "\n",
    "if all_generated_articles:\n",
    "    # Create checkpoint directory\n",
    "    checkpoint_dir = DATA_PATH / 'synthetic' / 'checkpoints'\n",
    "    checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Save as JSON with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    checkpoint_file = checkpoint_dir / f'synthetic_articles_initial_300_{timestamp}.json'\n",
    "    \n",
    "    # Prepare data for JSON (convert numpy types)\n",
    "    articles_for_json = []\n",
    "    for article in all_generated_articles:\n",
    "        article_copy = article.copy()\n",
    "        \n",
    "        # Convert features dictionary numpy types to regular Python types\n",
    "        if 'features' in article_copy and isinstance(article_copy['features'], dict):\n",
    "            features_converted = {}\n",
    "            for key, value in article_copy['features'].items():\n",
    "                if hasattr(value, 'item'):  # numpy scalar\n",
    "                    features_converted[key] = value.item()\n",
    "                else:\n",
    "                    features_converted[key] = value\n",
    "            article_copy['features'] = features_converted\n",
    "        \n",
    "        articles_for_json.append(article_copy)\n",
    "    \n",
    "    # Save JSON checkpoint\n",
    "    with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump({\n",
    "            'metadata': {\n",
    "                'total_articles': len(articles_for_json),\n",
    "                'generation_date': timestamp,\n",
    "                'approaches': ['enhanced_zero_shot_v1', 'enhanced_zero_shot_v2', 'enhanced_zero_shot_v3'],\n",
    "                'validation_results': {\n",
    "                    'v1_f1_score': 0.995,\n",
    "                    'v2_f1_score': 0.985,  # Best match to real baseline\n",
    "                    'v3_f1_score': 0.995,\n",
    "                    'real_baseline_f1': 0.985\n",
    "                }\n",
    "            },\n",
    "            'articles': articles_for_json\n",
    "        }, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nüíæ Checkpoint saved: {checkpoint_file}\")\n",
    "    \n",
    "    # Also create CSV for easy analysis\n",
    "    csv_data = []\n",
    "    for article in all_generated_articles:\n",
    "        row = {\n",
    "            'article_text': article['article'],\n",
    "            'approach': article.get('approach', 'unknown'),\n",
    "            'generation_batch': article.get('generation_batch', 'unknown'),\n",
    "            'topic': article.get('topic', ''),\n",
    "            'timestamp': article.get('timestamp', ''),\n",
    "            'char_count': article.get('features', {}).get('char_count', 0),\n",
    "            'word_count': article.get('features', {}).get('word_count', 0),\n",
    "            'sentence_count': article.get('features', {}).get('sentence_count', 0),\n",
    "            'person_entities': article.get('features', {}).get('person_entities', 0),\n",
    "            'org_entities': article.get('features', {}).get('org_entities', 0),\n",
    "            'subjectivity': article.get('features', {}).get('subjectivity', 0),\n",
    "            'polarity': article.get('features', {}).get('polarity', 0)\n",
    "        }\n",
    "        csv_data.append(row)\n",
    "    \n",
    "    csv_df = pd.DataFrame(csv_data)\n",
    "    csv_file = checkpoint_dir / f'synthetic_articles_initial_300_{timestamp}.csv'\n",
    "    csv_df.to_csv(csv_file, index=False)\n",
    "    \n",
    "    print(f\"üìä CSV analysis file: {csv_file}\")\n",
    "    \n",
    "    # Store for production generation\n",
    "    globals()['EXISTING_ARTICLES'] = all_generated_articles\n",
    "    globals()['CHECKPOINT_DIR'] = checkpoint_dir\n",
    "    \n",
    "    print(f\"\\n‚úÖ Initial checkpoint complete - ready for production generation\")\n",
    "    \n",
    "else:\n",
    "    print(f\"\\n‚ùå No articles found to save\")\n",
    "\n",
    "# Calculate remaining articles needed\n",
    "print(f\"\\nüßÆ CALCULATING REMAINING ARTICLES NEEDED:\")\n",
    "\n",
    "if 'VALID_DF' in globals():\n",
    "    total_fake = len(VALID_DF[VALID_DF['label'] == 1])\n",
    "    total_real = len(VALID_DF[VALID_DF['label'] == 0])\n",
    "    current_synthetic = len(all_generated_articles) if all_generated_articles else 0\n",
    "    \n",
    "    print(f\"   Current fake articles: {total_fake:,}\")\n",
    "    print(f\"   Current real articles: {total_real:,}\")\n",
    "    print(f\"   Generated synthetic: {current_synthetic:,}\")\n",
    "    \n",
    "    # Target: Balance the dataset (equal fake and real)\n",
    "    if total_real > total_fake:\n",
    "        articles_needed = total_real - total_fake - current_synthetic\n",
    "        target_total_fake = total_real\n",
    "    else:\n",
    "        articles_needed = 0  # Already balanced or fake > real\n",
    "        target_total_fake = total_fake + current_synthetic\n",
    "    \n",
    "    print(f\"   Articles still needed: {max(0, articles_needed):,}\")\n",
    "    print(f\"   Target total fake articles: {target_total_fake:,}\")\n",
    "    \n",
    "    if articles_needed > 0:\n",
    "        print(f\"\\nüéØ Production generation target: {articles_needed:,} additional articles\")\n",
    "        globals()['ARTICLES_NEEDED'] = articles_needed\n",
    "    else:\n",
    "        print(f\"\\n‚úÖ Dataset already balanced or over-balanced\")\n",
    "        globals()['ARTICLES_NEEDED'] = 0\n",
    "        \n",
    "else:\n",
    "    print(f\"‚ùå Cannot calculate - VALID_DF not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "52cb3013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üè≠ PRODUCTION ARTICLE GENERATOR\n",
      "============================================================\n",
      "‚úÖ Production generator initialized\n",
      "üéØ Ready for large-scale generation with Enhanced v2 approach\n"
     ]
    }
   ],
   "source": [
    "# Production Article Generator with Robust Checkpointing\n",
    "print(\"üè≠ PRODUCTION ARTICLE GENERATOR\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "class ProductionEnhancedGenerator:\n",
    "    \"\"\"\n",
    "    Production-ready generator with checkpointing and error recovery\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, openai_client, feature_extractor, checkpoint_dir):\n",
    "        self.client = openai_client\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.checkpoint_dir = checkpoint_dir\n",
    "        \n",
    "        # Use Enhanced v2 approach (best match to real fake news baseline)\n",
    "        self.approach = 'enhanced_zero_shot_v2'\n",
    "        self.prompt_version = 2\n",
    "        \n",
    "    def create_production_prompt(self):\n",
    "        \"\"\"Enhanced v2 prompt - proven to match real fake news patterns\"\"\"\n",
    "        return \"\"\"\n",
    "Write a news article following these fake news characteristics:\n",
    "\n",
    "CONTROVERSY FRAMING (essential elements):\n",
    "- Present political events through lens of public outrage or controversy\n",
    "- Reference \"trump campaign\", \"supreme court\", or major political institutions\n",
    "- Include \"republican party\" vs opposition dynamics\n",
    "- Frame as \"year old\" precedent breaking or historical significance\n",
    "\n",
    "VISUAL MEDIA FOCUS (must include):\n",
    "- \"featured image video\" or \"image video screen\" references\n",
    "- \"screen capture\" of social media posts or statements\n",
    "- \"getty images\" attribution for photos\n",
    "- \"video screen capture\" of TV appearances or speeches\n",
    "\n",
    "ENGAGEMENT PATTERNS:\n",
    "- Use \"we\", \"people\", \"you\" to engage readers directly\n",
    "- Include rhetorical questions about implications\n",
    "- Reference how \"this affects everyone\" or community impact\n",
    "- Create sense of urgency about political developments\n",
    "\n",
    "TECHNICAL SPECIFICATIONS:\n",
    "- 800-1200 words in 17-29 sentences\n",
    "- Exactly 16-27 commas for complex sentence structure  \n",
    "- 8-17 named individuals with specific titles/roles\n",
    "- 5-12 organizational entities mentioned\n",
    "- 1-2 question marks, 0-1 exclamation marks maximum\n",
    "- Slightly positive emotional tone (0.04-0.11 polarity)\n",
    "- High interpretive content (0.45-0.65 subjectivity)\n",
    "\n",
    "TOPIC: {topic}\n",
    "\n",
    "Focus on the political implications and public reactions rather than just reporting facts. Include references to specific images or social media content that drove the story.\n",
    "\"\"\"\n",
    "    \n",
    "    def get_production_topics(self):\n",
    "        \"\"\"Political topics that encourage realistic fake news patterns\"\"\"\n",
    "        return [\n",
    "            \"congressional committee investigation reveals new evidence in ongoing inquiry\",\n",
    "            \"state election officials respond to federal oversight proposal with mixed reactions\", \n",
    "            \"supreme court decision creates uncertainty for pending legislation across multiple states\",\n",
    "            \"political figure's testimony before house committee draws bipartisan scrutiny\",\n",
    "            \"federal agency rule change faces legal challenges from industry groups\",\n",
    "            \"government transparency report highlights accountability gaps in multiple departments\",\n",
    "            \"bipartisan legislation faces obstacles despite initial cross-party support\",\n",
    "            \"judicial nomination hearing features contentious exchanges over judicial philosophy\",\n",
    "            \"campaign finance investigation expands to include additional political organizations\",\n",
    "            \"regulatory agency decision impacts multiple stakeholders across different sectors\",\n",
    "            \"political party leadership meeting addresses strategy ahead of upcoming elections\",\n",
    "            \"government accountability office report criticizes implementation of federal program\",\n",
    "            \"congressional hearing on oversight reveals tensions between legislative and executive branches\",\n",
    "            \"federal investigation into government contracts raises questions about procurement processes\",\n",
    "            \"policy implementation challenges emerge as states adapt to new federal guidelines\",\n",
    "            \"political alliance shows signs of strain over disagreements on key legislative priorities\",\n",
    "            \"government ethics investigation examines conduct of multiple public officials\",\n",
    "            \"regulatory reform proposal generates debate among business groups and consumer advocates\",\n",
    "            \"congressional subpoena fight escalates as executive branch claims privilege\",\n",
    "            \"federal court ruling creates precedent that may affect similar cases nationwide\",\n",
    "            \"state legislature debates election security measures amid public concern\",\n",
    "            \"federal communications commission ruling on media ownership sparks industry backlash\",\n",
    "            \"house intelligence committee reviews classified documents in ongoing probe\",\n",
    "            \"senate judiciary hearing on judicial nominations becomes contentious affair\",\n",
    "            \"department of justice investigation expands to include political organizations\"\n",
    "        ]\n",
    "    \n",
    "    def generate_batch_with_checkpoints(self, total_articles, batch_size=100, start_from=0):\n",
    "        \"\"\"\n",
    "        Generate articles in batches with automatic checkpointing\n",
    "        \"\"\"\n",
    "        print(f\"üöÄ Starting production generation:\")\n",
    "        print(f\"   Total articles: {total_articles:,}\")\n",
    "        print(f\"   Batch size: {batch_size}\")\n",
    "        print(f\"   Starting from: {start_from}\")\n",
    "        \n",
    "        all_articles = []\n",
    "        topics = self.get_production_topics()\n",
    "        prompt = self.create_production_prompt()\n",
    "        \n",
    "        try:\n",
    "            for batch_start in range(start_from, total_articles, batch_size):\n",
    "                batch_end = min(batch_start + batch_size, total_articles)\n",
    "                current_batch_size = batch_end - batch_start\n",
    "                \n",
    "                print(f\"\\nüì¶ Generating batch {batch_start//batch_size + 1}\")\n",
    "                print(f\"   Articles {batch_start+1}-{batch_end} ({current_batch_size} articles)\")\n",
    "                \n",
    "                batch_articles = []\n",
    "                \n",
    "                for i in range(current_batch_size):\n",
    "                    global_index = batch_start + i\n",
    "                    \n",
    "                    try:\n",
    "                        # Select topic\n",
    "                        topic = np.random.choice(topics)\n",
    "                        full_prompt = prompt.format(topic=topic)\n",
    "                        \n",
    "                        # Generate article\n",
    "                        response = self.client.chat.completions.create(\n",
    "                            model=\"gpt-3.5-turbo\",\n",
    "                            messages=[\n",
    "                                {\"role\": \"system\", \"content\": \"You are creating synthetic fake news articles for academic research. Focus precisely on matching the specified linguistic patterns, social media integration, and interpretive journalism style characteristic of fake news.\"},\n",
    "                                {\"role\": \"user\", \"content\": full_prompt}\n",
    "                            ],\n",
    "                            max_tokens=1500,\n",
    "                            temperature=0.7\n",
    "                        )\n",
    "                        \n",
    "                        article_text = response.choices[0].message.content.strip()\n",
    "                        features = self.feature_extractor.extract_features(article_text)\n",
    "                        \n",
    "                        article = {\n",
    "                            'article': article_text,\n",
    "                            'approach': self.approach,\n",
    "                            'topic': topic,\n",
    "                            'features': features,\n",
    "                            'generation_batch': f'production_batch_{batch_start//batch_size + 1}',\n",
    "                            'global_index': global_index,\n",
    "                            'timestamp': datetime.now().isoformat()\n",
    "                        }\n",
    "                        \n",
    "                        batch_articles.append(article)\n",
    "                        \n",
    "                        if (i + 1) % 20 == 0:\n",
    "                            print(f\"     Generated {i+1}/{current_batch_size} articles...\")\n",
    "                        \n",
    "                        # Rate limiting\n",
    "                        time.sleep(0.4)\n",
    "                        \n",
    "                    except Exception as e:\n",
    "                        print(f\"     ‚ùå Error generating article {global_index+1}: {e}\")\n",
    "                        continue\n",
    "                \n",
    "                # Add batch to total\n",
    "                all_articles.extend(batch_articles)\n",
    "                \n",
    "                print(f\"   ‚úÖ Batch complete: {len(batch_articles)} articles generated\")\n",
    "                \n",
    "                # Save checkpoint after each batch\n",
    "                self.save_checkpoint(all_articles, batch_end, total_articles)\n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            print(f\"\\n‚è∏Ô∏è Generation interrupted by user\")\n",
    "            print(f\"   Articles generated so far: {len(all_articles)}\")\n",
    "            self.save_checkpoint(all_articles, len(all_articles), total_articles, interrupted=True)\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ùå Generation error: {e}\")\n",
    "            print(f\"   Articles generated so far: {len(all_articles)}\")\n",
    "            self.save_checkpoint(all_articles, len(all_articles), total_articles, error=str(e))\n",
    "        \n",
    "        print(f\"\\nüéâ Production generation complete!\")\n",
    "        print(f\"   Total articles generated: {len(all_articles)}\")\n",
    "        \n",
    "        return all_articles\n",
    "    \n",
    "    def save_checkpoint(self, articles, current_count, total_target, interrupted=False, error=None):\n",
    "        \"\"\"Save checkpoint with metadata\"\"\"\n",
    "        \n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        \n",
    "        # Determine checkpoint type\n",
    "        if error:\n",
    "            checkpoint_type = \"error\"\n",
    "        elif interrupted:\n",
    "            checkpoint_type = \"interrupted\"\n",
    "        elif current_count >= total_target:\n",
    "            checkpoint_type = \"final\"\n",
    "        else:\n",
    "            checkpoint_type = \"batch\"\n",
    "        \n",
    "        filename = f'production_checkpoint_{checkpoint_type}_{current_count}articles_{timestamp}.json'\n",
    "        checkpoint_file = self.checkpoint_dir / filename\n",
    "        \n",
    "        # Convert articles for JSON\n",
    "        articles_for_json = []\n",
    "        for article in articles:\n",
    "            article_copy = article.copy()\n",
    "            if 'features' in article_copy and isinstance(article_copy['features'], dict):\n",
    "                features_converted = {}\n",
    "                for key, value in article_copy['features'].items():\n",
    "                    if hasattr(value, 'item'):\n",
    "                        features_converted[key] = value.item()\n",
    "                    else:\n",
    "                        features_converted[key] = value\n",
    "                article_copy['features'] = features_converted\n",
    "            articles_for_json.append(article_copy)\n",
    "        \n",
    "        # Save checkpoint\n",
    "        checkpoint_data = {\n",
    "            'metadata': {\n",
    "                'checkpoint_type': checkpoint_type,\n",
    "                'articles_generated': len(articles),\n",
    "                'target_total': total_target,\n",
    "                'progress_percentage': (len(articles) / total_target * 100) if total_target > 0 else 0,\n",
    "                'generation_date': timestamp,\n",
    "                'approach': self.approach,\n",
    "                'interrupted': interrupted,\n",
    "                'error': error\n",
    "            },\n",
    "            'articles': articles_for_json\n",
    "        }\n",
    "        \n",
    "        with open(checkpoint_file, 'w', encoding='utf-8') as f:\n",
    "            json.dump(checkpoint_data, f, indent=2, ensure_ascii=False)\n",
    "        \n",
    "        status = \"‚ùå ERROR\" if error else \"‚è∏Ô∏è INTERRUPTED\" if interrupted else \"‚úÖ SUCCESS\" if current_count >= total_target else \"üîÑ PROGRESS\"\n",
    "        print(f\"   üíæ {status} Checkpoint saved: {filename}\")\n",
    "        print(f\"      Progress: {len(articles)}/{total_target} ({len(articles)/total_target*100:.1f}%)\")\n",
    "        \n",
    "        return checkpoint_file\n",
    "\n",
    "# Initialize production generator\n",
    "if API_AVAILABLE and 'enhanced_generator' in globals() and 'CHECKPOINT_DIR' in globals():\n",
    "    production_generator = ProductionEnhancedGenerator(\n",
    "        OPENAI_CLIENT, \n",
    "        feature_extractor, \n",
    "        CHECKPOINT_DIR\n",
    "    )\n",
    "    print(\"‚úÖ Production generator initialized\")\n",
    "    print(\"üéØ Ready for large-scale generation with Enhanced v2 approach\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Production generator not initialized - missing dependencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "069659d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üé¨ EXECUTING PRODUCTION GENERATION\n",
      "============================================================\n",
      "üéØ Starting generation of 1,922 additional articles\n",
      "üìä Using Enhanced v2 approach (F1=0.985, matches real fake news baseline)\n",
      "üíæ Checkpoints will be saved every 100 articles\n",
      "‚è±Ô∏è Estimated time: 16.0 minutes\n",
      "\n",
      "‚ö†Ô∏è This will generate 1,922 articles and may take significant time.\n",
      "üí° You can interrupt (Ctrl+C) at any time - progress will be checkpointed.\n",
      "üöÄ Starting production generation:\n",
      "   Total articles: 1,922\n",
      "   Batch size: 100\n",
      "   Starting from: 0\n",
      "\n",
      "üì¶ Generating batch 1\n",
      "   Articles 1-100 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_100articles_20251116_165204.json\n",
      "      Progress: 100/1922 (5.2%)\n",
      "\n",
      "üì¶ Generating batch 2\n",
      "   Articles 101-200 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_200articles_20251116_170207.json\n",
      "      Progress: 200/1922 (10.4%)\n",
      "\n",
      "üì¶ Generating batch 3\n",
      "   Articles 201-300 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_300articles_20251116_171222.json\n",
      "      Progress: 300/1922 (15.6%)\n",
      "\n",
      "üì¶ Generating batch 4\n",
      "   Articles 301-400 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_400articles_20251116_172235.json\n",
      "      Progress: 400/1922 (20.8%)\n",
      "\n",
      "üì¶ Generating batch 5\n",
      "   Articles 401-500 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_500articles_20251116_173310.json\n",
      "      Progress: 500/1922 (26.0%)\n",
      "\n",
      "üì¶ Generating batch 6\n",
      "   Articles 501-600 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_600articles_20251116_174333.json\n",
      "      Progress: 600/1922 (31.2%)\n",
      "\n",
      "üì¶ Generating batch 7\n",
      "   Articles 601-700 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_700articles_20251116_175325.json\n",
      "      Progress: 700/1922 (36.4%)\n",
      "\n",
      "üì¶ Generating batch 8\n",
      "   Articles 701-800 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_800articles_20251116_180412.json\n",
      "      Progress: 800/1922 (41.6%)\n",
      "\n",
      "üì¶ Generating batch 9\n",
      "   Articles 801-900 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_900articles_20251116_181504.json\n",
      "      Progress: 900/1922 (46.8%)\n",
      "\n",
      "üì¶ Generating batch 10\n",
      "   Articles 901-1000 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1000articles_20251116_182526.json\n",
      "      Progress: 1000/1922 (52.0%)\n",
      "\n",
      "üì¶ Generating batch 11\n",
      "   Articles 1001-1100 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1100articles_20251116_183607.json\n",
      "      Progress: 1100/1922 (57.2%)\n",
      "\n",
      "üì¶ Generating batch 12\n",
      "   Articles 1101-1200 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1200articles_20251116_184611.json\n",
      "      Progress: 1200/1922 (62.4%)\n",
      "\n",
      "üì¶ Generating batch 13\n",
      "   Articles 1201-1300 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1300articles_20251116_185608.json\n",
      "      Progress: 1300/1922 (67.6%)\n",
      "\n",
      "üì¶ Generating batch 14\n",
      "   Articles 1301-1400 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1400articles_20251116_190637.json\n",
      "      Progress: 1400/1922 (72.8%)\n",
      "\n",
      "üì¶ Generating batch 15\n",
      "   Articles 1401-1500 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1500articles_20251116_191739.json\n",
      "      Progress: 1500/1922 (78.0%)\n",
      "\n",
      "üì¶ Generating batch 16\n",
      "   Articles 1501-1600 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1600articles_20251116_192853.json\n",
      "      Progress: 1600/1922 (83.2%)\n",
      "\n",
      "üì¶ Generating batch 17\n",
      "   Articles 1601-1700 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1700articles_20251116_193929.json\n",
      "      Progress: 1700/1922 (88.4%)\n",
      "\n",
      "üì¶ Generating batch 18\n",
      "   Articles 1701-1800 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1800articles_20251116_195016.json\n",
      "      Progress: 1800/1922 (93.7%)\n",
      "\n",
      "üì¶ Generating batch 19\n",
      "   Articles 1801-1900 (100 articles)\n",
      "     Generated 20/100 articles...\n",
      "     Generated 40/100 articles...\n",
      "     Generated 60/100 articles...\n",
      "     Generated 80/100 articles...\n",
      "     Generated 100/100 articles...\n",
      "   ‚úÖ Batch complete: 100 articles generated\n",
      "   üíæ üîÑ PROGRESS Checkpoint saved: production_checkpoint_batch_1900articles_20251116_200035.json\n",
      "      Progress: 1900/1922 (98.9%)\n",
      "\n",
      "üì¶ Generating batch 20\n",
      "   Articles 1901-1922 (22 articles)\n",
      "     Generated 20/22 articles...\n",
      "   ‚úÖ Batch complete: 22 articles generated\n",
      "   üíæ ‚úÖ SUCCESS Checkpoint saved: production_checkpoint_final_1922articles_20251116_200302.json\n",
      "      Progress: 1922/1922 (100.0%)\n",
      "\n",
      "üéâ Production generation complete!\n",
      "   Total articles generated: 1922\n",
      "\n",
      "üéâ PRODUCTION GENERATION COMPLETE!\n",
      "   Articles generated: 1,922\n",
      "   Total synthetic articles: 2,222\n",
      "   üíæ Final dataset saved: ../data/articles/synthetic/checkpoints/complete_synthetic_dataset_2222articles_20251116_200302.json\n"
     ]
    }
   ],
   "source": [
    "# Execute Production Generation\n",
    "print(\"üé¨ EXECUTING PRODUCTION GENERATION\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Run the actual generation\n",
    "if 'production_generator' in globals() and 'ARTICLES_NEEDED' in globals():\n",
    "    \n",
    "    if ARTICLES_NEEDED > 0:\n",
    "        print(f\"üéØ Starting generation of {ARTICLES_NEEDED:,} additional articles\")\n",
    "        print(f\"üìä Using Enhanced v2 approach (F1=0.985, matches real fake news baseline)\")\n",
    "        print(f\"üíæ Checkpoints will be saved every 100 articles\")\n",
    "        print(f\"‚è±Ô∏è Estimated time: {ARTICLES_NEEDED * 0.5 / 60:.1f} minutes\")\n",
    "        \n",
    "        # Confirm before starting large generation\n",
    "        print(f\"\\n‚ö†Ô∏è This will generate {ARTICLES_NEEDED:,} articles and may take significant time.\")\n",
    "        print(f\"üí° You can interrupt (Ctrl+C) at any time - progress will be checkpointed.\")\n",
    "        \n",
    "        # Start generation\n",
    "        production_articles = production_generator.generate_batch_with_checkpoints(\n",
    "            total_articles=ARTICLES_NEEDED,\n",
    "            batch_size=100,\n",
    "            start_from=0\n",
    "        )\n",
    "        \n",
    "        if production_articles:\n",
    "            print(f\"\\nüéâ PRODUCTION GENERATION COMPLETE!\")\n",
    "            print(f\"   Articles generated: {len(production_articles):,}\")\n",
    "            \n",
    "            # Combine with existing articles\n",
    "            total_synthetic_articles = []\n",
    "            if 'EXISTING_ARTICLES' in globals():\n",
    "                total_synthetic_articles.extend(EXISTING_ARTICLES)\n",
    "            total_synthetic_articles.extend(production_articles)\n",
    "            \n",
    "            print(f\"   Total synthetic articles: {len(total_synthetic_articles):,}\")\n",
    "            \n",
    "            # Save final combined dataset\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            final_file = CHECKPOINT_DIR / f'complete_synthetic_dataset_{len(total_synthetic_articles)}articles_{timestamp}.json'\n",
    "            \n",
    "            # Convert for JSON\n",
    "            final_articles_for_json = []\n",
    "            for article in total_synthetic_articles:\n",
    "                article_copy = article.copy()\n",
    "                if 'features' in article_copy and isinstance(article_copy['features'], dict):\n",
    "                    features_converted = {}\n",
    "                    for key, value in article_copy['features'].items():\n",
    "                        if hasattr(value, 'item'):\n",
    "                            features_converted[key] = value.item()\n",
    "                        else:\n",
    "                            features_converted[key] = value\n",
    "                    article_copy['features'] = features_converted\n",
    "                final_articles_for_json.append(article_copy)\n",
    "            \n",
    "            final_dataset = {\n",
    "                'metadata': {\n",
    "                    'total_articles': len(final_articles_for_json),\n",
    "                    'completion_date': timestamp,\n",
    "                    'approaches_used': ['enhanced_zero_shot_v1', 'enhanced_zero_shot_v2', 'enhanced_zero_shot_v3'],\n",
    "                    'primary_approach': 'enhanced_zero_shot_v2',\n",
    "                    'validation_f1_scores': {\n",
    "                        'v1': 0.995,\n",
    "                        'v2': 0.985,\n",
    "                        'v3': 0.995,\n",
    "                        'real_baseline': 0.985\n",
    "                    },\n",
    "                    'dataset_purpose': 'fake_news_imbalance_correction'\n",
    "                },\n",
    "                'articles': final_articles_for_json\n",
    "            }\n",
    "            \n",
    "            with open(final_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_dataset, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"   üíæ Final dataset saved: {final_file}\")\n",
    "            \n",
    "            # Store for integration\n",
    "            globals()['PRODUCTION_ARTICLES'] = production_articles\n",
    "            globals()['TOTAL_SYNTHETIC_ARTICLES'] = total_synthetic_articles\n",
    "            globals()['FINAL_DATASET_FILE'] = final_file\n",
    "            \n",
    "        else:\n",
    "            print(f\"\\n‚ùå Production generation failed or was interrupted\")\n",
    "            \n",
    "    else:\n",
    "        print(f\"‚úÖ No additional articles needed - dataset already balanced\")\n",
    "        print(f\"üìä Current synthetic articles: {len(EXISTING_ARTICLES) if 'EXISTING_ARTICLES' in globals() else 0}\")\n",
    "        \n",
    "        # Still save the existing articles as final dataset\n",
    "        if 'EXISTING_ARTICLES' in globals():\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            final_file = CHECKPOINT_DIR / f'complete_synthetic_dataset_{len(EXISTING_ARTICLES)}articles_{timestamp}.json'\n",
    "            \n",
    "            final_articles_for_json = []\n",
    "            for article in EXISTING_ARTICLES:\n",
    "                article_copy = article.copy()\n",
    "                if 'features' in article_copy and isinstance(article_copy['features'], dict):\n",
    "                    features_converted = {}\n",
    "                    for key, value in article_copy['features'].items():\n",
    "                        if hasattr(value, 'item'):\n",
    "                            features_converted[key] = value.item()\n",
    "                        else:\n",
    "                            features_converted[key] = value\n",
    "                    article_copy['features'] = features_converted\n",
    "                final_articles_for_json.append(article_copy)\n",
    "            \n",
    "            final_dataset = {\n",
    "                'metadata': {\n",
    "                    'total_articles': len(final_articles_for_json),\n",
    "                    'completion_date': timestamp,\n",
    "                    'approaches_used': ['enhanced_zero_shot_v1', 'enhanced_zero_shot_v2', 'enhanced_zero_shot_v3'],\n",
    "                    'validation_f1_scores': {\n",
    "                        'v1': 0.995,\n",
    "                        'v2': 0.985,\n",
    "                        'v3': 0.995,\n",
    "                        'real_baseline': 0.985\n",
    "                    },\n",
    "                    'dataset_purpose': 'fake_news_synthetic_articles',\n",
    "                    'note': 'Dataset already balanced - no additional generation needed'\n",
    "                },\n",
    "                'articles': final_articles_for_json\n",
    "            }\n",
    "            \n",
    "            with open(final_file, 'w', encoding='utf-8') as f:\n",
    "                json.dump(final_dataset, f, indent=2, ensure_ascii=False)\n",
    "            \n",
    "            print(f\"üíæ Existing articles saved as final dataset: {final_file}\")\n",
    "            \n",
    "            globals()['TOTAL_SYNTHETIC_ARTICLES'] = EXISTING_ARTICLES\n",
    "            globals()['FINAL_DATASET_FILE'] = final_file\n",
    "\n",
    "else:\n",
    "    print(\"‚ùå Cannot start production generation - missing generator or calculation\")\n",
    "    \n",
    "    if 'ARTICLES_NEEDED' not in globals():\n",
    "        print(\"   Missing: Articles needed calculation\")\n",
    "    if 'production_generator' not in globals():\n",
    "        print(\"   Missing: Production generator initialization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61098267",
   "metadata": {},
   "source": [
    "## üéØ Production Generation Summary\n",
    "\n",
    "### ‚úÖ Setup Complete\n",
    "\n",
    "**Generated Articles Saved:**\n",
    "- ‚úÖ 300 articles successfully saved as checkpoint\n",
    "- ‚úÖ Enhanced v1: 100 articles (F1=0.995)\n",
    "- ‚úÖ Enhanced v2: 100 articles (F1=0.985) - **Optimal approach**\n",
    "- ‚úÖ Enhanced v3: 100 articles (F1=0.995)\n",
    "\n",
    "**Dataset Analysis:**\n",
    "- Current fake articles: 9,050\n",
    "- Current real articles: 11,272  \n",
    "- **Articles needed: 1,922 additional articles**\n",
    "- Target: Balance dataset at 11,272 fake articles\n",
    "\n",
    "**Production System Ready:**\n",
    "- üéØ Enhanced v2 approach selected (perfect match to real fake news baseline)\n",
    "- üíæ Robust checkpointing every 100 articles\n",
    "- ‚è∏Ô∏è Interrupt-safe generation (Ctrl+C preserves progress)\n",
    "- üîÑ Automatic error recovery and resumption capability\n",
    "- ‚è±Ô∏è Estimated generation time: ~16 minutes for remaining articles\n",
    "\n",
    "### üöÄ Next Steps\n",
    "Run the cell below to start generating the remaining 1,922 articles needed to balance your dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
